
@ARTICLE{Chen201983,
author={Chen, A. and Chen, Y. and Lu, G. and Zhang, L. and Luo, J.},
title={An anomaly detection algorithm for spatiotemporal data based on attribute correlation},
journal={Lecture Notes in Electrical Engineering},
year={2019},
volume={518},
pages={83-89},
doi={10.1007/978-981-13-1328-8_11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058337970&doi=10.1007%2f978-981-13-1328-8_11&partnerID=40&md5=c2ebbab79ee1dac44359eda75fbd477f},
abstract={In cyber physical systems (CPS), anomaly detection is an important means to ensure the quality of sensory data and the effect of data fusion. However, the challenge of detecting anomalies in data stream has become harder over time due to its large scale, multi-dimension and spatiotemporal features. In this paper, a novel anomaly detection algorithm for spatiotemporal data is proposed. The algorithm firstly uses data mining technology to dig out correlation rules between multidimensional data attributes, and output the strong association attributes set. Then the corresponding specific association rules for data anomaly detection are built based on machine learning method. Experimental results show that the algorithm is superior to other algorithms. © Springer Nature Singapore Pte Ltd. 2019.},
author_keywords={Anomaly detection;  Cyber-physical system;  Data fusion;  Data mining;  Machine learning},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Suzhen2018,
author={Suzhen, Q.},
title={Data Mining and Business Process Management of Apriori Algorithm},
journal={IOP Conference Series: Materials Science and Engineering},
year={2018},
volume={439},
number={3},
doi={10.1088/1757-899X/439/3/032012},
art_number={032012},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057518133&doi=10.1088%2f1757-899X%2f439%2f3%2f032012&partnerID=40&md5=8312fadde5ce4ba8740958ed2ddbb2ad},
abstract={The classical association rule data mining algorithm Apriori algorithm is widely used in various fields. Through the analysis and mining of data relevance, the information extracted has important reference value in the decision-making process. The continuous promotion and application of information technology, how to make full use of this data information to provide decision support for decision maker in various industries have become an urgent and thorny issue. In addition to using the existing relational database standard query statements to obtain general and intuitive information, It is necessary to mine the data relationships that are contained, unknown, and actually exist. The famous Apriori algorithm is an algorithm for mining association rules. In this paper, through the basic idea of Apriori algorithm, the embedded data relationship is mined and Apriori algorithm is implemented. © Published under licence by IOP Publishing Ltd.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Sinaei20181,
author={Sinaei, S. and Fatemi, O.},
title={Run-time mapping algorithm for dynamic workloads using association rule mining},
journal={Journal of Systems Architecture},
year={2018},
volume={91},
pages={1-10},
doi={10.1016/j.sysarc.2018.09.005},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054032125&doi=10.1016%2fj.sysarc.2018.09.005&partnerID=40&md5=f1343958b56394c2f52842c04fccb547},
abstract={Task mapping exploration plays an important role in the high performance achieved by heterogeneous multi-processor system-on-chip (MPSoC) platforms. The dynamic of application workloads in modern MPSoC-based embedded systems are consistently growing. Nowadays, the execution of different applications is done concurrently, and these applications compete for resources in such systems. To cope with the dynamism of application workloads at runtime and improve the efficiency of the underlying system architecture, this paper presents a hybrid task mapping algorithm for multimedia applications. That consists of two phases: design-time and run-time. During design-time, static mapping exploration is performed, and the applications are clustered based on their efficient mapping, then a set of rules for mapping is extracted by Association Rule Mining techniques. During run-time, when a new application enters to the system, this application is classified to one of the existing clusters using the rule sets extracted at design-time phase. The objective of application mapping is to minimize execution time in a predefined budget of energy consumption. A heterogeneous MPSoC system is used to evaluate the proposed algorithm. The experimental results revealed that during run-time by using the proposed algorithm, suitable resources regarding energy consumption and execution time are selected for mapping. © 2018 Elsevier B.V.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Song2018239,
author={Song, X. and Shi, Y. and Chen, X. and Han, Y.},
title={Explore multi-step reasoning in video question answering},
journal={MM 2018 - Proceedings of the 2018 ACM Multimedia Conference},
year={2018},
pages={239-247},
doi={10.1145/3240508.3240563},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058225699&doi=10.1145%2f3240508.3240563&partnerID=40&md5=35c21da232d60bde5ca51ef311c799f1},
abstract={Video question answering (VideoQA) always involves visual reasoning. When answering questions composing of multiple logic correlations, models need to perform multi-step reasoning. In this paper, we formulate multi-step reasoning in VideoQA as a new task to answer compositional and logical structured questions based on video content. Existing VideoQA datasets are inadequate as benchmarks for the multi-step reasoning due to limitations such as lacking logical structure and having language biases. Thus we design a system to automatically generate a large-scale dataset, namely SVQA (Synthetic Video Question Answering). Compared with other VideoQA datasets, SVQA contains exclusively long and structured questions with various spatial and temporal relations between objects. More importantly, questions in SVQA can be decomposed into human readable logical tree or chain layouts, each node of which represents a sub-task requiring a reasoning operation such as comparison or arithmetic. Towards automatic question answering in SVQA, we develop a new VideoQA model. Particularly, we construct a new attention module, which contains spatial attention mechanism to address crucial and multiple logical sub-tasks embedded in questions, as well as a refined GRU called ta-GRU (temporal-attention GRU) to capture the long-term temporal dependency and gather complete visual cues. Experimental results show the capability of multi-step reasoning of SVQA and the effectiveness of our model when compared with other existing models. © 2018 Association for Computing Machinery.},
author_keywords={Multi-Step Reasoning;  Video Question Answering},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Sinaei2018373,
author={Sinaei, S. and Fatemi, O.},
title={Run-time mapping algorithm for dynamic workloads on heterogeneous MPSoCs platforms},
journal={Proceedings - 21st Euromicro Conference on Digital System Design, DSD 2018},
year={2018},
pages={373-380},
doi={10.1109/DSD.2018.00071},
art_number={8491842},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056453754&doi=10.1109%2fDSD.2018.00071&partnerID=40&md5=cf68ba11213dad4a05eaeaef81d1210a},
abstract={Task mapping exploration plays an important role in the high performance achieved by heterogeneous multi-processor system-on-chip (MPSoC) platforms. The dynamic of application workloads in modern MPSoC-based embedded systems are consistently growing. Nowadays, the execution of different applications is done concurrently and these applications compete for resources in such systems. This paper presents a novel run-time mapping algorithm for multimedia applications. The objective of application mapping is to minimize execution time in a predefined budget of energy consumption. This algorithm is divided to two phases: design-time and run-time. During design-time, application clustering is combined with design space exploration, then a set of rules for mapping is extracted by using Association Rule Mining techniques, and after that, during run-time, feature extraction and application classification is performed based on the rule sets. The evaluation of the proposed algorithm is done by using a heterogeneous MPSoC system with several applications that have different communication and computation behaviors. The experimental results revealed that during run-time, applications were correctly classified by the proposed algorithm and the best resources selected for mapping accurately. The results clearly showcase the proposed algorithm's effectiveness. © 2018 IEEE.},
author_keywords={Heterogeneous MPSoC;  Rule Association Mining;  Run time Mapping},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Liao2018,
author={Liao, S. and Chen, J. and Hou, J. and Xiong, Q. and Wen, J.},
title={Deep Convolutional Neural Networks with Random Subspace Learning for Short-term Traffic Flow Prediction with Incomplete Data},
journal={Proceedings of the International Joint Conference on Neural Networks},
year={2018},
volume={2018-July},
doi={10.1109/IJCNN.2018.8489536},
art_number={8489536},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056526185&doi=10.1109%2fIJCNN.2018.8489536&partnerID=40&md5=0265a954b363e9d29f0b5b3e46705fdd},
abstract={Traffic flow prediction is a fundamental component in intelligent transportation systems. However, many existing prediction models endure several shortages. Most of the methods are constructed as a shallow model, which is difficult to reveal the intrinsic spatio-temporal relations embedded in traffic raw data. Moreover, the separation of feature learning and predictor learning brings a sacrifice of model performance. Then the hand designed features are difficult to be tuned appropriately. Finally, few existing methods consider the incomplete data problem which is in fact very severe for practical application. In this work, we develop a deep learning model to predict traffic flows. The main contribution is development of an architecture that integrates random subspace learning and ensemble learning on deep convolutional neural networks. The proposed model takes the traffic flow data as an image, and considers both exploring spatio-temporal correlations in the unified architecture and the incomplete data problem. The experimental results, using traffic data originated from the California Freeway Performance Measurement System (PeMS), corroborate the effectiveness of the proposed approach compared with the state of the art. © 2018 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Fang2018741,
author={Fang, G. and Wang, J. and Ying, H.},
title={A Novel Model for Mining Frequent Patterns Based on Embedded Granular Computing},
journal={International Journal of Uncertainty, Fuzziness and Knowlege-Based Systems},
year={2018},
volume={26},
number={5},
pages={741-769},
doi={10.1142/S0218488518500344},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054193700&doi=10.1142%2fS0218488518500344&partnerID=40&md5=9d142c1178137f54a53b5f177bb33cc2},
abstract={For mining frequent patterns, it is very expensive for the Apriori mining model to read the database repeatedly, and a highly condensed data structure made the FP-growth mining model cost larger memory. In order to avoid the disadvantages of these data mining model, this paper proposes a novel data mining model for discovering frequent patterns, called a data mining model based on embedded granular computing, which is different from the Apriori model and the FP-growth model. The data mining model adopts efficiently dividing and conquering from granular computing, which can construct adaptively different hierarchical granules. To form the data mining model, an embedded granular computing model is proposed in this paper. The granular computing model is used in discovering frequent patterns, on the one hand, it avoids reading the database repeatedly via constructing the extended information granule, and lessen the calculated amount of support; on the other hand, it reduces the memory requirements by the attribute granule, where the search space can compress the memory space of data structure that make the method of generating the candidate become simple relatively; and it can divide the overlarge computing task into several easy operations via the attribute granule, namely, the embedded granular computing model could short the size of the search space from a super state to several sub-states. All experimental results show that the data mining model based on embedded granular computing is more reasonable and efficient than these classical models for mining frequent patterns under these different types of datasets. Otherwise, an extra discussion describes the performance trend of the model by a group of experiments. © 2018 World Scientific Publishing Company.},
author_keywords={association rules;  data mining;  Frequent patterns;  granular computing},
document_type={Article},
source={Scopus},
}

@ARTICLE{Lee20181665,
author={Lee, S.-R. and Choi, Y.-D. and Cho, N.-H.},
title={Association between pathologic factors and ERG expression in prostate cancer: finding pivotal networking},
journal={Journal of Cancer Research and Clinical Oncology},
year={2018},
volume={144},
number={9},
pages={1665-1683},
doi={10.1007/s00432-018-2685-6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048369500&doi=10.1007%2fs00432-018-2685-6&partnerID=40&md5=2a1eb26a2e132027f16aef299c70518b},
abstract={Purpose: To evaluate associations between pathologic factors and erythroblast transformation-specific (ETS)-related gene (ERG) expression in prostate cancer patients. Using next-generation sequencing, we identified target genes and regulatory networks. Methods: ERG expression in 60 radical prostatectomies was compared with pathological findings by association rule mining with the Apriori algorithm. Whole-exome and RNA sequencing were performed on three formalin-fixed, paraffin-embedded ERG-positive and negative prostate cancer samples. A network diagram identifying dominant altered genes was constructed using Cytoscape open-source bioinformatics platform and GeneMania plugin. Results: Pathologic conditions positive for perineural invasion, apical margins, and Gleason score 3 + 4 = 7 were significantly more likely to be ERG-positive than other pathologic conditions (p = 0.0008), suggesting an association between ERG positivity, perineural invasion, apical margins, and Gleason score 3 + 4 = 7 (Firth’s logistic regression: OR 42.565, 95% CI 1.670–1084.847, p = 0.0232). Results of whole-exome and RNA sequencing identified 97 somatic mutations containing common mutated genes. Regulatory network analysis identified NOTCH1, MEF2C, STAT3, LCK, CACNA2D3, PCSK7, MEF2A, PDZD2, TAB1, and ASGR1 as pivotal genes. NOTCH1 appears to function as a hub, because it had the highest node degree and betweenness. NOTCH1 staining was found 8 of 60 specimens (13%), with a significant association between ERG and NOTCH1 positivity (p = 0.001). Conclusions: Evaluating the association between ERG expression and pathologic factors, and identifying the regulatory network and pivotal hub may help to understand the clinical significance of ERG-positive prostate cancer. © 2018, Springer-Verlag GmbH Germany, part of Springer Nature.},
author_keywords={ERG (ETS-related gene);  ETS (erythroblast transformation-specific) gene fusions;  Next-generation sequencing;  Prostate cancer;  TMPRSS2 (transmembrane protease serine 2 gene)},
document_type={Article},
source={Scopus},
}

@ARTICLE{Lau20181138,
author={Lau, H. and Lee, C.K.M. and Nakandala, D. and Shum, P.},
title={An outcome-based process optimization model using fuzzy-based association rules},
journal={Industrial Management and Data Systems},
year={2018},
volume={118},
number={6},
pages={1138-1152},
doi={10.1108/IMDS-08-2017-0347},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051821082&doi=10.1108%2fIMDS-08-2017-0347&partnerID=40&md5=95b7289629665d69d8febc07177ea624},
abstract={Purpose: The purpose of this paper is to propose an outcome-based process optimization model which can be deployed in companies to enhance their business operations, strengthening their competitiveness in the current industrial environment. To validate the approach, a case example has been included to assess the practicality and validity of this approach to be applied in actual environment. Design/methodology/approach: This model embraces two approaches including: fuzzy logic for mimicking the human thinking and decision making mechanism; and data mining association rules approach for optimizing the analyzed knowledge for future decision-making as well as providing a mechanism to apply the obtained knowledge to support the improvement of different types of processes. Findings: The new methodology of the proposed algorithm has been evaluated in a case study and the algorithm shows its potential to determine the primary factors that have a great effect upon the final result of the entire operation comprising a number of processes. In this case example, relevant process parameters have been identified as the important factors causing significant impact on the result of final outcome. Research limitations/implications: The proposed methodology requires the dependence on human knowledge and personal experience to determine the various fuzzy regions of the processes. This can be fairly subjective and even biased. As such, it is advisable that the development of artificial intelligence techniques to support automatic machine learning to derive the fuzzy sets should be promoted to provide more reliable results. Originality/value: Recent study on the relevant topics indicates that an intelligent process optimization approach, which is able to interact seamlessly with the knowledge-based system and extract useful information for process improvement, is still seen as an area that requires more study and investigation. In this research, the process optimization system with an effective process mining algorithm embedded for supporting knowledge discovery is proposed for use to achieve better quality control. © 2018, Emerald Publishing Limited.},
author_keywords={Algorithms;  Association rules;  Data mining;  Fuzzy logic;  Optimization model},
document_type={Article},
source={Scopus},
}

@CONFERENCE{NoAuthor2018,
title={Proceedings - International Computer Software and Applications Conference},
journal={Proceedings - International Computer Software and Applications Conference},
year={2018},
volume={2},
page_count={1911},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055504995&partnerID=40&md5=2e70d6046fc9e289f5750bcaf5ee9158},
abstract={The proceedings contain 136 papers. The topics discussed include: how agile impacts a software corporation: an empirical study; Smart Block: a visual programming environment for SmartThings; improving the smartness of cloud management via machine learning based workload prediction; the implementation of a data-accessing platform built from big data warehouse of electric loads; the integration of shared storages with the CephFS and Rados gateway for big data accessing; the learning effectiveness analysis of java programming with automatic grading system; review of small data learning methods; a deep learning approach for estimating inventory rebalancing demand in bicycle sharing systems; on learning fuel consumption prediction in vehicle clusters; an approach to proposing new business models basing on association rule learning, BP neural network and creative computing; mining sequential patterns to explore users' learning behavior in a visual programming app; predicting decisions of the Philippine supreme court using natural language processing and machine learning; prediction method of blasting vibration by optimized GEP based on Spark; approximation of time-consuming simulation based on generative adversarial network; towards effective generation of synthetic memory references via Markovian models; a load-balanced approach to time efficient resource scheduling in SDN-enabled data center; and interaction with platform games using smartwatches and continuous gesture recognition: a case study.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Mostafa20182816,
author={Mostafa, A.M. and Almutairi, F.A. and Hassan, M.M.},
title={False alarm reduction scheme for database intrusion detection system},
journal={Journal of Theoretical and Applied Information Technology},
year={2018},
volume={96},
number={10},
pages={2816-2825},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048016963&partnerID=40&md5=4718d4d3482dc4a89804b802b99c64c4},
abstract={Database intrusion detection system is considered a mandatory security layer in recent database applications. The detection of intrusions in database applications is mostly based on anomaly methods like access patterns, association rule mining and mining data dependencies between data items. These countermeasures achieve good results in traditional applications but new forms of attacks on computer systems lead to the depreciation of intrusion detection systems due to the high rates of false positive alarms. The goal of this paper is to improve the accuracy of intrusion detection system by reducing false alarms using alert clustering mechanism and system hibernation capabilities. In this paper, a three-stage access control framework is developed for detecting malicious users in database. This framework is embedded with an alert clustering mechanism for reducing false alarms by correlating low-level alerts into one cluster. A post security countermeasure is developed by merging system hibernation capabilities into the developed application. The hibernation mechanism is used for maintaining the availability of data in case of intrusion detection. The experimental results of the proposed algorithm achieve high detection rate with low false positive and low false negative alarms when compared to recent researches in intrusion detection systems. © 2005 – ongoing JATIT & LLS.},
author_keywords={Alert clustering;  Hibernation mechanism;  Intrusion detection system},
document_type={Article},
source={Scopus},
}

@ARTICLE{Yu2018,
author={Yu, W.},
title={Discovering Frequent Movement Paths From Taxi Trajectory Data Using Spatially Embedded Networks and Association Rules},
journal={IEEE Transactions on Intelligent Transportation Systems},
year={2018},
doi={10.1109/TITS.2018.2834573},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047646585&doi=10.1109%2fTITS.2018.2834573&partnerID=40&md5=c961eef6b3f507405bef278b2ac3681f},
abstract={In view of the complex traffic flows, spatial interactions within a city exhibit the properties of dynamics, connectivity, and repeatability. This paper aims at mining spatial-temporal movement patterns from massive taxi trajectory data for discovering the inherent travel flow information within the urban system. Similar to the role of ocean circulation in a marine system, identifying the frequent paths and cycles of the travel flows within a city would be critical for understanding the principles behind the travel flow surfaces. Thus, we propose a multi-level method for the discovery of movement paths by incorporating the techniques of network analysis and association rules. Specifically, the proposed method begins by constructing a directed network on the subdivision of the study region, in which the node with geolocation represents the corresponding cell and the edge with weight represents the travel flow between neighboring cells. The method then adopts an extended label propagation clustering algorithm to identify frequent paths and cycles on the flow network within a specific time interval. Finally, to extract frequent paths during the whole time period, we also develop an association rules mining algorithm by modeling the edges as items and the paths in each time span as transactions. Experiment results demonstrate that our framework is able to effectively mine movement patterns in taxi trajectory data. Our results are expected to provide an avenue for further research, such as transportation planning and urban structure analysis. IEEE},
author_keywords={Clustering algorithms;  Data mining;  data mining;  movement pattern;  Public transportation;  Space exploration;  spatial association rule.;  Taxi trajectory;  Trajectory;  travel pattern;  Urban areas},
document_type={Article in Press},
source={Scopus},
}

@ARTICLE{Zhang2018137,
author={Zhang, M. and Yang, Y. and Ji, Y. and Xie, N. and Shen, F.},
title={Recurrent attention network using spatial-temporal relations for action recognition},
journal={Signal Processing},
year={2018},
volume={145},
pages={137-145},
doi={10.1016/j.sigpro.2017.12.008},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037697297&doi=10.1016%2fj.sigpro.2017.12.008&partnerID=40&md5=4950aacd8e0368f2a70097db51a44a9a},
abstract={Action recognition in videos, which contains many complex and semantic contents, is still a challenging task in computer vision research. In this paper, we propose a novel attention mechanism that leverages the gate system of Long Short Term Memory (LSTM) to compute the attention weights for action recognition. The proposed attention mechanism is embedded in a recurrent attention network that can explore the spatial-temporal relations between different local regions to concentrate important ones. For more accurate attention, we derive a new attention unit from the standard LSTM unit so as how important the local region is only depends on its input gate. Because of exploring spatial-temporal relations and using attention unit, our model can attend more accurately and thus achieve a better action recognition performance. We evaluate our proposed model on three datasets: UCF101, HMDB51 and Hollywood2, and results illustrate that our model outperforms other attention models with significant improvements. © 2017},
author_keywords={Action recognition;  Attention mechanism;  LSTM;  Spatial-temporal relations},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Al-Janabi201837,
author={Al-Janabi, S. and Alwan, E.},
title={Soft Mathematical System to Solve Black Box Problem through Development the FARB Based on Hyperbolic and Polynomial Functions},
journal={Proceedings - International Conference on Developments in eSystems Engineering, DeSE},
year={2018},
pages={37-42},
doi={10.1109/DeSE.2017.23},
art_number={8285794},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054760745&doi=10.1109%2fDeSE.2017.23&partnerID=40&md5=3acd9a2d03fb6978de21bb9c6a9dce95},
abstract={This work attempts to design a method for computer-based mathematical model of multi-parametric datasets that their features are fully-automatic structural and parametric optimization of models. This method has different inputs and one output as a subset of components for the base function F. In addition, several functions in modeling the classified rules are used including 12 polynomials and 6 hyperbolic functions. This work combines the advantage of data mining algorithms and Fuzzy All-Permutation Rule Base (FARB). In order to evaluate the performance of the proposed method, two classifications based on association rules case studies were used in an attempt to design a dynamic mathematical method. The first case study takes the virtual rules which consist of four rules, while in the second case study actual rules are selected. According to the experimental results, not only enhanced accuracy can be achieved by the proposed method, but also it can be used for intelligent data analysis for huge and small datasets. © 2017 IEEE.},
author_keywords={Black Box;  FARB;  Hyperbolic Functions;  Mathematical Model;  Polynomial Functions},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kabli20181,
author={Kabli, F. and Hamou, R.M. and Amine, A.},
title={New classification system for protein sequences},
journal={Proceedings of EDIS 2017 - 1st International Conference on Embedded and Distributed Systems},
year={2018},
volume={2017-December},
pages={1-6},
doi={10.1109/EDIS.2017.8284029},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050349928&doi=10.1109%2fEDIS.2017.8284029&partnerID=40&md5=2a031ab9cd0a8102f588792ef1c1f2e4},
abstract={The Protein classification is an important activity in bioinformatics field. Several techniques have been developed to improve the categories prediction of unclassified protein that serves to predict its function. For this reason, we present a global framework inspired by the knowledge extraction process from biological data based on the association rules. This framework has three main steps: the pre-processing phase consists of extracting the descriptors, we used the N-Gram technique, The second one is devoted to extracting the association rules between the proteins components, we applied the Apriori algorithm; As a third step we selected the relevant rules to classified the unclassified protein. We have tested this classifier on five classes of protein, extracted from the uniprot data bank compared with five methods of classification in WEKA platform, based on the validation tools we obtained satisfied results improve the effectiveness of our protein classifier. © 2017 IEEE.},
author_keywords={Apriori Algorithm;  classification;  N-Gram technique;  protein sequences;  relevant association rules},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Singh20181,
author={Singh, I. and Sareen, S. and Ahuja, H.},
title={Detection of malicious transactions in databases using dynamic sensitivity and weighted rule mining},
journal={Proceedings of 2017 International Conference on Innovations in Information, Embedded and Communication Systems, ICIIECS 2017},
year={2018},
volume={2018-January},
pages={1-8},
doi={10.1109/ICIIECS.2017.8276084},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046972197&doi=10.1109%2fICIIECS.2017.8276084&partnerID=40&md5=e32fc1ef16330fd52053950886bf5347},
abstract={The development of an Intrusion Detection System for Database Security has grown into an undeniable necessity in the past few years. In order to maintain scalability and dynamicity of database systems, detecting privilege abuse is of foremost importance. Most researchers have presented either a static or database dependent solution to the existing problem of Insider Attacks. Our Approach, Dynamic Sensitivity Driven Rule Generation Algorithm (DSDRGA) detects intrusive transactions and therefore safeguards crucial data from modification. Sensitivity of data attributes and the data dependency rules are dynamically determined by mining frequent sequences from normal user data access patterns retrieved from the audit log. The extent of weighted similarity between the mined rules and the incoming transactions is used to classify the transaction as malicious or normal user behavior. DSDRGA gives promising results in the detection of malicious transactions when evaluated on a characteristic banking dataset. © 2017 IEEE.},
author_keywords={Database Intrusion Detection;  Dynamic Sensitivity;  Role Based Access Control;  Weighted Association Rule Mining},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Sakhare20181,
author={Sakhare, A.V. and Kasbe, P.S.},
title={A review on road accident data analysis using data mining techniques},
journal={Proceedings of 2017 International Conference on Innovations in Information, Embedded and Communication Systems, ICIIECS 2017},
year={2018},
volume={2018-January},
pages={1-5},
doi={10.1109/ICIIECS.2017.8275920},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046939420&doi=10.1109%2fICIIECS.2017.8275920&partnerID=40&md5=016b57a2ddb8d8b2ddf95ebb9eaaf36a},
abstract={Road accident analysis plays an important role in transportation system. This paper shows a survey of road accident analysis methods in data mining. In the data mining there is no. of techniques available for clustering and classification, from those techniques k-mean, association rule, SVM, Weka tool was used in previously research for road accident analysis. In our daily life there are no. of accident increases and it is big problem to us because no. of people death and injured for that improve the road transportation system is needed. In this research self organization map (SOM) is used for find a no. of pattern to analysis the road accident data which help to find prediction of accident reasons and improve the accuracy of analysis compare to k-means clustering algorithm. With the help of SOM, clusters are created and analyze them. Self Organizing map method is based on neural network, it is used as an unsupervised learning method. It will help to improve analysis accuracy. © 2017 IEEE.},
author_keywords={accident analysis;  clustering;  Data Mining;  K-mean;  self organizing-map(SOM)},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Nguyen2018661,
author={Nguyen, P.A. and Yang, H.-C. and Xu, R. and Li, Y.-C.},
title={An automated technique to construct a knowledge base of traditional Chinese herbal medicine for cancers: An exploratory study for breast cancer},
journal={Studies in Health Technology and Informatics},
year={2018},
volume={247},
pages={661-665},
doi={10.3233/978-1-61499-852-5-661},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046552179&doi=10.3233%2f978-1-61499-852-5-661&partnerID=40&md5=a151945d7fabe5e6023bb30f229764f4},
abstract={Traditional Chinese Medicine utilization has rapidly increased worldwide. However, there is limited database provides the information of TCM herbs and diseases. The study aims to identify and evaluate the meaningful associations between TCM herbs and breast cancer by using the association rule mining (ARM) techniques. We employed the ARM techniques for 19.9 million TCM prescriptions by using Taiwan National Health Insurance claim database from 1999 to 2013. 364 TCM herbs-breast cancer associations were derived from those prescriptions and were then filtered by their support of 20. Resulting of 296 associations were evaluated by comparing to a gold-standard that was curated information from Chinese-Wikipedia with the following terms, cancer, tumor, malignant. All 14 TCM herbs-breast cancer associations with their confidence of 1% were valid when compared to gold-standard. For other confidences, the statistical results showed consistently with high precisions. We thus succeed to identify the TCM herbs-breast cancer associations with useful techniques. © 2018 European Federation for Medical Informatics (EFMI) and IOS Press.},
author_keywords={Association rule mining;  Cancers;  Traditional Chinese Medicine},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Phu20181213,
author={Phu, V.N. and Ngoc Tran, V.T.},
title={A reformed K-nearest neighbors algorithm for big data sets},
journal={Journal of Computer Science},
year={2018},
volume={14},
number={9},
pages={1213-1225},
doi={10.3844/jcssp.2018.1213.1225},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054590837&doi=10.3844%2fjcssp.2018.1213.1225&partnerID=40&md5=75750655a4907f3372e5cbe8fe7bfb09},
abstract={A Data Mining Has Already Had Many Algorithms Which A K-Nearest Neighbors Algorithm, K-NN, Is A Famous Algorithm For Researchers. K-NN Is Very Effective On Small Data Sets, However It Takes A Lot Of Time To Run On Big Datasets. Today, Data Sets Often Have Millions Of Data Records, Hence, It Is Difficult To Implement K-NN On Big Data. In This Research, We Propose An Improvement To K-NN To Process Big Datasets In A Shortened Execution Time. The Reformed KNearest Neighbors Algorithm (R-K-NN) Can Be Implemented On Large Datasets With Millions Or Even Billions Of Data Records. R-K-NN Is Tested On A Data Set With 500,000 Records. The Execution Time Of R-KNN Is Much Shorter Than That Of K-NN. In Addition, R-K-NN Is Implemented In A Parallel Network System With Hadoop Map (M) And Hadoop Reduce (R). © 2018 Vo Ngoc Phu and Vo Thi Ngoc Tran.},
author_keywords={Association rules;  Cloudera;  Data mining;  Distributed system;  Hadoop map;  Hadoop reduce;  K-Nearest neighbors algorithm;  K-NN;  Parallel network environment},
document_type={Article},
source={Scopus},
}

@ARTICLE{Agapito2018,
author={Agapito, G. and Guzzi, P.H. and Cannataro, M.},
title={Parallel and distributed association rule mining in life science: A novel parallel algorithm to mine genomics data},
journal={Information Sciences},
year={2018},
doi={10.1016/j.ins.2018.07.055},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050698935&doi=10.1016%2fj.ins.2018.07.055&partnerID=40&md5=bbdf2af8bf0b07ff54b2abf4b6e79222},
abstract={Association rule mining (ARM) is largely employed in several scientific areas and application domains, and many different algorithms for learning association rules from databases have been introduced. Despite the presence of many existing algorithms, there is still room for the introduction of novel approaches tailored for novel kinds of datasets. Because often the efficiency of such algorithms depends on the type of analyzed dataset. For instance, classical ARM algorithms present some drawbacks for biological datasets produced by microarray technologies in particular containing Single Nucleotide Polymorphisms (SNPs). In particular classical algorithms require large execution times also with small datasets. Therefore the possibility to improve the performance of such algorithms by leveraging parallel computing is a growing research area. The main contributions of this paper are: a comparison among different sequential, parallels and distributed ARM techniques, and the presentation of a novel ARM algorithm, named Balanced Parallel Association Rule Extractor from SNPs (BPARES), that employs parallel computing and a novel balancing strategy to improve response time. BPARES improves performance without loosing in accuracy as well as it handles more efficiently the available computational power and reduces the memory consumption. © 2018 Elsevier Inc.},
author_keywords={Association rules mining;  Genomics data;  Multi-threading;  Parallel data mining},
document_type={Article in Press},
source={Scopus},
}

@ARTICLE{Afzali2018,
author={Afzali, G.A. and Mohammadi, S.},
title={Privacy preserving big data mining: Association rule hiding using fuzzy logic approach},
journal={IET Information Security},
year={2018},
volume={12},
number={1},
doi={10.1049/iet-ifs.2015.0545},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042217577&doi=10.1049%2fiet-ifs.2015.0545&partnerID=40&md5=b03fb3c74752acde82217a19c5869fd6},
abstract={Recently, privacy preserving data mining has been studied widely. Association rule mining can cause potential threat toward privacy of data. So, association rule hiding techniques are employed to avoid the risk of sensitive knowledge leakage. Many researches have been done on association rule hiding, but most of them focus on proposing algorithms with least side effect for static databases (with no new data entrance), while now the authors confront with streaming data which are continuous data. Furthermore, in the age of big data, it is necessary to optimise existing methods to be executable for large volume of data. In this study, data anonymisation is used to fit the proposed model for big data mining. Besides, special features of big data such as velocity make it necessary to consider each rule as a sensitive association rule with an appropriate membership degree. Furthermore, parallelisation techniques which are embedded in the proposed model, can help to speed up data mining process. © The Institution of Engineering and Technology 2017.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Braun2018642,
author={Braun, P. and Cuzzocrea, A. and Leung, C.K. and Pazdor, A.G.M. and Tanbeer, S.K. and Grasso, G.M.},
title={An innovative framework for supporting frequent pattern mining problems in IoT environments},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10964 LNCS},
pages={642-657},
doi={10.1007/978-3-319-95174-4_49},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049967785&doi=10.1007%2f978-3-319-95174-4_49&partnerID=40&md5=ab7331d088e98c2bfc6d1e18bd875ae0},
abstract={In the current era of big data, high volumes of a wide variety of data of different veracity can be easily generated or collected at a high velocity from rich sources of data include devices from the Internet of Things (IoT). Embedded in these big data are useful information and valuable knowledge. Hence, frequent pattern mining and its related research problem of association rule mining, which aim to discover implicit, previously unknown and potentially useful information and knowledge—in the form of sets of frequently co-occurring items or rules revealing relationships between these frequent sets—from these big data have drawn attention of many researchers. For instance, since introduction of the research problems of association rule mining or frequent pattern mining, numerous information system and engineering approaches have been developed. These include the development of serial algorithms, distributed and parallel algorithms, as well as MapReduce-based big data mining algorithms. These algorithms can be run in local computers, distributed and parallel environments, as well as clusters, grids and clouds. In this paper, we describe some of these algorithms and discuss how to mine frequent patterns or association rules in fogs—i.e., edges of the computing network. © Springer International Publishing AG, part of Springer Nature 2018.},
author_keywords={Association rules;  Big data;  Cloud computing;  Distributed computing;  Edge computing;  Fog computing;  Frequent patterns;  Frequent sets of items;  High performance computing;  Parallel computing},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Bagchi2018143,
author={Bagchi, S.},
title={Formulation of composite discrete measures for estimating uncertainties in probabilistic databases},
journal={Communications in Computer and Information Science},
year={2018},
volume={928},
pages={143-156},
doi={10.1007/978-3-319-99987-6_11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053847927&doi=10.1007%2f978-3-319-99987-6_11&partnerID=40&md5=3f451a0a2884fe20e12794d8b91a728c},
abstract={The probabilistic databases contain large datasets embedded with noise and uncertainties in data association rules and queries. The data identification and interpretation in probabilistic databases require probabilistic models for data clustering and query processing. Thus, the associated probability measures are required to be heterogeneous as well as computable. This paper proposes a formal model of composite discrete measures in metric spaces intended to probabilistic databases. The proposed composite measures are computable and cover real as well as complex spaces. The spaces of discrete measures are constructed on continuous smooth functions. This paper presents construction of the formal model and computational evaluations of discrete measures following different functions having varying linearity and smoothness. Furthermore, a special monotone class of the composite discrete measure is presented using analytical formulation. The condensation measure of uniform contraction map is constructed. The proposed model can be employed to computationally estimate uncertainties in probabilistic databases. © Springer Nature Switzerland AG 2018.},
author_keywords={Measure space;  Metric spaces;  Monotone;  Probabilistic databases;  Probability},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={30th International Conference on Advanced Information Systems Engineering, CAiSE 2018},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10816 LNCS},
page_count={277},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048481882&partnerID=40&md5=17a61a53070c74e5b9df3d16fc6a8915},
abstract={The proceedings contain 37 papers. The special focus in this conference is on Advanced Information Systems Engineering. The topics include: Big data driven software reuse: Feature models and case-based reasoning; using fractal enterprise model for business model innovation; preface; association rules for anomaly detection and root cause analysis in process executions; educating users to formulate questions in Q&A platforms: A scaffold for google sheets; News recommendation with CF-IDF+; model-driven elasticity for cloud resources; fog computing and data as a service: A goal-based modeling approach to enable effective data movements; an ontology-based framework for describing discoverable data services; how much event data is enough? A statistical framework for process discovery; process discovery from low-level event logs; detection and interactive repair of event ordering imperfection in process logs; fusion-based process discovery; on the relationships between decision management and performance measurement; AB testing for process versions with contextual multi-armed bandit algorithms; DMN decision execution on the ethereum blockchain; Shared ledger accounting - Implementing the economic exchange pattern in DL technology; exploring new directions in traceability link recovery in models: The process models case; clinical processes - The killer application for constraint-based process interactions?; formal executable theory of multilevel modeling; An LSH-based model-words-driven product duplicate detection method; a manageable model for experimental research data: An empirical study in the materials sciences; VizDSL: A visual DSL for interactive information visualization; evaluating several design patterns and trends in big data warehousing systems; KAYAK: A framework for just-in-time data preparation in a data lake; embedded cardinality constraints.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={25th International Conference on Web Services, ICWS 2018 Held as Part of the Services Conference Federation, SCF 2018},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10966 LNCS},
page_count={515},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049371860&partnerID=40&md5=11e71f5233b17edf78f11d6005d63425},
abstract={The proceedings contain 32 papers. The special focus in this conference is on Web Services. The topics include: An open access platform for analyzing artistic style using semantic workflows; accelerating training for distributed deep neural networks in mapreduce; large-scale QoS-aware service composition integrating chained dynamic programming and hybrid pruning; supervised web service composition integrating multi-objective QoS optimization and service quantity minimization; selection optimization of bloom filter-based index services in ubiquitous embedded systems; coupled linear and deep nonlinear method for meetup service recommendation; social information services: A service oriented analysis of social media; A RESTful web service for non-overlapping community quality assessment with MPI; classifying quality centrality for source localization in social networks; service bridge: Trans-boundary influence evaluation method of internet; BIS: Bidirectional item similarity for next-item recommendation; RLT: Residual-loop training in collaborative filtering for combining factorization and global-local neighborhood; MF-DMPC: Matrix factorization with dual multiclass preference context for rating prediction; a privacy-preserving semantic annotation framework using online social media; identification for strategically malicious participants; trustworthiness and untrustworthiness inference with group assignment; WED-SQL: An intermediate declarative language for PAIS execution; PARMTRD: Parallel association rules based multiple-topic relationships detection; min-Forest: Fast reachability indexing approach for large-scale graphs on spark platform; Towards smart incident management under human resource constraints for an IoT-BPM hybrid architecture; Modeling time-critical processes with WED-Flow; design of a Secure shield for internet and web-based services using software reflection; big social data as a service: A service composition framework for social information service analysis; Privacy-preserving homomorphic MACs with efficient verification.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Hirano2017612,
author={Hirano, S. and Tsumoto, S.},
title={Frequent temporal pattern mining for medical data based on ranged relations},
journal={IEEE International Conference on Data Mining Workshops, ICDMW},
year={2017},
volume={2017-November},
pages={612-616},
doi={10.1109/ICDMW.2017.87},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044093857&doi=10.1109%2fICDMW.2017.87&partnerID=40&md5=70158158015d6f9a67cef487df7359c4},
abstract={This paper presents a temporal pattern mining method for medical data. It modifies the mining algorithms proposed by Batal et al. to incorporate with ranged relations. Experimental results demonstrate that the proposed method could generate frequent patterns with abstracted time ranges embedded in their temporal relations. © 2017 IEEE.},
author_keywords={Medical data;  Ranged relations;  Temporal data mining},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Vardar20171,
author={Vardar, R. and Keskin, M. and Valitova, E. and Bayrakci, B. and Yildirim, E. and Bor, S.},
title={Effect of alginate in patients with GERD hiatal hernia matters},
journal={Diseases of the Esophagus},
year={2017},
volume={30},
number={10},
pages={1-7},
doi={10.1093/dote/dox039},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042350024&doi=10.1093%2fdote%2fdox039&partnerID=40&md5=6c9ba2d5422a80cd52e90ba2140dceca},
abstract={Alginate-based formulations are frequently used as add-on proton pump inhibitor (PPI) therapy to help control of heartburn and regurgitation. There are limited data regarding the mechanisms and effects of alginate-based formulations. We aimed to evaluate the effects of the sodium alginate intake and its likely temporal relations on intraesophageal reflux events byMII-pH in patients with and without hiatal hernia (HH). Fifty GERD patients (18 with HH, 32 without HH) with heartburn or regurgitation once a week or more common were included. After combined multichannel intraluminal impedance and pH-metry (MII-pH) had been performed, all patients were asked to eat the same standard meal (double cheeseburger, 1 banana, 100 g regular yoghurt, and 200 mL water with total energy value of 744 kcal: 37.6% of carbohydrates, 21.2% of proteins, and 41.2% of lipids) during two consecutive days. On separate random two consecutive days, all patients took 10 mL of sodium alginate (GA; Gaviscon Advance; Reckitt Benckiser Healthcare, Hull, UK) or 10 mL of water, 30 minutes after the refluxogenic meal. After eating refluxogenic meal, patients were examined 12 hour for basal conditions, 1 hour in upright, and 1 hour in supine positions. Alginate significantly decreased acid reflux after intake at the first hour in comparison to water in patients with HH (6.1 vs. 13.7, P = 0.004) and without HH (3.5 vs. 5.5, P = 0.001). Weakly acid reflux were increased at the first hour in patients with HH (3.4 vs. 1.3, P = 0.019) and without HH (1.7 vs. 5, P = 0.02) compared to water. There was no distinctive effect of alginate on the height of proximal migration of reflux events in patients with HH and without HH. Alginate decreases acid reflux events within a limited time period, especially at the first hour both in patients with and without HH. Alginate has no effect on the height of reflux events along the esophagus both in patients with and without HH. © The Authors 2017. Published by Oxford University Press on behalf of International Society for Diseases of the Esophagus. All rights reserved.},
author_keywords={Gastroesophageal reflux disease;  Multichannel intraluminal impedance and pH-metry;  Sodium alginate},
document_type={Article},
source={Scopus},
}

@ARTICLE{Barati2017183,
author={Barati, M. and Bai, Q. and Liu, Q.},
title={Mining semantic association rules from RDF data},
journal={Knowledge-Based Systems},
year={2017},
volume={133},
pages={183-196},
doi={10.1016/j.knosys.2017.07.009},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021971477&doi=10.1016%2fj.knosys.2017.07.009&partnerID=40&md5=8762b7719f9fa7c02aae0a94181c53a9},
abstract={The Semantic Web opens up new opportunities for the data mining research. Semantic Web data is usually represented in the RDF triple format (subject, predicate, object). Large RDF-style Knowledge Bases contain hundreds of millions of RDF triples that represent knowledge in a machine-understandable format. Association rule mining is one of the most effective techniques for detecting frequent patterns. In the context of Semantic Web data mining, most existing methods rely on users intervention that is time-consuming and error-prone due to a large amount of data. Meanwhile, rule quality factors (e.g. support and confidence) usually consider knowledge at the instance-level. Namely, these factors disregard the knowledge embedded at the schema-level. In this paper, we demonstrate that ignoring knowledge encoded at the schema-level negatively impacts the interpretation of discovered rules. We introduce an approach called SWARM (Semantic Web Association Rule Mining) that automatically mines Semantic Association Rules from RDF data. The main achievement of SWARM is to reveal common behavioural patterns associated with knowledge at the instance-level and schema-level. We discuss how to utilize knowledge encoded at the schema-level to add more semantics to the rules. We compare the semantic of rules discovered by SWRAM with one of the latest approaches in this field to show the importance of considering schema-level knowledge. Initial experiments performed on RDF-style Knowledge Bases demonstrate the effectiveness of the proposed approach. © 2017 Elsevier B.V.},
author_keywords={Association rule mining;  Knowledge discovery;  Ontology;  Semantic Web data},
document_type={Article},
source={Scopus},
}

@ARTICLE{Xu20172438,
author={Xu, F. and Shi, Y. and Deng, M. and Gong, J.-Y. and Liu, Q.-L. and Jin, R.},
title={Multi-scale regionalization based mining of spatio-temporal teleconnection patterns between anomalous sea and land climate events},
journal={Journal of Central South University},
year={2017},
volume={24},
number={10},
pages={2438-2448},
doi={10.1007/s11771-017-3655-x},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034431152&doi=10.1007%2fs11771-017-3655-x&partnerID=40&md5=ad171f5e1f29cff8d845cbb9b56f07a2},
abstract={Climate sequences can be applied to defining sensitive climate zones, and then the mining of spatio-temporal teleconnection patterns is useful for learning from the past and preparing for the future. However, scale-dependency in this kind of pattern is still not well handled by existing work. Therefore, in this study, the multi-scale regionalization is embedded into the spatio-temporal teleconnection pattern mining between anomalous sea and land climatic events. A modified scale-space clustering algorithm is first developed to group climate sequences into multi-scale climate zones. Then, scale variance analysis method is employed to identify climate zones at characteristic scales, indicating the main characteristics of geographical phenomena. Finally, by using the climate zones identified at characteristic scales, a time association rule mining algorithm based on sliding time windows is employed to discover spatio-temporal teleconnection patterns. Experiments on sea surface temperature, sea level pressure, land precipitation and land temperature datasets show that many patterns obtained by the multi-scale approach are coincident with prior knowledge, indicating that this method is effective and reasonable. In addition, some unknown teleconnection patterns discovered from the multi-scale approach can be further used to guide the prediction of land climate. © 2017, Central South University Press and Springer-Verlag GmbH Germany, part of Springer Nature.},
author_keywords={anomalous climatic events;  climate sequences;  multi-scale regionalization;  spatio-temporal teleconnection patterns},
document_type={Article},
source={Scopus},
}

@CONFERENCE{NoAuthor2017,
title={Journal of Physics: Conference Series},
journal={Journal of Physics: Conference Series},
year={2017},
volume={892},
number={1},
page_count={191},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030154868&partnerID=40&md5=4c362927971f536d0bc819ae48e7f31d},
abstract={The proceedings contain 19 papers. The topics discussed include: an integrated study of surface roughness in EDM process using regression analysis and GSO algorithm; machining parameters optimization using hybrid firefly algorithm and particle swarm optimization; towards an enhanced aspect-based contradiction detection approach for online review content; an element search ant colony technique for solving virtual machine placement problem; association rule-based predictive model for machine failure in industrial internet of things; replacing missing values using trustworthy data values from web data sources; selection input output by restriction using DEA models based on a fuzzy Delphi approach and expert information; towards an enhancement of organizational information security through threat factor profiling (TFP) model; appropriation of social media for fostering effective tacit knowledge sharing: developing conceptual model; the impacts of demographic variables on technological and contextual challenges of e-learning implementation; the awareness and challenges of cloud computing adoption on tertiary education in Malaysia; similarity measure for molecular structure: a brief review; and handling a small dataset problem in prediction model by employ artificial data generation approach: a review.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Zheng20171469,
author={Zheng, K. and Gu, D. and Fang, F. and Wang, Y. and Liu, H. and Zhao, W. and Zhang, M. and Li, Q.},
title={Visualization of spatio-temporal relations in movement event using multi-view},
journal={International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
year={2017},
volume={42},
number={2W7},
pages={1469-1476},
doi={10.5194/isprs-archives-XLII-2-W7-1469-2017},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030983348&doi=10.5194%2fisprs-archives-XLII-2-W7-1469-2017&partnerID=40&md5=79e8fa752f578b3f4639c76579cc748c},
abstract={Spatio-temporal relations among movement events extracted from temporally varying trajectory data can provide useful information about the evolution of individual or collective movers, as well as their interactions with their spatial and temporal contexts. However, the pure statistical tools commonly used by analysts pose many difficulties, due to the large number of attributes embedded in multiscale and multi-semantic trajectory data. The need for models that operate at multiple scales to search for relations at different locations within time and space, as well as intuitively interpret what these relations mean, also presents challenges. Since analysts do not know where or when these relevant spatio-temporal relations might emerge, these models must compute statistical summaries of multiple attributes at different granularities. In this paper, we propose a multi-view approach to visualize the spatio-temporal relations among movement events. We describe a method for visualizing movement events and spatio-temporal relations that uses multiple displays. A visual interface is presented, and the user can interactively select or filter spatial and temporal extents to guide the knowledge discovery process. We also demonstrate how this approach can help analysts to derive and explain the spatiotemporal relations of movement events from taxi trajectory data. © Authors 2017. CC BY 4.0 License.},
author_keywords={Movement events;  Spatio-temporal relations;  Taxi;  Trajectory;  Visual exploration;  Visualization},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Jamil2017176,
author={Jamil, A. and Salam, A. and Amin, F.},
title={Performance evaluation of top-k sequential mining methods on synthetic and real datasets},
journal={International Journal of Advanced Computer Research},
year={2017},
volume={7},
number={32},
pages={176-184},
doi={10.19101/IJACR.2017.732004},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044435859&doi=10.19101%2fIJACR.2017.732004&partnerID=40&md5=27e64c0405f9b87fd0a60130d70b5b85},
abstract={Discovering sequential pattern from a large sequence database is an important problem in the field of sequential pattern mining, which is the well-known data mining technique. Several articles have surveyed the field of sequential pattern mining over the past few years. In those papers major focus was on improving the efficiency of algorithms by employing different techniques. However, the researchers paid less attention to consider the characteristics of the underlying data that the algorithm uses. It is very less investigated. The properties of data incredibly affect the execution of data mining algorithms. This study complemented the top-k sequential pattern mining field by providing further in depth analysis with respect to data properties and characteristics. The performance of top-k sequential pattern mining (TKS) with top-k closed sequential pattern mining (TSP), the state-of-the-art algorithm for top-k sequential pattern mining were evaluated both on synthetic and real databases. Experiments were carried out on real and synthetic datasets having varied characteristics. The impact of different parameters was investigated against the running time and memory usage analysis of each algorithm. Extensive experiments show that TKS and TSP have certain advantages and disadvantages of different types of data. Furthermore, due to the continuous addition of large amounts of data in the databases, the idea of sequential pattern mining (SPAM) is becoming popular. Various algorithms have been developed that are used for mining the sequential patterns in the data. These algorithms have proved to be more effective for smaller databases, but when the size of the database increased, their performance may decline. Hence these methods have to be amended in order to perform the mining processes in a more efficient way. © 2017 ACCENTS.},
author_keywords={Association rule mining;  Data mining;  Pattern discovery;  Sequential pattern mining;  Top-k},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sethi20173652,
author={Sethi, K.K. and Ramesh, D.},
title={HFIM: a Spark-based hybrid frequent itemset mining algorithm for big data processing},
journal={Journal of Supercomputing},
year={2017},
volume={73},
number={8},
pages={3652-3668},
doi={10.1007/s11227-017-1963-4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010933931&doi=10.1007%2fs11227-017-1963-4&partnerID=40&md5=0f15c27c3e097771523505441c3b47ee},
abstract={Frequent itemset mining is one of the data mining techniques applied to discover frequent patterns, used in prediction, association rule mining, classification, etc. Apriori algorithm is an iterative algorithm, which is used to find frequent itemsets from transactional dataset. It scans complete dataset in each iteration to generate the large frequent itemsets of different cardinality, which seems better for small data but not feasible for big data. The MapReduce framework provides the distributed environment to run the Apriori on big transactional data. However, MapReduce is not suitable for iterative process and declines the performance. We introduce a novel algorithm named Hybrid Frequent Itemset Mining (HFIM), which utilizes the vertical layout of dataset to solve the problem of scanning the dataset in each iteration. Vertical dataset carries information to find support of each itemsets. Moreover, we also include some enhancements to reduce number of candidate itemsets. The proposed algorithm is implemented over Spark framework, which incorporates the concept of resilient distributed datasets and performs in-memory processing to optimize the execution time of operation. We compare the performance of HFIM with another Spark-based implementation of Apriori algorithm for various datasets. Experimental results show that the HFIM performs better in terms of execution time and space consumption. © 2017, Springer Science+Business Media New York.},
author_keywords={Apache Spark;  Apriori algorithm;  Big data;  Frequent pattern mining},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Bhosale20171302,
author={Bhosale, M. and Ghorpade, T. and Shedge, R.},
title={On demand recommendation using association rule mining approach},
journal={International Conference on Signal Processing, Communication, Power and Embedded System, SCOPES 2016 - Proceedings},
year={2017},
pages={1302-1306},
doi={10.1109/SCOPES.2016.7955650},
art_number={7955650},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025169913&doi=10.1109%2fSCOPES.2016.7955650&partnerID=40&md5=0bed2e8538b7b8f48e7e6ae6a60e256a},
abstract={In these day, as the e-commerce industry is growing and becoming complex, everyone uses online websites for getting reviews and giving the reviews on the website in the form of comments. This comment varies from worst level to best level. So in order to categorize these comments or to predict the best outcome among the posted comments recommendation is needed there is a need for recommendation system. Collaborative filtering is currently most widely used approach to build recommendation system. It require users to express opinions on items and then they collect opinions and recommend items based on peoples opinions similarity. Those who agree most are the contributors. Recommendation system applies information retrieval technique to select online information relevant to a given user. We proposed hybrid recommendation system, where we are considering external feedback of users to recommend cars in market. we are considering technical words related to car in the data-set itself, so that it will be easy for categorization of car and gives rating to a car. In proposed system recommendation of all users are combined and this recommendation are used to categorized the users region wise, with the help of region data-set. Also used Association rule mining for finding On-demand car in market which gives faster result for large number of data-set. © 2016 IEEE.},
author_keywords={Association Rule mining;  Collaborative Filtering;  Feedback analysis;  Multiple Parameter},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lynden2017,
author={Lynden, S.},
title={Analysis of Semantic URLs to Support Automated Linking of Structured Data on theWeb},
journal={ACM International Conference Proceeding Series},
year={2017},
volume={Part F129475},
doi={10.1145/3102254.3102265},
art_number={a13},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028341642&doi=10.1145%2f3102254.3102265&partnerID=40&md5=5dcfb26848d4327c7b0add66f29508ad},
abstract={A growing amount of structured data can be found embedded in web pages using formats such as RDFa, JSON-LD and Microdata. Although such data is indexed by search engines and sometimes replicated in centralised knowledge bases, application scenarios exist in which there is a need to discover such data on-The-fly, for example when using the follow-your-nose principle of accessing Linked Open Data, or in applications where the velocity at which data changes can result in centralised repositories being out of date. In this paper we demonstrate two complementary techniques for aiding such applications by analysing URLs. Firstly, we demonstrate that machine learning can be of benefit in predicting, from previously encountered URLs, the likelihood of encountering structured data in an unseen URL. This can be applied within applications that encounter large number of possible URLs to dereference, and must implement some priority scheme to choose relevant URLs. Secondly, we demonstrate that association rule mining can be of use in linking existing resources in a knowledge base, such as DBpedia, to URLs that follow common schemes, such as Semantic (search engine friendly) URLs. © 2017 ACM.},
author_keywords={Linked data;  Semantic URLs;  Structured data},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Pal2017124,
author={Pal, K. and Adepu, S. and Goh, J.},
title={Effectiveness of association rules mining for invariants generation in cyber-physical systems},
journal={Proceedings of IEEE International Symposium on High Assurance Systems Engineering},
year={2017},
pages={124-127},
doi={10.1109/HASE.2017.21},
art_number={7911883},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019188660&doi=10.1109%2fHASE.2017.21&partnerID=40&md5=e39712044935e711841a4f5642d95001},
abstract={Cyber-Physical Systems (CPS), which integrate controls, computing and physical processes are critical infrastructures of any country. They are becoming more vulnerable to cyber attacks due to an increase in computing and network facilities. The increase of monitoring network protocols increases the chances of being attacked. Once an attacker is able to cross the network intrusion detection mechanisms, he can affect the physical operations of the system which may lead to physical damages of components and/or a disaster. Some researchers used constraints of physical processes known as invariants to monitor the system in order to detect cyber attacks or failures. However, invariants generation is lacking in automation. This paper presents a novel method to identify invariants automatically using association rules mining. Through this technique, we show that it is possible to generate a number of invariants that are sometimes hidden from the design layout. Our preliminary study on a secure water treatment plant suggests that this approach is promising. © 2017 IEEE.},
author_keywords={Artificial Intelligence;  Association Rules Mining;  Attack Detection;  Cyber attacks;  Cyber Physical System;  Cyber Security;  Secure Water Treatment testbed},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{LeCaillec2017333,
author={Le Caillec, J.-M. and Itani, A. and Guriot, D. and Rakotondratsimba, Y.},
title={Stock Picking by Probability-Possibility Approaches},
journal={IEEE Transactions on Fuzzy Systems},
year={2017},
volume={25},
number={2},
pages={333-349},
doi={10.1109/TFUZZ.2016.2574921},
art_number={7482672},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018528058&doi=10.1109%2fTFUZZ.2016.2574921&partnerID=40&md5=5f897a003ae0c45af46668d560432347},
abstract={This paper presents a performance evaluation of stock picking by merging several technical indicators. Several fusion operators have been proposed either in the probabilistic or in the possibilistic framework. The latter fuzzy framework has been introduced to manage the uncertain information embedded in financial time series due to human biases as studied by behavioral finance. Performances of portfolio resulting from the proposed systems are evaluated according to cumulative returns but also through a risk analysis point of view (Sharpe ratio). Two fusion mechanisms (one probabilistic, one possibilistic) aiming at discriminating common information from merged technical indicators, produce the higher portfolio performances. It also appears that selecting specific technical indicators affects the overall performances of the proposed stock picking systems. Indeed, studying the technical indicators selection through a shared/nonshared information point of view reveals that possibilistic framework is more robust to redundant sources than probabilistic framework. Effects of some parameters used in the fusion algorithms (amount of assets, window length analysis, ⋯ are also investigated. Results from all these tests clearly show the high potentiality of technical indicators fusion to improve portfolio performances. However, these first promising results have to be further inspected within wider contexts, as discussed at the end of the paper. © 1993-2012 IEEE.},
author_keywords={Association rules;  economic forecasting;  forecast uncertainty;  fuzzy sets;  hybrid intelligent systems},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Palomba20178,
author={Palomba, F. and Oliveto, R. and De Lucia, A.},
title={Investigating code smell co-occurrences using association rule learning: A replicated study},
journal={MaLTeSQuE 2017 - IEEE International Workshop on Machine Learning Techniques for Software Quality Evaluation, co-located with SANER 2017},
year={2017},
pages={8-13},
doi={10.1109/MALTESQUE.2017.7882010},
art_number={7882010},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018335521&doi=10.1109%2fMALTESQUE.2017.7882010&partnerID=40&md5=a6a21b4f125c8915806da549565f8ca7},
abstract={Previous research demonstrated how code smells (i.e., symptoms of the presence of poor design or implementation choices) threat software maintainability. Moreover, some studies showed that their interaction has a stronger negative impact on the ability of developers to comprehend and enhance the source code when compared to cases when a single code smell instance affects a code element (i.e., a class or a method). While such studies analyzed the effect of the co-presence of more smells from the developers' perspective, a little knowledge regarding which code smell types tend to co-occur in the source code is currently available. Indeed, previous papers on smell co-occurrence have been conducted on a small number of code smell types or on small datasets, thus possibly missing important relationships. To corroborate and possibly enlarge the knowledge on the phenomenon, in this paper we provide a large-scale replication of previous studies, taking into account 13 code smell types on a dataset composed of 395 releases of 30 software systems. Code smell co-occurrences have been captured by using association rule mining, an unsupervised learning technique able to discover frequent relationships in a dataset. The results highlighted some expected relationships, but also shed light on co-occurrences missed by previous research in the field. © 2017 IEEE.},
author_keywords={Association Rule Mining;  Code Smells;  Empirical Studies},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Shankar20171025,
author={Shankar, S.K. and Kaur, A.},
title={Constraint data mining using apriori algorithm with and operation},
journal={2016 IEEE International Conference on Recent Trends in Electronics, Information and Communication Technology, RTEICT 2016 - Proceedings},
year={2017},
pages={1025-1029},
doi={10.1109/RTEICT.2016.7807985},
art_number={7807985},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015064113&doi=10.1109%2fRTEICT.2016.7807985&partnerID=40&md5=4ad561e6990ec478f15db41df1467b84},
abstract={Data mining is one of the most important steps in knowledge discovery. Apriori algorithm is the most used one in this process. The major drawback with Apriori algorithm is of time and space. It generates numerous uninteresting itemsets which lead to generate various rules which are of completely of no use. The two factors considered for association rules generation are Minimum Support Threshold and Minimum Confidence Threshold. However, constraint mining reduces these two limitations of Apriori algorithm to a considerable extent. This paper uses constraint mining and AND operation between MST and MCT to prune itemsets generated in each iteration. The overall performance has been increased and simulated in this paper through various figures from simulation result. © 2016 IEEE.},
author_keywords={Apriori algorithm;  Constrained data mining;  Constraint data mining;  Data mining;  MCT;  MST},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Jia2017166,
author={Jia, K. and Liu, H.},
title={An improved FP-growth algorithm based on SOM partition},
journal={Communications in Computer and Information Science},
year={2017},
volume={727},
pages={166-178},
doi={10.1007/978-981-10-6385-5_15},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030031918&doi=10.1007%2f978-981-10-6385-5_15&partnerID=40&md5=d67591f97572ef9f94d33f792d8adf20},
abstract={FP-growth algorithm is an algorithm for mining association rules without generating candidate sets. It has high practical value in many fields. However, it is a memory resident algorithm, and can only handle small data sets. It seems powerless when dealing with massive data sets. This paper improves the FP-growth algorithm. The core idea of the improved algorithm is to partition massive data set into small data sets, which would be dealt with separately. Firstly, systematic sampling methods are used to extract representative samples from large data sets, and these samples are used to make SOM (Self-organizing Map) cluster analysis. Then, the large data set is partitioned into several subsets according to the cluster results. Lastly, FP-growth algorithm is executed in each subset, and association rules are mined. The experimental result shows that the improved algorithm reduces the memory consumption, and shortens the time of data mining. The processing capacity and efficiency of massive data is enhanced by the improved algorithm. © 2017, Springer Nature Singapore Pte Ltd.},
author_keywords={Cluster;  Data mining;  FP-growth;  Partition;  SOM},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Jia2017,
author={Jia, X. and Liu, S. and Powers, D. and Cardiff, B.},
title={A multi-layer fusion-based facial expression recognition approach with optimal weighted AUs},
journal={Applied Sciences (Switzerland)},
year={2017},
volume={7},
number={2},
doi={10.3390/app7020112},
art_number={112},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032070109&doi=10.3390%2fapp7020112&partnerID=40&md5=ae6802be6680b0f335b9c65a193bdb61},
abstract={Affective computing is an increasingly important outgrowth of Artificial Intelligence, which is intended to deal with rich and subjective human communication. In view of the complexity of affective expression, discriminative feature extraction and corresponding high-performance classifier selection are still a big challenge. Specific features/classifiers display different performance in different datasets. There has currently been no consensus in the literature that any expression feature or classifier is always good in all cases. Although the recently updated deep learning algorithm, which uses learning deep feature instead of manual construction, appears in the expression recognition research, the limitation of training samples is still an obstacle of practical application. In this paper, we aim to find an effective solution based on a fusion and association learning strategy with typical manual features and classifiers. Taking these typical features and classifiers in facial expression area as a basis, we fully analyse their fusion performance. Meanwhile, to emphasize the major attributions of affective computing, we select facial expression relative Action Units (AUs) as basic components. In addition, we employ association rules to mine the relationships between AUs and facial expressions. Based on a comprehensive analysis from different perspectives, we propose a novel facial expression recognition approach that uses multiple features and multiple classifiers embedded into a stacking framework based on AUs. Extensive experiments on two public datasets show that our proposed multi-layer fusion system based on optimal AUs weighting has gained dramatic improvements on facial expression recognition in comparison to an individual feature/classifier and some state-of-the-art methods, including the recent deep learning based expression recognition one. © 2017 by the authors.},
author_keywords={Action units (AUs);  Association rules;  Facial expression recognition;  Feature fusion;  Multi-layer ensemble},
document_type={Article},
source={Scopus},
}

@ARTICLE{NoAuthor20171,
title={1st International Conference on Smart Computing and Communication, SmartCom 2016},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10135 LNCS},
pages={1-588},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010641644&partnerID=40&md5=ded4d645478044a93e71d1af43d3a697},
abstract={The proceedings contain 59 papers. The special focus in this conference is on Smart Computing and Communication. The topics include: Cost reduction for data allocation in heterogenous cloud computing using dynamic programming; minimizing bank conflict delay for real-time embedded multicore systems via bank mapping; a hybrid algorithm based on particle swarm optimization and ant colony optimization algorithm; understanding networking capacity management in cloud computing; cloud learning community of engineering drawing; energy saving method for on-chip data bus based on bit switching activity perception with multi-encoding; a novel PSO based task scheduling algorithm for multi-core systems; artificial bee colony algorithm with hierarchical groups for global numerical optimization; an buffering optimization algorithm for cooperative mobile service; SDN protocol analysis with process algebra method; unsupervised pre training classifier based on restricted Boltzmann machine with imbalanced data; a secure homomorphic encryption algorithm over integers for data privacy protection in clouds; big data management the mass weather logs; application of a parallel FSM parsing algorithm for web engines; predicting the change of stock market index based on social media analysis; bug analysis of android applications based on JPF; a hybrid algorithm of extreme learning machine and sparse auto- encoder; bank card and id card number recognition in android financial app; mining association rules from a dynamic probabilistic numerical dataset using estimated-frequent uncertain-itemsets and an optimized scheme of Mel frequency cepstral coefficient for multi-sensor sign language recognition.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Kamepalli2016265,
author={Kamepalli, S. and Kurra, R.S.R. and Sundara Krishna, Y.K.},
title={A novel top-K infrequent mining technique on complex distributed market databases},
journal={Journal of Theoretical and Applied Information Technology},
year={2016},
volume={92},
number={2},
pages={265-275},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994104343&partnerID=40&md5=f72313bb8e0d31577d274af74fc234c6},
abstract={Infrequent association rule mining is one of the essential tasks in data mining research to find rare items on complex data set. Also, most of the traditional models focus on finding negative association rules based on different association measures. However, finding relational infrequent patterns from the large number of candidate sets is still an open problem in the distributed market analysis. Traditional infrequent mining models are mainly depending on quantitative attributes, limited data size and Boolean datasets. In any distributed environment, as the size and complexity of the market data increases, it is difficult to find the sparsity issue from the positive association rules. In this proposed approach a novel infrequent association mining algorithm was implemented to find the topmost relational infrequent patterns from the complex market dataset. Experimental outcomes prove that the proposed model extracts high quality, infrequent patterns compared to conventional infrequent rule mining techniques. © 2005-2016 JATIT & LLS. All rights reserved.},
author_keywords={Complex data;  Data sparsity;  Infrequent association rules;  Quantitative association rules;  Rank correlation},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Chemweno2016,
author={Chemweno, P. and Pintelon, L. and Jongers, L. and Muchiri, P.},
title={I-RCAM: Intelligent expert system for root cause analysis in maintenance decision making},
journal={2016 IEEE International Conference on Prognostics and Health Management, ICPHM 2016},
year={2016},
doi={10.1109/ICPHM.2016.7542830},
art_number={7542830},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985961623&doi=10.1109%2fICPHM.2016.7542830&partnerID=40&md5=7daf5c1543be14942fdc4283c0b50620},
abstract={The increasing adoption of maintenance information management systems for maintenance decision support by industry has facilitated the collection of large volumes of maintenance data. Apart from enhancing maintenance decision support in aspects such as task planning or resource allocation, the data could assist decision makers identify the focal root causes of recurrent equipment failures. In this way, more effective strategies may be formulated and targeted at these focal causes. Despite the increased adoption of maintenance information systems and, as such, availability of maintenance data few techniques so far developed leverage on the maintenance data for decision support in root cause analysis. A particular focus in this regard relates to application of techniques for data mining such as association rule mining. In particular, association rule mining is attractive in the sense of analyzing failure associations embedded in the maintenance data. Thus, this study proposes a methodology for enhancing decision support for root cause analysis in maintenance decision making. The methodology leverages on two association rule mining algorithms - Apriori and Predictive Apriori. Moreover, the methodology incorporates a data standardization step, whereof standard terms and vocabulary are adopted from the ISO 14224 and used for standardizing the equipment failure descriptions. Thereafter, the standardized descriptions are applied as input to an association rule mining framework from which important failure associations are extracted and validated by experts for relevancy. After which, the extracted failure associations are used to generate causal maps, and from the maps, the focal root causes of the equipment failure are identified. The added value of the proposed methodology is demonstrated in the application case of thermal power plant maintenance data. © 2016 IEEE.},
author_keywords={Association rule mining;  Causal mapping;  Decision support;  Expert system;  Maintenance data;  Root cause analysis},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Dao2016248,
author={Dao, T.H.D. and Thill, J.-C.},
title={The SpatialARMED Framework: Handling Complex Spatial Components in Spatial Association Rule Mining},
journal={Geographical Analysis},
year={2016},
volume={48},
number={3},
pages={248-274},
doi={10.1111/gean.12094},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957712845&doi=10.1111%2fgean.12094&partnerID=40&md5=d4abe99ce6bf7296375dd1082972e66d},
abstract={Recent research has identified spatial association rule (SAR) mining as a promising technique for geographic pattern mining and knowledge discovery. Nevertheless, important spatial components embedded in the studied phenomenon, in particular complex spatial functional relations such as neighborhood effects and spatial spillover effects have largely been neglected. This article unravels this specific problem to enhance the effective application of SAR mining practices in spatial data analytics. The main discussion focuses on the specification of complex spatial components by means of spatial dependence properties of the data and on how to integrate them in the process of SAR mining. A comprehensive framework dubbed SpatialARMED is proposed for the effective extraction of spatial patterns. The framework is then showcased through its application to crime analysis. © 2016 The Ohio State University},
document_type={Article},
source={Scopus},
}

@ARTICLE{Singh20162666,
author={Singh, G. and Chen, T.A. and Robucci, R. and Patel, C. and Banerjee, N.},
title={Distratto: Impaired driving detection using textile sensors},
journal={IEEE Sensors Journal},
year={2016},
volume={16},
number={8},
pages={2666-2673},
doi={10.1109/JSEN.2015.2491225},
art_number={7299255},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962013868&doi=10.1109%2fJSEN.2015.2491225&partnerID=40&md5=19abd69f9307bcc689d015d790798bbd},
abstract={Statistical data show that the driving-related accidents and human casualties caused by vehicles are on the rise in the U.S. and globally. Most of these accidents are cause by impaired or distracted driving. Existing systems that detect impaired driving use cameras that perform eye and head tracking and do not capture full-body movements that are indicative of dangerous driving. To address this problem, we present, distratto, a system that uses capacitive textile sensors embedded into car seats, headrests, and arm rests to capture whole body motion. The system also uses inertial and GPS sensors for determining vehicle speed and turns. Using a combination of these sensors and a tiered signal processing algorithm, we infer attributes that are indicative of impaired driving. We have developed a fully functional prototype of distratto that we evaluate in a real vehicle environment. We show that our system can detect impaired driving instances and driver movements with high accuracy. © 2015 IEEE.},
author_keywords={Accident prevention;  Association rules;  Data mining;  Pervasive computing;  Road accidents;  Sensor fusion;  Transportation},
document_type={Article},
source={Scopus},
}

@ARTICLE{Afzali201670,
author={Afzali, G.A. and Mohammadi, S.},
title={Privacy preserving big data mining: Association rule hiding},
journal={Journal of Information Systems and Telecommunication},
year={2016},
volume={4},
number={2},
pages={70-77},
doi={10.7508/jist.2016.02.001},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020381448&doi=10.7508%2fjist.2016.02.001&partnerID=40&md5=c2797d7104d5c8d21719f3f37a2efddd},
abstract={Data repositories contain sensitive information which must be protected from unauthorized access. Existing data mining techniques can be considered as a privacy threat to sensitive data. Association rule mining is one of the utmost data mining techniques which tries to cover relationships between seemingly unrelated data in a data base.. Association rule hiding is a research area in privacy preserving data mining (PPDM) which addresses a solution for hiding sensitive rules within the data problem. Many researches have be done in this area, but most of them focus on reducing undesired side effect of deleting sensitive association rules in static databases. However, in the age of big data, we confront with dynamic data bases with new data entrance at any time. So, most of existing techniques would not be practical and must be updated in order to be appropriate for these huge volume data bases. In this paper, data anonymization technique is used for association rule hiding, while parallelization and scalability features are also embedded in the proposed model, in order to speed up big data mining process. In this way, instead of removing some instances of an existing important association rule, generalization is used to anonymize items in appropriate level. So, if necessary, we can update important association rules based on the new data entrances. We have conducted some experiments using three datasets in order to evaluate performance of the proposed model in comparison with Max-Min2 and HSCRIL. Experimental results show that the information loss of the proposed model is less than existing researches in this area and this model can be executed in a parallel manner for less execution time.},
author_keywords={Anonymization;  Association rule;  Big data;  Data mining;  Privacy preserving},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Karthik2015,
author={Karthik, K.},
title={Key search and adaptation based on association rules for backward secrecy},
journal={2015 IEEE International Workshop on Information Forensics and Security, WIFS 2015 - Proceedings},
year={2015},
doi={10.1109/WIFS.2015.7368582},
art_number={7368582},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964794728&doi=10.1109%2fWIFS.2015.7368582&partnerID=40&md5=7fa1cc130c2b45785430bc7ad6569928},
abstract={Static storage of decryption keys in RFID tags creates a security issue particularly when some of these tags are compromised. To address this problem, a framework is proposed in which these tags search and compute decryption keys based on specific intrinsic association rules embedded in the tags, which feed on publicly known broadcast messages transmitted by the centre. This association rule is nothing but a circular linked list which connects a set of T tokens, in some random order. To facilitate backward secrecy, we also propose a rule adaptation methodology based on random deletions within this circular linked list triggered by random numbers, sent by the centre. We have shown theoretically that the search space for tags in possession of the actual keys is linear in the number of tokens contained in the association rule i.e. O(T ), while the search space for eavesdropping tags increases considerably to O(Tr), where r is centre-defined as the length of the footprint, within a circular linked list. Tradeoffs which involve balancing the extent of backward secrecy with network lifetime, are discussed. © 2015 IEEE.},
author_keywords={Association rule;  Backward secrecy;  Broadcast messages;  Decryption key;  Key search and computation;  RFID;  Rule adaptation;  Symmetric key},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Heidari2015,
author={Heidari, M.},
title={Recurrent Fuzzy Wavelet Neural Network to control a PCV},
journal={Indian Journal of Science and Technology},
year={2015},
volume={8},
number={36},
doi={10.17485/ijst/2015/v8i36/53072},
art_number={53072},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961916420&doi=10.17485%2fijst%2f2015%2fv8i36%2f53072&partnerID=40&md5=a61504dc113ddd2b696866412eca17bf},
abstract={Pneumatic Control Valves (PCV) are used in the process industries. In this paper, a Recurrent Fuzzy Wavelet Neural Network (RFWNN) is constructed by using Recurrent Wavelet Neural Network (RWNN). In RWNN, temporal relations are embedded in the network by adding feedback connections on the first layer of the network, and wavelet basis n is used as fuzzy membership function. The proposed method is applied on a PCV. P, PI and PID controllers are also employed For comparison. Bondgraph method has been utilized to model the control valve, so as to compare the response characteristics of valve. Simulation results have been made for four controllers.},
author_keywords={Bondgraph;  Control Valve;  Recurrent Fuzzy Neural Network},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhu20155140,
author={Zhu, G. and Wang, J. and Zhao, C. and Lu, H.},
title={Weighted part context learning for visual tracking},
journal={IEEE Transactions on Image Processing},
year={2015},
volume={24},
number={12},
pages={5140-5151},
doi={10.1109/TIP.2015.2479460},
art_number={7270313},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944044433&doi=10.1109%2fTIP.2015.2479460&partnerID=40&md5=0d67697cd33c37d32799a0d794cf4648},
abstract={Context information is widely used in computer vision for tracking arbitrary objects. Most of the existing studies focus on how to distinguish the object of interest from background or how to use keypoint-based supporters as their auxiliary information to assist them in tracking. However, in most cases, how to discover and represent both the intrinsic properties inside the object and the surrounding context is still an open problem. In this paper, we propose a unified context learning framework that can effectively capture spatiotemporal relations, prior knowledge, and motion consistency to enhance tracker's performance. The proposed weighted part context tracker (WPCT) consists of an appearance model, an internal relation model, and a context relation model. The appearance model represents the appearances of the object and the parts. The internal relation model utilizes the parts inside the object to directly describe the spatiotemporal structure property, while the context relation model takes advantage of the latent intersection between the object and background regions. Then, the three models are embedded in a max-margin structured learning framework. Furthermore, prior label distribution is added, which can effectively exploit the spatial prior knowledge for learning the classifier and inferring the object state in the tracking process. Meanwhile, we define online update functions to decide when to update WPCT, as well as how to reweight the parts. Extensive experiments and comparisons with the state of the arts demonstrate the effectiveness of the proposed method. © 1992-2012 IEEE.},
author_keywords={Part Context model;  Structure Leaning;  Visual Tracking},
document_type={Article},
source={Scopus},
}

@ARTICLE{Karimi-Majd2015421,
author={Karimi-Majd, A.-M. and Mahootchi, M.},
title={A new data mining methodology for generating new service ideas},
journal={Information Systems and e-Business Management},
year={2015},
volume={13},
number={3},
pages={421-443},
doi={10.1007/s10257-014-0267-y},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938421707&doi=10.1007%2fs10257-014-0267-y&partnerID=40&md5=cb39a36752d547b140952aad7afbbf95},
abstract={To survive in today’s market, decision makers including investors and their managerial teams should continuously attempt to realize the customers’ unspoken needs and requirements by discovering their behavioral patterns. Discovering customers’ patterns puts these decision makers in a better position in which higher qualified services can be designed and provided. Association rule mining is a well-known approach to discover these patterns. Although extracted rules could express customers’ behaviors in an easy-to-understand way, the number of rules in real applications could be problematic. Moreover, the customers’ comments are not usually considered for constructing/evaluating the rules. To tackle these issues, a system framework is proposed in this paper in which all association rules are clustered using a new similarity measure. For each cluster, a new type of graph is developed known as sub-graph in this paper. Each sub-graph has unique messages that can partially contribute to designing new services. Furthermore, for the first time, the real satisfaction levels are embedded into the association rules to enrich them in an innovative way. The main interesting point is that the satisfaction levels are only assessed for the overall system, not for current services. We also illustrate how our proposed methodology works through artificial and real datasets and also demonstrate the superiority of our proposed clustering algorithm compared to other popular methods. © 2014, Springer-Verlag Berlin Heidelberg.},
author_keywords={Customer satisfaction;  Data mining;  Decision support system;  Idea generation;  Knowledge representation},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Mistry2015,
author={Mistry, B.R. and Desai, A.},
title={Privacy preserving heuristic approach for association rule mining in distributed database},
journal={ICIIECS 2015 - 2015 IEEE International Conference on Innovations in Information, Embedded and Communication Systems},
year={2015},
doi={10.1109/ICIIECS.2015.7192972},
art_number={7192972},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957028098&doi=10.1109%2fICIIECS.2015.7192972&partnerID=40&md5=d3e007c7b8ddeeed445acff564954658},
abstract={Association rule mining is a powerful model of data mining used for finding hidden patterns in large databases. The challenges of data mining is to secure the confidentiality of sensitive patterns when releasing database of third parties. Privacy Preserving in this paper is used as hide association rule. Association rule hiding algorithm sanitize database such that certain sensitive association rule cannot be discovered through Association rule mining techniques. There are various approach this describe in this paper but used the Heuristic approach in Data Distortion Technique. The proposed algorithm is the extension of MDSRRC algorithm, which hides multiple R.H.S items. In Proposed work MDSRRC algorithm works on the distributed database. We will show experimental results in comparisons with MDSRRC algorithm in single database and MDSRRC algorithm in distributed database. © 2015 IEEE.},
author_keywords={association rule hiding;  Data Mining Privacy preserving;  sensitivity},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bawane2015,
author={Bawane, G.R. and Deshkar, P.},
title={Integration of OLAP and association rule mining},
journal={ICIIECS 2015 - 2015 IEEE International Conference on Innovations in Information, Embedded and Communication Systems},
year={2015},
doi={10.1109/ICIIECS.2015.7193123},
art_number={7193123},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957006127&doi=10.1109%2fICIIECS.2015.7193123&partnerID=40&md5=18367a7d765b6b05abd19ee0550f0847},
abstract={OLAP is a multidimensional view of complete data in the data store used for multidimensional analysis. It is the most practical approach used in the data warehouse for analytical process of large data and provides tools for analytical and statistical analysis of data. Association rule learning is a popular method for discovering user interested relations between variables in very large databases. Apriori-cube is advanced algorithm of traditional Apriori algorithm and is used to discover the association rules in multidimensional datasets. This algorithm is used to integrate OLAP and the Association rule mining and build a system which provides rules which can be further analyzed to take decisions regarding the market trends. © 2015 IEEE.},
author_keywords={Apriori algorithm;  Apriori-cube;  Association rule;  frequent itemset;  OLAP},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Meshram2015,
author={Meshram, P.R. and Gupta, D. and Dahiwale, P.D.},
title={An approach for predicting the missing items from large transaction database},
journal={ICIIECS 2015 - 2015 IEEE International Conference on Innovations in Information, Embedded and Communication Systems},
year={2015},
doi={10.1109/ICIIECS.2015.7193043},
art_number={7193043},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957033284&doi=10.1109%2fICIIECS.2015.7193043&partnerID=40&md5=08014c2243578cc735d66bcf4ed7b8fa},
abstract={The Internet is one of the fastest growing areas of intelligence gathering. Due to the tremendous amount of data on internet, web data mining has become very necessary. Predicting the missing items form dataset is indefinite area of research in Web Data Mining. Current approaches use association rule mining techniques which are applied to only small itemsets. Numbers of mechanisms were intended for 'Frequent itemsets' but less attention has been paid that take the advantage of these frequent itemsets for prediction purpose. In order to reduce the rule mining cost for large dataset & to provide online prediction efficiently, the proposed approach use novel method for predicting the missing items. The proposed approach extends advantages of prediction at a higher level of abstraction and reduced rule generation complexity. © 2015 IEEE.},
author_keywords={Frequent itemsets;  Prediction;  Rule Mining;  Web data Mining},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Dharmadhikari2015,
author={Dharmadhikari, M. and Kolhe, V.L.},
title={Anomaly extraction using association rule with the heterogeneous detectors},
journal={2014 International Conference on Information Communication and Embedded Systems, ICICES 2014},
year={2015},
doi={10.1109/ICICES.2014.7033908},
art_number={7033908},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925336918&doi=10.1109%2fICICES.2014.7033908&partnerID=40&md5=94b9b0b5e19b3dd8ba1d0d15efdf3dc1},
abstract={Anomaly detection techniques are used to detect the abnormal behavior. It is also used to identify security attack. The proposed system finds flows those are anomalous from the state of flows. Apriori algorithm is uses to identify anomalous flows which are present in network traffic. In this proposed method, first preprocessing of input traffic flow is done; Apriori algorithm is applied over network traffic flows are detecting. Heterogeneous detectors are applied on frequent item set to And anomalous flow. It enhances the performance in terms of speed as well as detection accuracy. © 2014 IEEE.},
author_keywords={Anomaly detection;  Apriori method;  Attack;  Data mining;  Heterogeneous detector},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kanimozhi2015,
author={Kanimozhi, D. and Rajadurai, R.},
title={Analysis of critical aspects to attract online contents},
journal={2014 International Conference on Information Communication and Embedded Systems, ICICES 2014},
year={2015},
doi={10.1109/ICICES.2014.7033867},
art_number={7033867},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925321475&doi=10.1109%2fICICES.2014.7033867&partnerID=40&md5=886adde724a032d7d2ddabaa2a6e276b},
abstract={Web portal sites have become an important medium to deliver digital content and service to the users such as news, advertisements, and so on. It's necessary to design a recommender system to attract more number of users on particular content module. To address this challenge, in this paper we propose deeper user action interpretation to enhance those critical aspects. Interpreting users' actions from the factors of user engagement to achieve estimation of content attractiveness. To attract the online content, estimate the rank for the content modules then, when a particular content module is ranked with same number, the server is being got confused to process the request of the user. The drawback is lack of data, traffic and unpredictable result which requested by the user to overcome this problem introducing association rule mining algorithm. © 2014 IEEE.},
author_keywords={content optimization;  recommender systems;  user interaction},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Novitasari201551,
author={Novitasari, W. and Hermawan, A. and Abdullah, Z. and Sembiring, R.W. and Herawan, T.},
title={A method of discovering interesting association rules from student admission dataset},
journal={International Journal of Software Engineering and its Applications},
year={2015},
volume={9},
number={8},
pages={51-66},
doi={10.14257/ijseia.2015.9.8.05},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942239480&doi=10.14257%2fijseia.2015.9.8.05&partnerID=40&md5=73d7740b61b2e5761742d8d259f05565},
abstract={For the past decades and until now, association rule mining is one of the most prominent research topics in data mining. However, the main challenge among public or private practitioners is to find the interesting rule from data repository. As a result, many efforts have been put forward to explore this rule by applying several methods and interesting measures. Therefore, in this paper, we introduced an enhanced association rule mining method namely Significant Least Pattern Growth (SLP-Growth), where the algorithm embeds with two interesting measures called Critical Relative Support (CRS) and Correlation (Corr). The experiment uses the dataset that contains the records of preferred programs being selected by post-matriculation or post-STPM students of Malaysia via Electronic Management of Admission System (e-MAS) for the year 2008/2009. The experimental results show that the SLP-Algorithm with the embedded measures can successfully in categorizing the association rules. In addition, this information can be used by educators and higher university authority personnel in the university to understand the programs' patterns being selected by the students. More importantly, it can assist them as a basis to offer more relevant programs to the potential students rather than by chance technique. © 2015 SERSC.},
author_keywords={Association rule;  Data mining;  Significant least patterns;  Student dataset},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhu201579,
author={Zhu, L. and Xu, S.},
title={Prediction algorithm based on web mining for multimedia objects in next-generation Digital Earth},
journal={International Journal of Embedded Systems},
year={2015},
volume={7},
number={1},
pages={79-87},
doi={10.1504/IJES.2015.066145},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84918577622&doi=10.1504%2fIJES.2015.066145&partnerID=40&md5=569920328f4d3f405f718d67aa100982},
abstract={New research questions related to big data have brought Digital Earth into a new data-intensive era. In this paper, we present a prediction algorithm based on data mining especially for multimedia objects in next-generation Digital Earth. We collect the useful data and preprocess them in client logs, mine the sequential pattern between the spatial objects and the multimedia objects, and obtain the association rules. The derived association rules can be used for prefetching some candidates in advance. The diverse experiment results show that our prefetching strategy based on mining web logs achieves higher efficiency than the other general or no prefetching ones. Copyright © 2015 Inderscience Enterprises Ltd.},
author_keywords={Association rules;  Embedded systems.;  Next-generation Digital Earth;  Prediction;  Sequential pattern;  Web mining},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Gonzalez20151,
author={Gonzalez, L.I.L. and Amft, O.},
title={Mining relations and physical grouping of building-embedded sensors and actuators},
journal={2015 IEEE International Conference on Pervasive Computing and Communications, PerCom 2015},
year={2015},
pages={1-10},
doi={10.1109/PERCOM.2015.7146503},
art_number={7146503},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942599717&doi=10.1109%2fPERCOM.2015.7146503&partnerID=40&md5=f7692601853885cf76949e4c659337be},
abstract={We present a framework to mine relations and group variables that represent measurement and status information from sensors and actuators in office buildings. Our work is motivated by the need to manage growing numbers of devices and related automation functions in buildings that are currently often manually commissioned and maintained. Our approach relies on the idea that building variables at the same location will change value in a temporal relation that can be discovered. Based on event sequences derived from various variables and modalities, our approach initially mines temporal association rules and subsequently groups variables. We propose a weighted transitive clustering (WTC) algorithm to automatically group co-located building variables. To validate our approach, we used living-lab office recordings across 14 months from three different office rooms. We compare our approach against a random guess baseline, a hierarchical agglomerative clustering (HAC) approach, and the rules of a manually configured building management system (BMS). We found that within three months of operation, 75% of the building variables could be grouped. Our WTC approach outperforms the baseline and HAC. Furthermore, we show that our framework can be used develop different BMS applications, including counting people in building spaces and identifying BMS configuration errors. © 2015 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Samizadeh2015261,
author={Samizadeh, R. and Mehregan, S.},
title={Retaining customers using clustering and association rules in insurance industry: A case study},
journal={International Journal of Management and Business Research},
year={2015},
volume={5},
number={4},
pages={261-268},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000386267&partnerID=40&md5=82a028988fdeabf0fdf52eba61be76d9},
abstract={This study clusters customers and finds the characteristics of different groups in a life insurance company in order to find a way for prediction of customer behavior based on payment. The approach is to use clustering and association rules based on CRISP-DM methodology in data mining. The researcher could classify customers of each policy in three different clusters, using association rules. At the end of study the characteristics are defined and given to the company, so they could implement CRM strategies based on the newly found differences. Attention to the income and cash earning comes before paying attention to other problems. In most of the companies in developing countries, infrastructural problems of the company like earning enough income prevent the company from effective research implementation on advanced strategies. So this study focuses on basic problems. Utilizing data mining approach to classify customers in life insurance is a new approach among insurance companies in Iran. There are some research in relation to the CRM and data mining, but the contribution of this study is to investigate two new attributes plus those common attributes used before in studying customer behavior; the two attributes are "payment type" and the "purchaser". In order to have a framework, all the process is embedded in CRISP-DM methodology. © IAU.},
author_keywords={Customer retention;  Data mining;  Decision tree;  Life insurance;  Segmentation},
document_type={Article},
source={Scopus},
}

@CONFERENCE{NoAuthor2015,
title={CEUR Workshop Proceedings},
journal={CEUR Workshop Proceedings},
year={2015},
volume={1422},
page_count={202},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944328373&partnerID=40&md5=3ffc52d1f9cac9c9d4cae85f1029c086},
abstract={The proceedings contain 28 papers. The topics discussed include: building a computer system for the world's information; evolutionary algorithms - selected topics; hybrid flow graphs: towards the transformation of sequential code into parallel pipeline networks; assessing applicability of power-efficient embedded devices for micro-cloud computing; free or fixed word order: what can treebanks reveal?; efficient computational algorithm for spline surfaces; a versatile algorithm for predictive graph rule mining; extension of business rule sets using data mining of GUHA association rules; resource-light acquisition of inflectional paradigms; giving a sense: a pilot study in concept annotation from multiple resources; Czech aspect-based sentiment analysis: a new dataset and preliminary results; and using multi-objective optimization for the selection of ensemble members.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2015,
title={2015 1st International Conference on Futuristic Trends in Computational Analysis and Knowledge Management, ABLAZE 2015},
journal={2015 1st International Conference on Futuristic Trends in Computational Analysis and Knowledge Management, ABLAZE 2015},
year={2015},
page_count={750},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941236650&partnerID=40&md5=2c4dccba16f5a0e20f212428bd7aeed2},
abstract={The proceedings contain 132 papers. The topics discussed include: comparative review of selection techniques in genetic algorithm; implementation of coherent rule mining algorithm for association rule mining; eigenvector centrality and its application in research professionals' relationship network; data clustering approaches survey and analysis; extending IAMCTD using data fusion and lossless data compression for UWSN; verification of various numerical methods using hardware implementation; predictions in heart disease using techniques of data mining; designing knowledge representation framework for ICD-10; Time optimization of instruction execution In FPGA using embedded systems; outage analysis of a secondary user in overlay/underlay model; a triple band stacked patch antenna with slotted ground structure; re-configurable ring resonator for oscillator application; a review on energy based spectrum sensing in cognitive radio networks; and multiband microstrip antenna with circular polarization for wireless communication.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Lin2015125,
author={Lin, C.-J. and Peng, C.-C. and Chen, C.-H. and Lin, H.-Y.},
title={A self-organizing recurrent wavelet neural network for nonlinear dynamic system identification},
journal={Applied Mathematics and Information Sciences},
year={2015},
volume={9},
number={1},
pages={125-132},
doi={10.12785/amis/091L16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924268423&doi=10.12785%2famis%2f091L16&partnerID=40&md5=7a218c3e6cb480733c4619e85d88900b},
abstract={To solve identification of nonlinear dynamic systems, a recurrent wavelet neural network (RWNN) model is proposed in this paper. The proposed RWNN model has four-layer structure. Temporal relations embedded in the network by adding some feedback connections representing the memory units in the second layer. An online learning algorithm, which consists of structure learning and parameter learning, is proposed and is able to construct the wavelet neural network dynamically. The structure learning is based on the input partitions to determine the number of wavelet bases, and the parameter learning is based on the supervised gradient descent method to adjust the shape of wavelet functions, feedback weights, and the connection weights. Computer simulations were conducted to illustrate the performance and applicability of the proposed model. © 2015 NSP Natural Sciences Publishing Cor.},
author_keywords={Backpropagation;  Degree measure;  Identification;  Online learning;  Recurrent neural network;  Wavelet bases},
document_type={Article},
source={Scopus},
}

@ARTICLE{AbdulKadir2014699,
author={Abdul Kadir, A.S. and Bakar, A.A. and Hamdan, A.R.},
title={Enhancing classification accuracy with frequent positive and negative rules},
journal={Journal of Theoretical and Applied Information Technology},
year={2014},
volume={66},
number={3},
pages={699-713},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906890155&partnerID=40&md5=2fe8f0dc8c21f65e689a56356629be2d},
abstract={Associative classification has been proven to be more accurate than the state-of-the-art classification algorithms, such as C4.5. The rules known as class association rules (CARs) are used to build the classifier. Initially, positive association rules were generated to build associative classifiers. However, more recently, negative association rules have been recognized for their ability to enhance associative classification accuracy. Literature shows that the knowledge obtained from negative association rules is considered unique and surprising compared to the positive association rules. We propose to mine the quality of negative association rule from frequent positive and negative (FPN) itemset approach. The FPN approach will be embedded in an Apriori algorithm for mining negative association rules and later, integrated with a CBA algorithm for the construction of the classifier. This approach presents challenges in the search space and selecting quality CARs in order to enhance the classification accuracy. An experiment was conducted with UCI datasets to evaluate the classifier's performance and the results demonstrated that the FPN managed to produce competitive classifier. © 2005 - 2014 JATIT & LLS. All rights reserved.},
author_keywords={Associative classification;  Negative association rule},
document_type={Article},
source={Scopus},
}

@BOOK{Leung2014339,
author={Leung, C.K.-S.},
title={Uncertain frequent pattern mining},
journal={Frequent Pattern Mining},
year={2014},
volume={9783319078212},
pages={339-367},
doi={10.1007/978-3-319-07821-2_14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924418282&doi=10.1007%2f978-3-319-07821-2_14&partnerID=40&md5=16cca98d5499b09a14eb3df675f5fd2d},
abstract={Frequent pattern mining aims to discover implicit, previously unknown and potentially useful knowledge-in the form of frequently occurring sets of items-that are embedded in data. Many of the models and algorithms developed in the early days mine frequent patterns from traditional transaction databases of precise data such as shopper market basket data, in which the contents of databases are known. However, we are living in an uncertain world, in which uncertain data can be found in various real-life applications. Hence, in recent years, researchers have paid more attention to frequent pattern mining from probabilistic datasets of uncertain data. This chapter covers key models, algorithms and topics about uncertain frequent pattern mining. © 2014 Springer International Publishing Switzerland. All rights are reserved.},
author_keywords={Association rule mining;  Data mining;  Frequent itemsets;  Frequent patterns;  Knowledge discovery from uncertain data;  Probabilistic approach;  Uncertain data},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Bui2014397,
author={Bui, D.B. and Hadzic, F. and Tagarelli, A. and Hecker, M.},
title={Evaluation of an associative classifier based on position-constrained frequent/closed subtree mining},
journal={Journal of Intelligent Information Systems},
year={2014},
volume={45},
number={3},
pages={397-421},
doi={10.1007/s10844-014-0312-9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946494301&doi=10.1007%2fs10844-014-0312-9&partnerID=40&md5=bab537d56b6192dfcff895897d01a6bd},
abstract={Tree-structured data are popular in many domains making structural classification an important task. In this paper, an associative classification method is introduced based on a structure preserving flat representation of trees. A major difference to traditional tree mining techniques is that subtrees are constrained by the position in the original trees, leading to a drastic reduction in the number of rules generated, especially with data having great structural variation among tree instances. This characteristic would be desired in the current status of frequent pattern mining, where excessive patterns hinder the practical use of results. However the question remains whether this reduction comes at a high cost in accuracy and coverage rate reduction. We explore this aspect and compare the approach with a state-of-the-art structural classifier based on same subtree type, but not positional constrained in any way. We investigate the effect of using different types of frequent pattern (frequent or closed), or subtree types (induced, embedded or embedded-plus-disconnected subtrees) to the performance of the two classifiers. Different rule strength measures such as confidence, weighted confidence and likelihood are also examined in our study. The experiments on three real-world data sets reveal important similarities and differences between the methods. © 2014, Springer Science+Business Media New York.},
author_keywords={Association rule mining;  Database structure model;  Structural classification;  Tree mining},
document_type={Article},
source={Scopus},
}

@ARTICLE{Tong2014651,
author={Tong, L.R. and Zhang, J. and Ma, L. and Xin, L. and Hu, S. and He, J.F.},
title={An improved Apriori algorithm based on linkedlist for the prevention of clinic pharmaceutical conflict},
journal={Applied Mechanics and Materials},
year={2014},
volume={513-517},
pages={651-656},
doi={10.4028/www.scientific.net/AMM.513-517.651},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897678148&doi=10.4028%2fwww.scientific.net%2fAMM.513-517.651&partnerID=40&md5=f1c285f2acd15c9adde76ee0882e86bf},
abstract={Investigation of association relation for medical prescription appears as an essential part for the treatment of patient in clinical pharmacy. Not often, however occasionally, the pharmaceutical conflict that could possibly relate to unpredictable hazard to patient may occur. Therefore, clinical physicians apply specific software package embedded in HIS (Hospital Information System) to sensitively and instantly discover the potential danger from the electronic prescription. In some HIS systems or independent software packages, Apriori algorithm is applied in pharmaceutical conflict checking, however, the efficacy is encumbered due to the mechanism of the algorithm. The mentioned algorithm Apriori is a classical algorithm for association rules mining, it applies an iteration method called searching step by step, to explore K itemset by (K-1) itemset. Each time when it explores a K-itemset, Apriori algorithm must scan the whole database, which causes the obvious reduction of efficiency due to the requirement of constant database scanning. To solve this problem, an improved Apriori algorithm based on Linkedlist is applied. Due to the decrease of transactions number, the operating efficiency of the algorithm is enhanced during the process of K-itemsets exploration. In order to reduce the number of transactions, the database is transformed into a series LinkedLists which could allocate an element of L1 as header node. After being transformed, the whole database scanning could be skipped. Instead, the corresponding LinkedList is scanned to explore K-itemsets. The proposed method could filter the unrelated transactions during the generation of frequent itemsets. The experiment proves that the new algorithm could release better performance rather than original Apriori algorithm. © (2014) Trans Tech Publications, Switzerland.},
author_keywords={Apriori;  Frequent itemsets;  Llinkedlist},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zin2014510,
author={Zin, T.T. and Tin, P. and Toriu, T. and Hama, H.},
title={An embedded knowledge extraction technology for consumer video surveillance},
journal={2014 IEEE 3rd Global Conference on Consumer Electronics, GCCE 2014},
year={2014},
pages={510-511},
doi={10.1109/GCCE.2014.7031300},
art_number={7031300},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946690152&doi=10.1109%2fGCCE.2014.7031300&partnerID=40&md5=9e9006778ec37ca7aeb42ff2782b833d},
abstract={New advances in embedded computing technology have opened up the potential for new era of consumer surveillance systems. This paper will explore and propose a new embedded modeling technique for the configuration of consumer video surveillance systems that can identify events of interest, especially on abandoned and stolen objects in indoor and outdoor environments. The proposed embedded system will focus on high level behavior understanding for object detection, tracking and classification. The experimental results illustrate the ability of the system to create complex spatiotemporal relations and to recognize the behavior of one or multiple objects in various video scenes. © 2014 IEEE.},
author_keywords={abandoned object;  consumer video surveillance;  embedded modeling technique;  high level behavior},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Shanmuganathan2014335,
author={Shanmuganathan, S. and Narayanan, A. and Mohamed, M. and Ibrahim, R. and Khalid, H.},
title={A hybrid approach to modelling the climate change effects on Malaysia’s oil palm yield at the regional scale},
journal={Advances in Intelligent Systems and Computing},
year={2014},
volume={287},
pages={335-346},
doi={10.1007/978-3-319-07692-8_32},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84918523563&doi=10.1007%2f978-3-319-07692-8_32&partnerID=40&md5=a76f5a0a42ce547d21d6368789d7e9cf},
abstract={Understanding the climate change effects on local crops is vital for adapting new cultivation practices and assuring world food security. Given the volume of palm oil produced in Malaysia, climate change effects on oil palm phenology and fruit production have greater implications at both local and international scenes. In this context, the paper looks at analysing the recent climate change effects on oil palm yield within a five year period (2007-2011) at the regional scale. The hybrid approach of data mining techniques (association rules) and statistical analyses (regression) used in this research reveal new insights on the effects of climate change on oil palm yield within this small data set insufficient for conventional analyses on their own. © Springer International Publishing Switzerland 2014.},
author_keywords={Data mining (association rules);  JRip;  Regression test;  WEKA},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kliegr2014236,
author={Kliegr, T. and Kuchař, J. and Sottara, D. and Vojíř, S.},
title={Learning business rules with association rule classifiers},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2014},
volume={8620 LNCS},
pages={236-250},
doi={10.1007/978-3-319-09870-8_18},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905260896&doi=10.1007%2f978-3-319-09870-8_18&partnerID=40&md5=2ff0be028de898681829da4507c73457},
abstract={The main obstacles for a straightforward use of association rules as candidate business rules are the excessive number of rules discovered even on small datasets, and the fact that contradicting rules are generated. This paper shows that Association Rule Classification algorithms, such as CBA, solve both these problems, and provides a practical guide on using discovered rules in the Drools BRMS and on setting the ARC parameters. Experiments performed with modified CBA on several UCI datasets indicate that data coverage rule pruning keeps the number of rules manageable, while not adversely impacting the accuracy. The best results in terms of overall accuracy are obtained using minimum support and confidence thresholds. Disjunction between attribute values seem to provide a desirable balance between accuracy and rule count, while negated literals have not been found beneficial. © 2014 Springer International Publishing.},
author_keywords={association rules;  business rules;  Drools;  rule pruning},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Qian20141249,
author={Qian, Z. and Schulte, O. and Sun, Y.},
title={Computing multi-relational sufficient statistics for large databases},
journal={CIKM 2014 - Proceedings of the 2014 ACM International Conference on Information and Knowledge Management},
year={2014},
pages={1249-1258},
doi={10.1145/2661829.2662010},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937560235&doi=10.1145%2f2661829.2662010&partnerID=40&md5=c1561dcfd8ba06ecbbf5170c6a159c8c},
abstract={Databases contain information about which relationships do and do not hold among entities. To make this information accessible for statistical analysis requires computing sufficient statistics that combine information from different database tables. Such statistics may involve any number of positive and negative relationships. With a naive enumeration approach, computing sufficient statistics for negative relationships is feasible only for small databases. We solve this problem with a new dynamic programming algorithm that performs a virtual join, where the requisite counts are computed without materializing join tables. Contingency table algebra is a new extension of relational algebra, that facilitates the efficient implementation of this Möbius virtual join operation. The Möbius Join scales to large datasets (over 1M tuples) with complex schemas. Empirical evaluation with seven benchmark datasets showed that information about the presence and absence of links can be exploited in feature selection, association rule mining, and Bayesian network learning. Copyright 2014 ACM.},
author_keywords={Multi-relational databases;  Relational algebra;  Sufficient statistics;  Virtual join},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Abdullah2014159,
author={Abdullah, Z. and Herawan, T. and Deris, M.M.},
title={Mining indirect least association rule},
journal={Lecture Notes in Electrical Engineering},
year={2014},
volume={285 LNEE},
pages={159-166},
doi={10.1007/978-981-4585-18-7_19},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958546837&doi=10.1007%2f978-981-4585-18-7_19&partnerID=40&md5=d95d8ceb33097d0a1d65d11830d5ef7a},
abstract={Indirect pattern can be considered as one of the interesting information that is hiding in transactional database. It corresponds to the property of high dependencies between two items that are rarely appeared together but indirectly occurred through another items. Therefore, we propose an algorithm for Mining Indirect Least Association Rule (MILAR) from the real dataset. MILAR is embedded with a scalable least measure called Critical Relative Support (CRS). The experimental results indicate that MILAR is capable in generating the indirect least association rules from the given dataset. © Springer Science+Business Media Singapore 2014.},
author_keywords={Association rule;  Indirect;  Least;  Mining},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Saleena2014254,
author={Saleena, B. and Srivatsa, S.K.},
title={An automated approach to extract domain ontology for an e-learning system},
journal={International Journal of Innovation and Learning},
year={2014},
volume={15},
number={3},
pages={254-273},
doi={10.1504/IJIL.2014.060876},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899784652&doi=10.1504%2fIJIL.2014.060876&partnerID=40&md5=7c6507d1f6573b5fe8164c471eb5b148},
abstract={The main aim of the proposed work is to design an automated approach to extract domain ontology from the e-learning resources. The domain ontology derived is embedded into the e-learning system so that the learners can be provided with more relevant and meaningful learning materials based on their knowledge levels. The advantage of the proposed approach is the concept map extraction that is effectively achieved through the use of association rule mining algorithm and fuzzy techniques. Experimentations were carried out to prove the efficiency in constructing the domain ontology and the performance is analysed with the previous approach. Simulation experiments were carried out to implement the automated domain ontology to the adaptive e-learning system. © 2014 Inderscience Enterprises Ltd.},
author_keywords={Association rule mining;  Concept map;  E-learning;  Fuzzy domain ontology;  Information gain;entropy;  Innovation;  Taxonomy},
document_type={Article},
source={Scopus},
}

@CONFERENCE{NoAuthor2014625,
title={IJCB 2014 - 2014 IEEE/IAPR International Joint Conference on Biometrics},
journal={IJCB 2014 - 2014 IEEE/IAPR International Joint Conference on Biometrics},
year={2014},
pages={625},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921968905&partnerID=40&md5=2b8802ba5567b7319711d641189d7dc1},
abstract={The proceedings contain 80 papers. The topics discussed include: framework for improving the performance of verification algorithms with a low false positive rate requirement and limited training data; multi-modal biometrics for mobile authentication; LPIDB v1.0 - latent palmprint identification database; audio-visual gender recognition in uncontrolled environment using variability modeling techniques; cross-view gait recognition using view-dependent discriminative analysis; a coarse-to-fine approach to robust 3D facial landmarking via curvature analysis and active normal model; age invariant face recognition based on texture embedded discriminative graph model; impact of sensor ageing on iris recognition; non-negative sparse coding based scalable access control using fingertip ECG; aiding face recognition with social context association rule based re-ranking; and iris pattern obfuscation in digital images.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Li2014170,
author={Li, Z. and O'Brien, L. and Yang, Y.},
title={Impact of product complexity on actual effort in software developments: An empirical investigation},
journal={Proceedings of the Australian Software Engineering Conference, ASWEC},
year={2014},
pages={170-179},
doi={10.1109/ASWEC.2014.38},
art_number={6824122},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903520166&doi=10.1109%2fASWEC.2014.38&partnerID=40&md5=67e9e93601775ae4cb9574e62a3bb897},
abstract={[Background:] Software effort prediction methods and models typically assume positive correlation between software product complexity and development effort. However, conflicting observations, i.e. negative correlation between product complexity and actual effort, have been witnessed from our experience with the COCOMO81 dataset. [Aim:] Given our doubt about whether the observed phenomenon is a coincidence, this study tries to investigate if an increase in product complexity can result in the abovementioned counter-intuitive trend in software development projects. [Method:] A modified association rule mining approach is applied to the transformed COCOMO81 dataset. To reduce noise of analysis, this approach uses a constant antecedent (Complexity increases while Effort decreases) to mine potential consequents with pruning. [Results:] The experiment has respectively mined four, five, and seven association rules from the general, embedded, and organic projects data. The consequents of the mined rules suggested two main aspects, namely human capability and product scale, to be particularly concerned in this study. [Conclusions:] The negative correlation between complexity and effort is not a coincidence under particular conditions. In a software project, interactions between product complexity and other factors, such as Programmer Capability and Analyst Capability, can inevitably play a 'friction' role in weakening the practical influences of product complexity on actual development effort. © 2014 IEEE.},
author_keywords={Empirical Software Engineering;  Product Complexity;  Software Development;  Software Effort Estimation},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Takeuchi20144960,
author={Takeuchi, H. and Kodama, N.},
title={Validity of association rules extracted by healthcare-data-mining},
journal={2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC 2014},
year={2014},
pages={4960-4963},
doi={10.1109/EMBC.2014.6944737},
art_number={6944737},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929493458&doi=10.1109%2fEMBC.2014.6944737&partnerID=40&md5=496edb39faf0074f385fca84eb909ac6},
abstract={A personal healthcare system used with cloud computing has been developed. It enables a daily time-series of personal health and lifestyle data to be stored in the cloud through mobile devices. The cloud automatically extracts personally useful information, such as rules and patterns concerning the user's lifestyle and health condition embedded in their personal big data, by using healthcare- data-mining. This study has verified that the extracted rules on the basis of a daily time-series data stored during a half- year by volunteer users of this system are valid. © 2014 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Wang20145242,
author={Wang, L. and Sun, M. and Cao, C.},
title={How to mine information from each instance to extract an abbreviated and credible logical rule},
journal={Entropy},
year={2014},
volume={16},
number={10},
pages={5242-5262},
doi={10.3390/e16105242},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908452494&doi=10.3390%2fe16105242&partnerID=40&md5=a7cc43a305923817a55a8761707634a5},
abstract={Decision trees are particularly promising in symbolic representation and reasoning due to their comprehensible nature, which resembles the hierarchical process of human decision making. However, their drawbacks, caused by the single-tree structure, cannot be ignored. A rigid decision path may cause the majority class to overwhelm other class when dealing with imbalanced data sets, and pruning removes not only superfluous nodes, but also subtrees. The proposed learning algorithm, flexible hybrid decision forest (FHDF), mines information implicated in each instance to form logical rules on the basis of a chain rule of local mutual information, then forms different decision tree structures and decision forests later. The most credible decision path from the decision forest can be selected to make a prediction. Furthermore, functional dependencies (FDs), which are extracted from the whole data set based on association rule analysis, perform embedded attribute selection to remove nodes rather than subtrees, thus helping to achieve different levels of knowledge representation and improve model comprehension in the framework of semi-supervised learning. Naive Bayes replaces the leaf nodes at the bottom of the tree hierarchy, where the conditional independence assumption may hold. This technique reduces the potential for overfitting and overtraining and improves the prediction quality and generalization. Experimental results on UCI data sets demonstrate the efficacy of the proposed approach. © 2014 by the authors.},
author_keywords={Decision forest;  Functional dependency;  Naive bayes;  Semi-supervised learning},
document_type={Article},
source={Scopus},
}

@CONFERENCE{NoAuthor2014,
title={2013 International Conference on Communication Technology, ICCT 2013},
journal={WIT Transactions on Information and Communication Technologies},
year={2014},
volume={51},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903206911&partnerID=40&md5=d451ea7462b6b94e2b089375889571e2},
abstract={The proceedings contain 169 papers. The special focus in this conference is on Circuits and Systems, Computers and Information Technology, Communication Systems, Controls, Electrical Power Systems, and Signal Processing. The topics include: Study on performance of PCI interface for embedded system; model and simulation for utilizing regenerative energy with uncertain factors; research on bearer network program of power softswitch dispatching network; wearable motion recognition system based on foot pressure sensing; a novel digital AGC algorithm based on fault tolerance probability; design of intelligent vehicle system based on embedded ARM; design and realization of class D audio power amplifier; parallel multi-beam adaptive beamformer for GPS receivers; an open-loop digital solver of shaft angle based on DSP; an asymmetrical watermarking algorithm for vector map data; agent-based approach for process hazard analysis; an improved people counting method based on occlusion detection and compensation; comprehensive evaluation of the level of scientific data quality; a creative camping schedule design; an attribute reduction algorithm based on information entropy and its application; cloud resource management based on multi-agent system; a new data transmission scheme with adaptive power consumption in mobile cloud environments; improved DV-distance localization algorithm base on differential evolution; a novel information rate computation for erasure channel; a new method used for high speed pseudo-random code generating; animation production management software analysis and research; experience of constructing virtual desktop; the design of an encrypted file system based on improved DES algorithm; a low-complexity simulation of artificial pitch period detection algorithm; research on timing function of cerebellum in DIVA model; community detection using a potential-based label propagation algorithm; a gate-level model for single-event upset simulation; clustering protocol based on data aggregating scheme for wireless sensor networks; study review on android bytecode protection; research on spatial information retrieval based on Fourier descriptor; improvement of signal number estimation using Gerschgorin disks for acoustic vector sensor array; a supply chain network equilibrium model with loss-averse retailers; application of an attribute reduction algorithm based on discernibility matrix in PBNM; performance analysis for selective cooperation transmission in high-speed railway; research of system security assessment based on knowledge base; smooth strategies for high finishing tool path planning; the optimization problem of matching natural casing; research on expert intelligent retrieval and recommendation based on the search term; a study on smart phone users of college students in Hangzhou, China; based on multi-core parallel processing technology in weather radar data mosaic; personality mining system in e-learning by using improved association rules algorithm; security consideration in cyber-physical systems for next wireless generation; a secure scheme based on multi-dimension location for wireless sensor networks; risk analysis of application of cloud computing in electronic government; the lane line detection based on the improved Hough transform; channel characteristics in the LED traffic lights to vehicles communications; wireless monitoring system based on android phone; multiple relay selection for two-way relay networks with outdated channel state information; routing based on contact distributions in intermittently connected mobile networks; blind equalization for UWB-based wireless body area network on-body channel; research on cooperative jamming identification algorithms in fading channels; multi-pitch estimation based on correlation and spectrum analysis; radio frequency fingerprinting using integral envelope; a region-based selective encryption scheme for H.264 video; a design of dual-band planar inverted-F antenna for mobile communication in GSM and DCS; analysis of delay attacks based on game theory in time synchronization protocols; researches on efficient weather radar data transmission control; a spatial-context-related access control model based on role and time constraint; smart appliances management model research based on internet of things technology; parallel resource allocation algorithm for throughput maximization in LTE uplink systems; an adaptive congestion control scheme in opportunistic network; composite control method for active vibration suppression of tethered spacecraft; research on improvement of hard decision algorithm of low-density parity-check codes; electricity price forecasting by a combined method; design of embedded factory sewage remote monitoring system based on BP neural network algorithm; intermittent fault diagnosis method of power system based on dynamic particle swarm improved algorithm; design and simulation of multiple coil model for wireless power transmission system; a new maximum power point tracking technique for permanent magnet direct drive wind power system; blind extraction of specific signal based on auditory feature; Eigen space-based structured Gaussian mixture model for nonparallel corpora voice conversion; Jordan semi-triple maps on Hilbert space effect algebras; efficient data-intensive processing in cloud computing environment; research on capsule surface defects inspection algorithms based on colored image; a parallel segmentation method of medical image based on cluster system; tongue image segmentation based on the structure of Quadtree; a fast and illumination robust algorithm based on SRC for face recognition; a robust watermarking scheme for region of interest in scalable video coding; a robust watermarking scheme for region of interest in scalable video coding; efficient tropical cyclone center location based on adaptive image edge growing approaches and multiview and multifocus image fusion based on wavelet transform for wireless multimedia sensor networks.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2014,
title={2014 International Conference on Mechatronics, Materials and Manufacturing, ICMMM 2014},
journal={Applied Mechanics and Materials},
year={2014},
volume={624},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906976189&partnerID=40&md5=31dbaaa35a8472fd4c2820f74706893d},
abstract={The proceedings contain 145 papers. The special focus in this conference is on Mechatronics, Materials and Manufacturing. The topics include: Research on the anti-penetration performance of aluminum foam sandwich plate; crystallization of aluminium alloys; influence of the amount of recyclate and regranulate senosan on tensile properties of the material starex; strain rate effect on the mechanical properties of recycled wood particles/ epoxy composites; perceived roughness of material surfaces; study on gel time for electrorheological materials applied to ER automatic clutch; electrochemical corrosion behavior of AZ80 magnesium alloy tube fabricated by hydrostatic extrusion; research on affecting factor of preparation of calcium sulfate whisker with FGD gypsum; research status of flexible substrate transparent conductive; effect of quenching temperature and medium on properties of TiO2 nanotube arrays in DSSC; evaluation of interface performance by means of dynamic electrochemical impedance evaluation of interface performance by means of dynamic electrochemical impedance spectroscopy; effect of wire materials on cutting performance of WEDM for machining of inconel superalloy; a study on effect of beginning V concentration in TD process; experimental and numerical simulation of multipass hot-rolling on 7150 aluminum alloy; performance study analysis of inflaming retarding viscose of clothing material; research progress of W/ZrC ultra-high temperature cermets; exchange bias of the Fe/Fe3O4 coated Ag/hollow glass microspheres; fluorine doping effects on the electric property of BiFeO3 thin films; research on the influence factor and improving measures of machining accuracy; creep analysis of combined bolted flange joints under high temperature; numerical study of the effects of joint interface on two cylinders; torque analysis and simulation calculation of flying fixed canard; design of space sliding rails and mechanical analysis; eulerian description of rail straightening process; the quantum conditions of one dimension potential well based on WKB approximation method; the simulation research of tool wear in small hole EDM machining on titanium alloy; the buckling mechanism of square tube subjected to the impact of a mass; structural design and finite-element analysis of packing seal with self-adaption and resilience; vehicle dynamics modeling based on vortex; shock absorber using hydraulic system and shape memory alloys; experimental modal analysis of a first stage blade in ALSTOM gas turbine; load analysis and structure design of small-scale maglev wind turbine; analysis of spindle rotary precision based on two-point methods; SAR image recognition via local gradient ratio pattern; design of LIDR monitoring system based on GPRS; the method to calculate the length of the catenary for anchored vessel; failure prediction analysis on the 172 basic plane based on grey theory; research on teaching aid of analog circuits based on magnetic element; design of fitness device with power generation and multi-function; identification of coefficient of self inductance; the design of multiplier in integrated circuit based on low-power algorithm; design methodology of ALU based on resource-sharing; study on access system of low voltage distributed photovoltaic power station; research on human implantable wireless energy transfer system; research of novel phosphor membrane packaging technology for LED illuminant; design of control system for knuckle boom crane; design of map positioning and navigation system based on mobile platform; structure and control on FSM subsystem in precision tracking; a study on nonlinear decoupling controller for UPFC; research of constant pressure water supply system based on PLC; research on artificial intelligence technology of electrical automation control; research on modeling methods of nonlinear black box; survey and forecast on scheduling of networked control system; research of BD/GPS hybrid positioning module based on ARM and GPRS; design of reverse sensor based on solar power; shuffled frog leaping applied to optimal deployment of radar network; cultural shuffled frog leaping algorithm and its applications for the radar network deployment; research on path optimization of urban traffic guidance system; the research of model-driven architecture in the embedded system; research on routing protocol for wireless sensor network; virtual training system of special equipment operation based on virtools; the optimization of association rule algorithm in data mining; the water absorption rule of vertical fractured well; stability study on jointed rock mass affected by fissure water pressure; study on the infiltration rule of expansive rock canal slope; GPS application in ginkgo landslide monitoring; study on cracking resistance of concrete reinforced with rib stiffened steel plates; construction technology for deep foundation pit support in mining area; influence of silt soil layer on the space seismic design response spectrum; the deflection of orthotropic saddle membrane under the snow load; design of a new flexometer for the safety monitoring system of bridge; research on foundation stability of building based on foundation bearing capacity; a theory of hierarchy-gray for purchase decision support systems; a predicting model for demand quantities of downstream manufacturer; study on sales system with demand affected by delivery lead time; design coal conveying simulation system based on field bus power plant and the optical fiber connector ceramic insert core injection mold design.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2014,
title={2013 2nd International Conference on Frontiers of Mechanical Engineering and Materials Engineering, MEME 2013},
journal={Applied Mechanics and Materials},
year={2014},
volume={457-458},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887520414&partnerID=40&md5=ccc9eea5f12d90eb16ccbdbd280d6c90},
abstract={The proceedings contain 350 papers. The special focus in this conference is on Material Science and Chemical Engineering, Mechanical Engineering and Manufacturing, Automation, Information Technologies and Data Processing and Engineering Management and Product Design. The topics include: Effect of equal channel angular pressing on corrosion resistance of Al-Mg alloy; influence of stress ratio on fatigue crack propagation in TiAl alloy; study on corrosion behavior of 16MnR in the circulating water system; fabrication of polyacrylonitrile nanoporous fibers via electrospinning; illustration of fracture mechanism in high temperature for TiAl alloys; research on numerical simulation of quad bundle conductor on galloping; functional studies on coffee yarn knitted clothing fabrics; the experimental study on consolidation of RTV for wet-area earthen ruins in southwest china; preparation and performance evaluation of PU foam composite board; recycled polypropylene/SEBS polyblends; mechanical and physical property evaluations of kevlar/polyester complex nonwoven fabrics; synthesis of polyurethane dendrimers and transfer properties of dye; the start-up of A/O biofilm process with silicon-based zeolite filter material; treatment of domestic wastewater by A/O biofilm process of silicon-based zeolite filter material; study on aging of zinc oxide/poly(butylene succinate) composite; development and research of nanostructured multi-layered composite coatings for tool made of tungsten-free carbides (cermets); investigation of the influence of deep rolling on the thermal fatigue cracking for AISI H13 steel; experimental study of lanthanum boride ceramic powder synthesis process; numerical simulation analysis on porthole dies extrusion of aluminum mini-thin harmonica-shaped tube; application study of flotation column in reverse flotation of magnetic and hematite mixed iron ore; design and processing of temperature resistant enamel coating materials; the process experimental study on high efficiency deep grinding for 9SiCr alloy steel with a CBN wheel; study on the texture of materials in stop motion; novel anticaking materials of bentonite, biological carbon and abandoned animal/plant oil in compound fertilizer; effect of pulse magnetic field on primary silicon in Al-20Si alloy; mechanical properties of rice straw particle/HDPE composites; starch-based biodegradable packaging materials of antimicrobial; a new purification way for multiwalled carbon nanotubes; phase structure and thermodynamic stability of various nickel-base multicomponent alloy coating; preparation of PVAc/CNT/Carbon black composite particles; simulation research on three kinds of alloy material for penetration; preparation and performance of polysulfone hollow fiber ultrafiltration membranes; influence of mineral admixtures on early-age autogenous shrinkage of high-performance concrete; study on hollow microspheres with conductive and magnetic properties; the car brake system design and calculation; thermal management simulation of lithium ion batteries for EV/HEV; numerical implementation of a multi-physical fields coupling constitute model; solutions for the finite deformation elastic rod nonlinear wave equation; design and analysis of a transmission mechanism for aerostatic guideway; reliability analysis on anti-overturning stability for truck crane; manufacturing technique and property evaluations of protective textiles; study on release process of micro-CAES used screw expander; investigation on a new type of pneumatic flexible joint; similar structure of solution for the model of nonlinear spherical seepage in composite reservoir; analysis of turbine impeller vibration test equipment; thermal analysis and optimization of high power LED automotive headlamp cooling device; biomechanics quick response system research of vault technical training; fracturing well production dynamic simulation in fractured tight sandstone gas reservoir; the achievement of dynamic load simulator of servo mechanism of multiple DOF thrust vector; high temperature and high pressure ESP performance testing system design; torsional vibration analysis for large-scale reciprocating compressor crankshaft; the mechanical design and simulation of marine in-pipe robot based on metamorphic mechanism; influence of cutting parameters on vibration acceleration in micro-end-milling; life estimation of hub bearing unit based on test load spectrum; parameters optimization of multistage pump-off propped fracturing in thick formation; a gluing device based on PLC for manufacturing flap-disks; analysis on mechanical parameters at SCC tip in fusion boundary region of dissimilar weld joint; optimization techniques in numerical simulation of casting process; vibration performance analysis on gear systems; principle analysis of profiled bar turning peeling machine; studies on sprinklers arrangement in sprinkler systems; application of building information model technology in Shanghai disaster tolerant center construction; operation optimization of the airport check-in system; application of operations research in management; design and simulation of a high-isolation series/shunt mixed MEMS switch; optimization for limited resource schedule in public construction project; a differentiated registration method for complex surfaces; the design of ultrasonic ranging car collision prevention alarm system; design of temperature detection alarm circuit based on multisim; application of frequency conversion technology in the constant pressure water supply system; advanced technology research on the system of city passenger rail vehicle doors; the commercial real estate operation stages risk analysis based on the ISM model; experimental study on the stability properties of different design of tandem wing airship models; design of a new piezoelectric vibrating feeder; modal analysis and application based on finite element method; reasons for formation damage and preparation for disentanglement agent in low permeability oilfield; a study on public construction project duration risk identification and evaluation; study on the optimization of public construction project duration; error sensitivity analysis for machine tool based on three-dimensional vector chain; dynamic response analysis of asphalt pavement on steel deck under design loads; analysis and simulation of mineral grading sieve mechanism motion based on ADAMS; the design of force-displacement characteristics test system for electromagnet; key techniques of direct driving of rapid prototyping machine within CAD system; numerical simulation on penetration into double plates of annular jet; drilling and riveting agencies rigid structural dynamics analysis of virtual prototype; design and exploration on automobile crane mobile counterweight balance; living comfortable strategies for offices in Taiwan's hot-humid climate; semi-definite programming based waveform design for spectrum sensing; using the concept of utility solution resource allocation problem with the order; architecture analysis method study based on EID; the excavating stability study of a power station underground plan; simulation and on-site performance of a novel 3D concentrator for photovoltaic application; offshoring floating wind turbine platform initial design requirement considering whole-life cycle; optimization model and algorithm for smart distribution grid maintenance scheduling; a system model for assessment on creation capabilities of construction service enterprises in China; lean cost analysis based on BIM modeling for construction project; cognitive characteristics of industrial architecture; the obstructions that hamper the use of BIM in China and its solutions; research on evaluation of the modern logistics enterprise technological innovation ability based on SEM; study of agricultural product logistics information system based on multi-agent; supply chain design strategy based on E-Commerce; affective product design based on random forest and association rules; a holistic incentive model of information sharing in supply chain; design of brushless DC motor controller based on DSP; design of embedded controller with flexible programming for industrial robot; research on computer controlled optical surfacing (CCOS) working function at wear state; servo-control system design of automatic production line based on PLC and HMI; machine vision and applications; the application of the UPFC in power system; research on passivity-based ADRC of direct-drive wind power system back to back PWM converter; the research of intelligent seat belt pretension system based on active safety; a new method based on position sensitive detectors to measure spatial angle of large-scale gyroidal; the research on development status and key technology of elastic wave CT; control of pneumatic servo system based on neural network PID algorithm; study on dynamic phase correction method for improving the test accuracy of the pneumatic shape measuring roll; surface roughness measurement analysis; research on core competitiveness of real estate enterprise based on factor analysis and clustering analysis and a palmprint recognition based on collaborative representation.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Tyagi20131,
author={Tyagi, S. and Bharadwaj, K.K.},
title={Enhancing collaborative filtering recommendations by utilizing multi-objective particle swarm optimization embedded association rule mining},
journal={Swarm and Evolutionary Computation},
year={2013},
volume={13},
pages={1-12},
doi={10.1016/j.swevo.2013.07.001},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889888269&doi=10.1016%2fj.swevo.2013.07.001&partnerID=40&md5=0dca862dcc8396c67e07a8be2cf8918d},
abstract={Collaborative Filtering (CF) is the most prevalent technique in recommender systems and facilitates the high-quality recommendations by identifying similar users based on their logged history of prior transactions. However, accuracy of recommendations and sparsity are still major concerns related to CF recommendation techniques. Recent research in CF is investigating the use of Association Rule Mining (ARM) for extracting high-level information and thereby providing more accurate recommendations. However, determination of the threshold values for support and confidence measures affect the quality of association rules. Moreover, the traditional ARM algorithms are based on market basket analysis and therefore degrade computation efficiency by mining too many association rules which are not appropriate for a given user. The proposed approach attempts to improve the quality of recommendations through the application of Multi-objective Particle Swarm Optimization (MOPSO) algorithm for ARM in the framework of CF. Consequently, by considering support and confidence measures as different objectives, the MOPSO based ARM model extracts only useful and eminent direct association rules which are optimal in the wider sense that no other rules are superior to them when both objectives are simultaneously considered. In addition, computational efficiency is enhanced by mining rules only for the given user and over the related transactional database. Further, the present work explores the indirect (transitive) association between users as well as between items for providing more accurate recommendations even with highly sparse history of transactions. In order to evaluate the effectiveness of our approach, we conducted an experimental study using the MovieLens data set. Experimental results clearly reveal that the proposed method consistently outperform other traditional CF based methods as measured by recommendation accuracy, precision, and recall. © 2013 Elsevier B.V.},
author_keywords={Association rule mining;  Collaborative filtering;  Multi-objective optimization;  Particle swarm optimization;  Recommender system},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wang20135,
author={Wang, X. and Chen, M. and Chen, L.},
title={Research of the optimization of a data mining algorithm based on an embedded data mining system},
journal={Cybernetics and Information Technologies},
year={2013},
volume={13},
number={SPECIALISSUE},
pages={5-17},
doi={10.2478/cait-2013-0033},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891761950&doi=10.2478%2fcait-2013-0033&partnerID=40&md5=6fe6b9da6cdf528f809d946b4ff57a86},
abstract={At present most of the data mining systems are independent with respect to the database system, and data loading and conversion take much time. The running time of the algorithms in a data mining process is also long. Although some optimized algorithms have improved it in different aspects, they could not improve the efficiency to a large extent when many duplicate records are available in a database. Solving the problem of improving the efficiency of data mining in the presence of many coinciding records in a database, an Apriori optimized algorithm is proposed. Firstly, a new concept of duplication and use is suggested to remove and count the same records, in order to generate a new database of a small size. Secondly, the original database is compressed according to the users' requirements. At last, finding the frequent item sets based on binary coding, strong association rules are obtained. The structure of the data mining system based on an embedded database has also been designed in this paper. The theoretical analysis and experimental verification prove that the optimized algorithm is appropriate and the algorithm application in an embedded data mining system can further improve the mining efficiency.},
author_keywords={Apriori algorithm;  Association rules;  Data mining;  Duplication;  Embedded database;  Frequent item sets},
document_type={Article},
source={Scopus},
}

@BOOK{Petit201351,
author={Petit, J. and Meurice, N. and Medina-Franco, J.L. and Maggiora, G.M.},
title={A rough set theory approach to the analysis of gene expression profiles},
journal={Chemoinformatics for Drug Discovery},
year={2013},
pages={51-83},
doi={10.1002/9781118742785.ch3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941333456&doi=10.1002%2f9781118742785.ch3&partnerID=40&md5=29b6fda9a936e400711864ead68521ae},
abstract={Rough set theory (RST) is a set-based method that is well suited for dealing with a wide variety of discrete data. The goal of this preliminary study is to evaluate the potential suitability of RST for predicting biological endpoints in cells from their associated gene expression profiles. Such studies are the basis for identifying potential new targets that ultimately will be integrated with chemical information in drug-discovery research. In the present work, a small literature dataset was used to assess whether the gene-expression profiles induced by 30 well-known drugs can be used to predict whether human hepatoma HepG2 cells exhibit signs of phospholipidosis after treatment with the drugs. The data in this study is cast in the form of a decision table (DT), whose rows are associated with the 30 drugs and whose columns are associated with the drug-induced expression levels of 17 genes, called condition attributes in RST, plus a column that is associated with the single decision attribute that characterizes whether or not cells exhibit drug-induced phospholipidosis. The gene expression levels provide a means for partitioning the drugs into equivalence classes called indiscernibility classes in RST, such that none of the drugs in a given class can be distinguished from any other drugs in that class on the basis of their drug-induced gene expression levels. One of the powers of RST is that it provides a systematic, mathematically rigorous method for removing superfluous information. The remaining relevant information can then be expressed in terms of simple, linguistic rules that significantly enhance communication among scientists, especially those not conversant with RST. In this work, the RST approach allowed easy identification of the strongest relationships existing between drug-induced gene-expression profiles and the occurrence or nonoccurrence of phospholipidosis in the HepG2 cells. This study suggests that RST may be an efficient and effective tool for analyzing gene-expression levels in small datasets. Future studies will examine the suitability of the RST approach to larger and more complex datasets. © 2014 John Wiley & Sons, Inc.},
author_keywords={Association rules;  Drug discovery;  Drug-induced phospholipidosis;  Gene expression profiles;  Rough set theory},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{NoAuthor2013,
title={2013 International Conference on Vehicle and Mechanical Engineering and Information Technology, VMEIT 2013},
journal={Applied Mechanics and Materials},
year={2013},
volume={380-384},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885743159&partnerID=40&md5=61e7ab639d126a95ee5461f032e675e0},
abstract={The proceedings contain 1094 papers. The special focus in this conference is on Material Science, Manufacturing and Machining Technologies, Management and Economic Aspects in Enterprises. The topics include: Main drive vehicle of two-stage driving axle design; light bus drive axle design; research status and prospect on dynamics of tank automotive; the optimization for aircraft carrier main dimensions; performance analysis of the new helicopter-lift device; the calculation model and correction method of identifying deflexion of oil tank; influence for brake torque of hydraulic retarder with shape of circulation circle; prediction on vehicle crash acceleration based on circle of constant acceleration method; analysis of kinematics and throughput of the shotcrete machine; force analysis of petticoat valve of shotcrete machine based on fluent; acoustic parts in vehicle sound transmission loss test method research; the powertrain in vehicle sound power test method research; parametric design of grid plate type peanut picking machine; influence and analysis of temperature rise to principal spindle's rotating error test; modal analysis of linear guide way junction surface; study on the utilization of regenerative braking energy for high-speed railways; design of a new unlock mechanism for fuel tank catapult; frequency reliability analysis of diamond circular saw blade; the parametric design for hydraulic cylinder based on solidworks; statics and modal analysis for large vibrating screen; analysis and simulation on automobile airbag compression test; high-voltage converter technology applied in coal mining ventilator; design and kinematic analysis of reciprocating cutters; a hole-punching system for the pot-seedling hole-punching machine; finite element analysis for assembly fixtures based on ANSYS; electric scissor aerial work platform solenoid valve research; in the wind tunnel simulation defroster control study; brake distance calculation of CRH; research on optimization of water jet propulsion; mathematical modeling and robust control for beam reheating furnace; application of LED light source in the flow imaging; modeling and simulation of turning characteristic of batoid; the analysis of traffic flow model; a real-time traffic lights scheduling strategy; the study of control strategy of multi-microgrid based on AC bus; research and implementation of electric control system; the design of computer integrated control system for electron beam welder; a novel control strategy of PWM rectifier; control and simulation of spacecraft's attitude control based on quaternions; the design for tension control system of FOG coil winding; the design and control of the humanoid walking robot; design of control system of construction elevator based on PLC; simulation and analysis of impact factor on fuzzy PID controller; a system of computer optimization control for catalytic cracking; the application of neural network in computer control; research and analysis about static synchronous compensator control; fuzzy adaptive control of a Chinese medicine sugar precipitation process; study on control scheme of reheating furnace of steel rolling optimization; control system of smart home based on cloud monitoring system; fast collision detection and deformation of soft tissue in virtual surgery; real-time bus video monitoring system based on 3G network; design of general agricultural wireless monitoring system based on zigbee; the application of PSD in vibration measurment; development of online oil control valve detection system; the parameters measurement of the network performance; the method for real-time length measurement of fiber winding; development of the real-time measuring system based on video image; monitoring system of gate control TWT radar transmitter; fault diagnosis of aircraft engine based on order analysis; operating system for the dynamic belt measurement; fault diagnosis technology of equipment system; analysis of over-voltage failure in the computer room; research and design of wireless video monitoring; research on a quantitative packing weighing system of sticky foods; evaluation of visual fatigue caused by 3D display; a fiber-optic velocimeter using heterodyne technique; on-demand routing algorithm base on energy balancing in MANET; simulating liquid dynamics by a particle-based method; the principle and implementation of novel FRC algorithm; an improved iris localization algorithm based on curve fitting; an ELM based barcode localization algorithm; a novel disruption operator in particle swarm optimization; research on clustering algorithm for wireless sensor networks; efficient bounded model checking for LTL; analysis on children custody decision making model; research on performance evaluation based on fuzzy analysis; ontology-based K-means clustering algorithm analysis; multi-response linear polynomial regression models designs; the role of modelling in agile methodologies; an environmental personalized tag recommendation model; GMDH network model based on simulated annealing and genetic algorithm; agent-based simulation method of complex system; ontology-based CRM for bank customers; a two factor authentication algorithm for medical registration platform; a kind of method to parallelize AC algorithm; on the positive definite solutions of a nonlinear matrix equation; an improved niche genetic algorithm; improved genetic algorithms for software testing cases generation; fast block matching algorithm for ray space data compression; study on an algorithm for SAR raw data compression; Ml-KNN algorithm based on frequent item sets; an improved particle swarm optimization; a Ga algorithm based on niche and discrete; parallel route optimization algorithm of central guidance; an improved algorithm based on AC-BM algorithm; simulation on 3D computer dynamic cloth simulation process; extended probabilistic data association algorithm; the model of fuzzy retrieval based on external index; an improved dijkstras algorithm based on search strategy; application of wavelet algorithm in spectral analysis; decomposition of reflexive differential-difference polynomial systems; association rules mining algorithm based on linked list; test and analysis GPU-accelerated in molecular dynamics simulation; a potential field model avoiding local minimum in pedestrian simulation; a new prediction method for chaotic time series; a multi-point source thermal radiation model of pool fire; a clustering method based on K-means algorithm; model of a traffic circle; bubbling sort algorithm application based on C programming language; proactive reliability analysis for electric vehicles; the research on the embedded vehicle dynamics simulation method; research on voyage path methods in medical visualization; point cloud segmentation based on moving probability; enlarge the field of view of nano CT in synchrotron radiation; 3D reconstruction and analysis base on shape matching; a new q-learning based spectrum access strategy; running OpenFOAM in high performance computer; a microblog classification scheme based on partial indexing; research of the association rules based on elderly people.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Wang20132443,
author={Wang, X. and Wang, Y. and Bi, H. and Gao, R.},
title={Heat-supply network state prediction based on optimum combination model of data mining},
journal={Journal of Applied Sciences},
year={2013},
volume={13},
number={13},
pages={2443-2449},
doi={10.3923/jas.2013.2443.2449},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885238172&doi=10.3923%2fjas.2013.2443.2449&partnerID=40&md5=f55858ea19dfc88ea7318c63407eba66},
abstract={At present, a massive portion of data stored in the heat-supply network management system has formed the data grave which does not embody the intrinsic properties of data. To solve this problem, it is particularly important to take effective mining methods which reuse the existing historical data to improve the current system. In this paper, we first dispersed the continuous attribute information based on both entropy and importance of attribute to preprocess the data of heat-supply network. Then we exploited three kinds of algorithm for data mining, namely, classification and prediction based on the decision tree, cluster analysis based on the K-mean partition and association rules mining based on the frequent itemset model. Finally, we established forecasting model combining the results of three aforementioned mining schemes. The model was then embedded into the prediction module of present system and the results demonstrated the proposed scheme can improve the prediction performance efficiently. © 2013 Asian Network for Scientific Information.},
author_keywords={Clustering analysis;  Combination;  Data preprocessing;  Decision tree classification;  Frequent itemset},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bian2013845,
author={Bian, X. and Krim, H.},
title={Activity video analysis via operator-based local embedding},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2013},
volume={8085 LNCS},
pages={845-852},
doi={10.1007/978-3-642-40020-9_95},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884911273&doi=10.1007%2f978-3-642-40020-9_95&partnerID=40&md5=e1bf01ebc939fc8ea3c59bfe6087991a},
abstract={High dimensional data sequences, such as video clips, can be modeled as trajectories in a high dimensional space, and usually exhibit a low dimensional structure intrinsic to each distinct class of data sequence [1]. In this paper, we proposed a novel geometric framework to investigate the temporal relations as well as spatial features in a video sequence. Important visual features are preserved by mapping a high dimensional video sequence to operators in a circulant operator space (image operator space). The corresponding operator sequence is subsequently embedded into a low dimensional space, in which the temporal dynamics of each sequence is well preserved. In addition, an algorithm for human activity video classification is implemented by employing Markov models in the low dimensional embedding space, and illustrating examples and classification performance are presented. © 2013 Springer-Verlag.},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Cleophas20131,
author={Cleophas, T.J. and Zwinderman, A.H.},
title={Machine learning in medicine: Part three},
journal={Machine Learning in Medicine: Part Three},
year={2013},
volume={9789400778696},
pages={1-224},
doi={10.1007/978-94-007-7869-6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931308145&doi=10.1007%2f978-94-007-7869-6&partnerID=40&md5=2dcba4b7b328f233c69bb101b3e1dcc4},
abstract={Machine learning is concerned with the analysis of large data and multiple variables. It is also often more sensitive than traditional statistical methods to analyze small data. The first and second volumes reviewed subjects like optimal scaling, neural networks, factor analysis, partial least squares, discriminant analysis, canonical analysis, fuzzy modeling, various clustering models, support vector machines, Bayesian networks, discrete wavelet analysis, association rule learning, anomaly detection, and correspondence analysis. This third volume addresses more advanced methods and includes subjects like evolutionary programming, stochastic methods, complex sampling, optional binning, Newton's methods, decision trees, and other subjects. Both the theoretical bases and the step by step analyses are described for the benefit of non-mathematical readers. Each chapter can be studied without the need to consult other chapters. Traditional statistical tests are, sometimes, priors to machine learning methods, and they are also, sometimes, used as contrast tests. To those wishing to obtain more knowledge of them, we recommend to additionally study (1) Statistics Applied to Clinical Studies 5th Edition 2012, (2) SPSS for Starters Part One and Two 2012, and (3) Statistical Analysis of Clinical Data on a Pocket Calculator Part One and Two 2012, written by the same authors, and edited by Springer, New York. © 2013 Springer Science+Business Media Dordrecht. All rights are reserved.},
document_type={Book},
source={Scopus},
}

@ARTICLE{Zhang201394,
author={Zhang, F. and Zhang, Y. and Bakos, J.D.},
title={Accelerating frequent itemset mining on graphics processing units},
journal={Journal of Supercomputing},
year={2013},
volume={66},
number={1},
pages={94-117},
doi={10.1007/s11227-013-0887-x},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890551189&doi=10.1007%2fs11227-013-0887-x&partnerID=40&md5=63e64bcc3823fe3de7bc7e7a0a0cf1a5},
abstract={In this paper we describe a new parallel Frequent Itemset Mining algorithm called "Frontier Expansion." This implementation is optimized to achieve high performance on a heterogeneous platform consisting of a shared memory multiprocessor and multiple Graphics Processing Unit (GPU) coprocessors. Frontier Expansion is an improved data-parallel algorithm derived from the Equivalent Class Clustering (Eclat) method, in which a partial breadth-first search is utilized to exploit maximum parallelism while being constrained by the available memory capacity. In our approach, the vertical transaction lists are represented using a "bitset" representation and operated using wide bitwise operations across multiple threads on a GPU. We evaluate our approach using four NVIDIA Tesla GPUs and observed a 6-30× speedup relative to state-of-the-art sequential Eclat and FPGrowth implementations executed on a multicore CPU. © 2013 Springer Science+Business Media New York.},
author_keywords={Association rule mining;  CUDA GPU computing;  Frequent itemset mining;  Parallel computing},
document_type={Article},
source={Scopus},
}

@ARTICLE{NoAuthor2013,
title={2013 2nd International Conference on Measurement, Instrumentation and Automation, ICMIA 2013},
journal={Applied Mechanics and Materials},
year={2013},
volume={336-338},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883010990&partnerID=40&md5=ef0aa34c96311c4499306039f392e225},
abstract={The proceedings contain 503 papers. The special focus in this conference is on Virtual Instrument and Automation Instruments, Intelligent Electrician, Electricity Instruments, Sensors, Control System Modeling and Simulation Technology, Fluid Engineering and Control Technology, Mechatronics, Industrial Robot and Automation, Auto Control System, Electronic, Microelectronic and Embedded Systems and Communication Technology. The topics include: Multi-time averaging TDCs implemented in an actel flash-based FPGA; digital implementation and simulation of the ZVS control scheme; the key problem of portable food traceability electronic weigher design; design of conversion circuit for intellect vortex flow-meter; a magnet-coupled piezoelectric vibration energy harvester; analysis of active clamp forward converter of UAV; control of hospital wireless calling system based on SCM; some considerations of the pulse power switch centered on thyristor device; realization for new type system of energy recovery; development of PCBs functional tester with relay matrix network; a digitalized implementation of time-of-flight measurement for cable fault location; EMC on fiber-optic transceivers under EFT; study on magnetic induced polarization technology and instruments; detection and communication of the intelligent electric meter; the application of sensor technology in sports field; WSN energy management model based on multiple mobile agent; the application of sensor technology in physical training; design of sensor for detecting corona discharge signal in specific band; dynamic technique control on sectional warping machine by means of sensors; method of attitude measurement based on the geomagnetic and gyroscope; a discussion about FBG sensors application of crane SHM system; research on development and application of new particulate matter sensor; pressure-based soft sensors for fast volume estimation; an integrated GPS/INS navigation system for land vehicle; research on dual bellows FBG pressure sensor; wireless sensor for oil leakage detection of depots; a method of information fusion on the unmanned weapon system; a lightweight key management protocol for hierarchical sensor networks; seamless INS/GPS integration based on support vector machines; calibration of vector hydrophones in deep water; study on tensile strains in concrete bridge girders; software test of wireless vibration nodes of nuclear power plants; adaptive kalman filter for INS/GPS integrated navigation system; visual odometry and 3D mapping in indoor environments; gossip-based averaging estimation and optimization; design and simulation of portable data terminal for agriculture equipment; a design of infrared spots tracking platform based on the camera; lattice ordered evaluation method of equipment response event to voltage sag; application of kalman filter in the large-diameter antenna of ship-borne; adaptive observer of one-sided lipschitz nonlinear systems; fuzzy PID temperature control system of reaction kettle based on PLC; research on distillation fuzzy decoupling control system; an approach for short term traffic flow forecasting based on fuzzy logic control; vector decoupling control strategy for three-phase voltage source PWM rectifier; driven wheeled robot based on fuzzy PID algorithm control research; synchronization of Liu chaotic system with fractional-order; the design of output feedback controller for inverted pendulum system; semi-physical simulation platform design base on FMI; full-order nonlinear model and analysis of flyback converters in DCM; fault simulation of tanks sight based on optical parts fretting; control strategy of wind photovoltaic and energy storage system stability running; gird Lagrange stability analysis based on quasi periodic analysis; simulation of an opposed-piston four-stroke free-piston generator; simulation research of CVT variable fertilization control system; study on application of inventory control models; design of intelligent full-color LED display-screen system base on ARM and FPGA; development of virtual simulation in manufacturing industry; the application of numerical simulation technology in road engineering; research on simulation of Fischer-tropsch synthesis based on virtual assembly; a SVC optimal configuration method in wind power grid system; road feel design for vehicle steer-by-wire system based on joystick; a novel starting method for sensorless brushless DC motor with low cost; mechanical simulation of knee movement in basketball shooting; an agent-based battlefield simulation framework for decision support; study on the control system of electric vehicle anti-rollover based on DSP; PLC control system of cutting fixed-length plates and simulation debugging; the design and the test of the electric brake system controller; a near optimal midcourse guidance law for air-to-air missile; HSIC algorithm of process control; speed control based on the intelligent PID algorithm for robotic fish; modeling of incompressible flow inside the involute channel; energy conversion for gas isentropic compression process with high speed rotation; time-frequency analysis for power system oscillations; effects of structure parameters on performance of DSPM motor; digital controller design for sense mode of micro-machined gyroscope; development of high damping magneto-rheological mount for ship engines; slid mode VSC for aircraft anti-skid braking system with index reaching law; vehicle state and friction force estimation based on FPGA; design of test and adjustment system for coordinator of infrared seeker; the design of INS under PBN; research status and key technology of portable open-loop insulin pump; on obstacle avoidance of multiple ultrasonic sensors based on aloha robot; drive system design of a two-wheel differential tracked mobile robot; effect of air density on output power of wind turbine; the design of logistics handling robot based on MCU; research on switch linearity hybrid power converter; dynamic modeling and simulation of a novel wall-climbing robot; distributed intelligent control system design based on CAN bus; design of intelligent temperature controller for UAV airborne terminal; design of CAN-bus control modules for passenger car; environmental automatic control system of HMG-2 type solar greenhouse; process monitoring and adjustment based on optimal RBF network; behavior control of an automatic inspection robot for insulators; study on rice transplanter experiment based on virtual reality; principles of computer aided design in practice research; vibration analysis of a large pressure vessel using the FEA; a prototype monitoring system for automotive CAN bus gauge; VR-based interactive experienced platform for showroom; interactive digital campus visual navigation system design and development; research on avatar-included virtual environment modeling and testing; research on switching performance of static induction thyristors; a novel method for onsite commissioning of wide-area protection; design of remote monitoring system based on embedded system; design of calcium tester based on embedded technology; design on embedded processor with configurable divider; pipelined RISC processor design and FPGA implementation; design principle and data analysis of clamp meter; a novel covert communication method based on WCDMA; design and implementation of high-dynamic satellite channel emulator; automatic recognition of M-Nary digital modulation signals; design of Ka-band inset-fed conical conformal patch antenna; fade statistic analysis of SC in distributed antenna system; the research of chirp signal based on GNU radio and USRP; a mobility-aware task scheduling model in mobile grid; study of load shedding by IEC61850 implementation; improved GPSR routing protocol in VANETs; ECU calibration system based on ASAP; an implementation of configurable SIMD core on FPGA; towards learning web service applied to heterogenous systems; data conversion technique of heterogeneous system based on ESB; design of a new intelligence support system; the construction and design of personalized course website; mobile ordering system based on android; study on data resource policy in cloud computing environment; design and study of website architecture model; review of Chinese short text classification; text concept relation acquisition based on ontology similarity; strategies for sensitive association rule hiding; copulas with given rational function sections; frequency hopping prediction based on multi-kernel SVM; solutions for a class of the higher Diophantine equation; study on flexible dynamic visualization techniques; study on safety system of accounting in E-commerce; the research of fire risk factor evaluation; modified stochastic gradient algorithm for Hammerstein systems; a new method for target motion analysis; research of intrusion detection based on ensemble learning model; a security strategy of mobile agent system; design on the sink node for wireless network; GSM intelligent home security system based on MCU; study on signaling storm in 3G networks; manufacturer decision analysis on RFID adoption; internet of things and RFID technology; design and implementation of energy system based on smart grid; fault-tolerance of hierarchical power management in data center and study on household registration management system.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2013,
title={2013 2nd International Conference on Measurement, Instrumentation and Automation, ICMIA 2013},
journal={Applied Mechanics and Materials},
year={2013},
volume={333-335},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882932793&partnerID=40&md5=e308856d2de73cc7df987d57d6fe9317},
abstract={The proceedings contain 498 papers. The special focus in this conference is on Measurement Theory and Its Application, Data Acquisition, Signal and Data Processing Technology and System, Multimedia Signal Processing, Image and Video Processing, Intelligence Algorithm, Optimization Algorithm and Artificial Intelligence, Error Theory and Compensation Techniques, Detection and Monitoring. The topics include: 3D measurement method of underground displacement based on hall and MR effect; study on tank capacity table measuring model after the storage tank displacement; rapid measurement of power transformer winding DC resistance; three-dimensional measurement system based on line laser; liquid level measurement system design based on laser displacement sensor; an overview of uncertainty in measurement and its application in ship hydrodynamics; research on the tube system for the pressure measurement; reconfigurable measurement method based on mobile internet; articulated arm length calibration for cantilever coordinate measuring machine; an effective solution to improve GPS position precision; the extension of geodesics; a spatial measurement and statistics method to forecast ore deposits; improvement and application of the maximum bubble pressure tensiometer; dynamic characteristics test of a bearing micro workbench used for fiber measurement; a geo-acoustic model based on empirical formula; load measurement method of the MW class wind turbine; attitude angle measurement method based on the three-dimensional accelerometer; the design of simulating different altitudes ionic mobility measuring device; a twice calibrating method for binocular stereovision system; rotating accuracy measurement system of spindle based on three point method; design of analysis software for measured RCS data; automatic furnace measurement system based on the nuclear scale; soft measurement of heat flux for TEC based dynamic thermal management; the technology of circular parts precise measurement based on binocular calibration; system design of AC open-loop gain measurement of amplifier; error analysis and calibration of infra-red temperature measurement; design of ultrasonic distance measurement system based on microcontroller; research of EMT system spatial resolution; digital measurement system for ship draft survey; a dynamic voltage compensation method for improving weighing accuracy; the research on the methods of the aero engine blades evaluation; a novel method for azimuth estimate of ultra short base line positioning system; test methods for measuring mechanical parameter of simulated lunar dust; on-line measurement of fiber diameters along spinning line; online acquisition and display of track parameters based on visual C++; design of data acquisition system for a certain type of IR Seeker; microbial biosensor data acquisition system based on CC2530; a compact design for acquiring data; real-time data acquisition system for remote vital sign; OPC client application for CNC system reliability testing; high-speed data acquisition system based on FPGA in missile-borne test system; temperature and humidity monitoring system based on CC2530; synchronization design for multi-channel data acquisition system; a web-based remote laboratory using SCADA technology; the demodulate and denoising of vibration signal under very noise condition; de-noising method for wayside train bearings acoustic signal based on Doppler shift; study on filtering methods of airborne gravity; the algorithm of digital modulation recognition based on stochastic; a new approach for optimal decomposition level selection in wavelet de-noising; coal-gangue acoustic signal recognition based on sparse representation; an optimised signal reconstruction algorithm for compressed sensing; anti-jamming performance study of adaptive antenna; beam signal stretch method based on square process; design of a signal processing system for digital laser altimeter; research on performance of analog to information converter; anti-ship missile target selection method based on the target RCS information; DFCWs design based on improved DPSO; DOA estimation for L-shaped array based on complex FastICA; parallel channel equalizer for mobile OFDM baseband receivers; application of motion detection algorithm in patient monitoring system; a new method for phase difference estimation based on time-varying signal model; a method on realizing signal generator for arbitrary waveform; improved stack algorithm for MIMO systems; MATLAB simulation of DBPM digital down conversion; a sufficient condition of shearlet frame with several generators; application of virtual reality technology on digital scenic spot; Huffman coding and applications in compression for vector maps; automatic transcription of piano music using audio-vision fusion; an improved direct current prediction method for intra coding; improved algorithm for pitch detection and harmonic separation; acoustic events detection in dissimilarity measurement space; effect of speaking rate on Chinese speech recognition for foreign students; design and realization of the birdsong analysis and identification system; research on safety vehicle distance recognition based on stereo vision and DSP; object detection algorithm in traffic video surveillance based on compressed sensing; an variable coefficient images denoising method; a real-time dynamic gesture recognition system; study of digital character recognition based on Bp neural networks; extraction of the geometric features from the vacuum switching arc images; study on compressed representation of graph; edge detection of the impulse noise pollution image based on the rough set; polynomial correction of digital image based on MATLAB; study on detection of preceding vehicles based on computer vision; experiments on image processing for micro-assembly; study on the generation model of weighted visual codebook for action recognition; stereo matching algorithm based on edge feature of segmented image; segmentation-based automatic white balance algorithm; a novel image degradation scheme based on reversible watermarking; research on wrong match pairs elimination of SIFT algorithm; feature-based GDLOH deformable registration for CT lung image; digital image processing and coordinate transformation for Vic-3D system; moving objects detection based on Gaussian models with HSV; wafer image registration based on Hough transform; sub-pixel measurement of the cable sheath materials thickness; digital watermarking of high security based on holography; wavelet digital watermarking algorithm on the basis of SVD decomposition; improved watershed algorithm based on morphology and distance transform; new research progress in image retrieval; an instrument of palm vein pattern recognition; a blind watermarking algorithm for digital image; remote sensing image fusion of worldview-2 satellite data; applications and new research of visual saliency and attention; association analysis of NDVI changes and topographic factors; survey on image shadow detection and removal; a model of target detection in variegated natural scene based on visual attention; research of lossless digital watermarking technology; an efficient weighted association rules mining algorithm; the study and application of PI algorithm; prediction of campus fire based on SVM; a clustering algorithm based on variance-similarity; an effective K-means clustering based SVM algorithm; affective-cognitive reward model based on emotional interactions; a combined local best particle swarm optimization algorithm; cloud particle swarm optimization for vehicle routing problem; iterative methods for strictly pseudo-contractive mappings; multiple kernel feature fusion using kernel fisher method; swarm automated planning algorithm with repairing operators; research of microwave detection techniques; the analysis of wind power generation tower based on SSI effect; fault diagnostic equipment of electrical system based on embedded system; the defect identification of LED chips based on Bayesian classifier; study on PPP-BOTDA technology for concrete crack monitoring; study on application of GPR to quality detection of tunnel lining; availability analysis for airborne ECM system automatic test system; a new method in gears fault diagnosis; fault recognition of gear pump based on EMD neural network; the study of construction settlement observation; quantitative evaluation of laboratory testing capability; development of battery test system for electric vehicle; portable fault diagnostic system based on network and PDA; knowledge-based fault diagnostic system using binary fault tree; theory and application of fracture dynamics in concrete; research of flat heat pipe radiator applied in LED lighting; experimental study on loading accuracy of a disc brake; study on supplies loading of equipment support force; horizontal force on tire gantry crane; design and manufacture of 3D flat woven fabric; analysis on construction delay of suburban roads; digital games and independent learning; study online course evaluation system; E-learning exploration based on cloud computing; reliability analysis of engineering structures; design of digital test platform for diesel engine; XVL based study on 3D virtual product display system; signal generator design based on the FPGA and virtual dressing based on the kinect peripherals.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2013,
title={2013 2nd International Conference on Manufacturing Engineering and Process, ICMEP 2013},
journal={Applied Mechanics and Materials},
year={2013},
volume={325-326},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879907070&partnerID=40&md5=e4acb1718d715e55e7a20a4642117209},
abstract={The proceedings contain 373 papers. The special focus in this conference is on Materials Engineering and Technology, Mechanical Engineering, Design Technology and Engineering, Applied Thermodynamics, Heat Transfer, Energy Conversion, Electrical Engineering and Electric Machines, Power System and Energy Engineering, Its Applications, Instrumentation, Measurement Technologies, Analysis and Methodology, Electronics and Integrated Circuits, Embedded Technology and Applications, Mechatronics and Robotics, Modern Control, Automation and Reverse Engineering, Civil Engineering, Manufacturing and Industrial Engineering, Management Applications, Mathematics, Signal Processing and Data Mining, Information Technologies and Networks. The topics include: research on biological properties of PEEK based composites; optimizing the drilling process of multi-layer materials using vibration analysis; development of materials characterization procedure for composite aircraft; mechanical properties of concrete with compound mineral admixtures; study on the strength design of cold deformation strengthening material; early age cracking characteristic of concrete with compound admixtures; a research on the performance of grey chassis organic coating on vehicle equipment; minimization of total processing time in semiconductor photolithography process; process practice of refining for free cutting austenite stainless steel; analysis of effects of high temperature on asphalt binder; screening for the strain galactomyces sp. producing bioflocculant by UV mutagenesis; study of multiple quantum beats in atomic wavepackets; a damage model for prediction of the open-hole strength of glare laminates; recovery of copper from flotation tailings by leaching; intricacy of the transit manifold concept paid-off by computational accuracy; a study of vertical vibration transmissibility by the human body; topology optimization of the transmission shift fork; numerical simulation of electrohydrodynamic (EHD) atomization in the cone-jet mode; trajectory planning for the moving boundary in three dimensional DEM simulations; optimal design of LCD module under random vibration; multi-objective robust design of loader transmission based on genetic algorithm; on dynamics analysis of a novel three-dimensional autonomous chaotic system; reversing gear failure analysis of mini-car variator base on ANSYS software; kinematics and dynamics simulation of a new type direct-drive NC turret tool post; love wave in an isotropic half-space with a graded layer; design and improvement on a stress loading device for ligament tissue engineering; a high-frequency high-voltage excitation melting ice power design; CAD designing for stamped tooth wheels; tools for automated design of intermittent mechanisms with radial parallel cams; CAD analysis applied to self-centering compliant grippers; the well-posedness of a two-unit standby redundant electronic equipment system; fuzzy robust design of cycloid pin wheel reducer based on genetic algorithms; hybrid modeling based on multiple range image; the application of animation logo in modern visual system; a new P2P streaming media VOD system based on window; a mapping simulation of code generation for partitioned system; a new method for translating NFA into DFA; research of prewarning pipe-sticking based on neural network; wireless mesh network technical security performance analysis; a new hybrid algorithm based on artificial fish swarm algorithm and genetic algorithm for VRP; achieving quick trust transmission in P2P network based on matrix operation; implementation of the DES algorithm on EDA box; an efficient non-blocking commit protocol; design and analysis of CAN user layer communication protocol; mobile storage and data security management research; improved blind equalization algorithm and simulation; a improved infrared and visible images matching based on SURF; rough clustering method based on particle swarm optimization algorithm; the research and application of association rules algorithm; a new method for sub-pixel TDICCD image registration; an image matching algorithm based on SUSAN-SIFT algorithm and fast 3-D feature point detector based on Harris.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Rameshkumar2013300,
author={Rameshkumar, K. and Sambath, M. and Ravi, S.},
title={Relevant association rule mining from medical dataset using new irrelevant rule elimination technique},
journal={2013 International Conference on Information Communication and Embedded Systems, ICICES 2013},
year={2013},
pages={300-304},
doi={10.1109/ICICES.2013.6508351},
art_number={6508351},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879853453&doi=10.1109%2fICICES.2013.6508351&partnerID=40&md5=e8f7aab854c46c0916864cdf4298b971},
abstract={Association rule mining (ARM) is an emerging research in data mining. It extracts interesting association or correlation relationship in the large volume of transactions. Apriori based algorithms have two steps. First step is to find the frequent item set from the transactions. Second step is to construct the association rule. If ARM applied with medical dataset, it produces huge quantity of rules; most of these rules are irrelevant to the transaction. These irrelevant rules consume more memory space and misguide the decision making. Here irrelevant rule reduction is important. This paper proposes the n-cross validation technique to reduce association rules which are irrelevant to the transaction set. The proposed approach used partition based approaches are supported to association rule validation. The proposed algorithm called as PVARM (Partition based Validation for Association Rule Mining). The proposed PVARM algorithm is tested with T40I10D100K and heart disease prediction. The performance analysis attempted with Apriori, most frequent rule mining algorithm and non redundant rule mining algorithm to study the efficiency of proposed PVARM. The proposed work reduces large number of irrelevant rules and produces new set of rules with high confidence. It is much use to mine medical relevant rule mining. © 2013 IEEE.},
author_keywords={association rule mining;  data mining;  frequent itemset mining;  rule elimination},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Salem2013371,
author={Salem, R. and Boussaïd, O. and Darmont, J.},
title={Active XML-based Web data integration},
journal={Information Systems Frontiers},
year={2013},
volume={15},
number={3},
pages={371-398},
doi={10.1007/s10796-012-9405-6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878987960&doi=10.1007%2fs10796-012-9405-6&partnerID=40&md5=4ca64e2a60de1ccbaa90cf326e83a78f},
abstract={Today, the Web is the largest source of information worldwide. There is currently a strong trend for decision-making applications such as Data Warehousing (DW) and Business Intelligence (BI) to move onto the Web, especially in the cloud. Integrating data into DW/BI applications is a critical and time-consuming task. To make better decisions in DW/BI applications, next generation data integration poses new requirements to data integration systems, over those posed by traditional data integration. In this paper, we propose a generic, metadata-based, service-oriented, and event-driven approach for integrating Web data timely and autonomously. Beside handling data heterogeneity, distribution and interoperability, our approach satisfies near real-time requirements and realize active data integration. For this sake, we design and develop a framework that utilizes Web standards (e.g.; XML and Web services) for tackling data heterogeneity, distribution and interoperability issues. Moreover, our framework utilizes Active XML (AXML) to warehouse passive data as well as services to integrate active and dynamic data on-the-fly. AXML embedded services and changes detection services ensure near real-time data integration. Furthermore, the idea of integrating Web data actively and autonomously revolves around mining events logged by the data integration environment. Therefore, we propose an incremental XML-based algorithm for mining association rules from logged events. Then, we define active rules dynamically upon mined data to automate and reactivate integration tasks. Finally, as a proof of concept, we implement a framework prototype as a Web application using open-source tools. © 2013 Springer Science+Business Media New York.},
author_keywords={Active rules;  Event mining;  Integration services;  Metadata;  Real-time Web data integration},
document_type={Article},
source={Scopus},
}

@ARTICLE{Yang20132845,
author={Yang, G.},
title={A novel method for mining association rules from continuous attributes based on cultural immune algorithm},
journal={Journal of Information and Computational Science},
year={2013},
volume={10},
number={9},
pages={2845-2853},
doi={10.12733/jics20102086},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879528607&doi=10.12733%2fjics20102086&partnerID=40&md5=6108d348f987e326ac645cbd9db1d42a},
abstract={It is an important topic to mine association rules from data with continuous attributes. A novel model based on cultural algorithm and immune algorithm is proposed in this paper. This algorithm uses the cultural algorithm framework in which the immune algorithm embedded. The immune algorithm is used to discretize the continuous attributes and search association rules in the database rapidly. The cultural algorithm is used to obtain the commonly accepted beliefs in order to guide and speed up the search. The new algorithm integrates the discretization, attributes reduction and association rules mining together. In addition, a new diversity operator is put forward in order to discover global solutions. The experiment shows that the new algorithm is superior to immune algorithm in convergence speed and the rule's accuracy. Copyright © 2013 Binary Information Press.},
author_keywords={Association rules;  Continuous attribute;  Cultural algorithm;  Immune algorithm},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhang20131679,
author={Zhang, Y. and Pei, Z. and Shi, P.},
title={Association rule mining based on topology for attributes of multi-valued information systems},
journal={International Journal of Innovative Computing, Information and Control},
year={2013},
volume={9},
number={4},
pages={1679-1690},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875753147&partnerID=40&md5=97a0d3f1c1a8ffcc98fa9846f0fa42ae},
abstract={Association rules mining aims to extract associations and causal structures among sets of frequent items or attributes in a large database. In practice, interesting association rules satisfy predefined minimum support and minimum confidence thresholds. In this paper, we propose a new method to generate association rules which is focused on not only minimum support and minimum confidence thresholds but the shortest length among templates as well. The method is started by a transformation of a multi-valued information system into a two-valued information system. Then, we obtain a binary relation on attributes of the two-valued information system and deduce a topology for the attributes based on the binary relation. Formally, we present two kinds of lattice of the topology for the attributes, i.e., the lattice of the topology and the quotient lattice of the topology which is deduced by the support of subset of attributes. Finally, a new association rules mining method is proposed in the quotient lattice of the topology. Compared with existing association rules mining methods, three contributions of our method were achieved as: (1) all templates of association rules are embedded in the quotient lattice of the topology for attributes; (2) templates with minimum support are shown in the quotient lattice, and association rules with confidence 1 can be mined from equivalent classes of the quotient lattice; (3) association rules with minimum support, confidence 1 and the shortest length among templates can be extracted from the quotient lattice. Examples show that our method is an alternative approach for association rules mining. © 2013 ICIC International.},
author_keywords={Association rules;  Knowledge discovery in databases;  Lattice;  Topology},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Lekha2013,
author={Lekha, A. and Srikrishna, C.V. and Vinod, V.},
title={Utility of association rule mining: A case study using Weka tool},
journal={2013 International Conference on Emerging Trends in VLSI, Embedded System, Nano Electronics and Telecommunication System, ICEVENT 2013},
year={2013},
doi={10.1109/ICEVENT.2013.6496554},
art_number={6496554},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876780551&doi=10.1109%2fICEVENT.2013.6496554&partnerID=40&md5=578a5c273b5850151a5ded0dcf989fe4},
abstract={In this paper a few case studies pertaining to breast cancer, mushroom, larynx cancer and other datasets are studied to find the utility of association rule mining using Weka tool. Three association algorithms - Apriori, PredictiveApriori and Tertius Algorithms are employed to discuss different case studies. A comparative study of the three algorithms is also made. Further architecture for implementing the association rules on datasets using Weka is also given. The analysis reveals that although the implementation of the three algorithms gives the strong association rules they have problems with the number of cycles taken to generate the frequent itemsets, minimum support needed, memory utilized and non-numeric data. © 2013 IEEE.},
author_keywords={Apriori Algorithm;  Data Mining;  Predictive Apriori Algorithm;  Tertius Algorithm Introduction},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Cleophas20131,
author={Cleophas, T.J. and Zwinderman, A.H.},
title={Machine learning in medicine: Part two},
journal={Machine Learning in Medicine: Part Two},
year={2013},
volume={9789400768864},
pages={1-231},
doi={10.1007/978-94-007-6886-4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928853349&doi=10.1007%2f978-94-007-6886-4&partnerID=40&md5=68590eb3609495e2bbb39bcbf7c1a583},
abstract={Machine learning is concerned with the analysis of large data and multiple variables. However, it is also often more sensitive than traditional statistical methods to analyze small data. The first volume reviewed subjects like optimal scaling, neural networks, factor analysis, partial least squares, discriminant analysis, canonical analysis, and fuzzy modeling. This second volume includes various clustering models, support vector machines, Bayesian networks, discrete wavelet analysis, genetic programming, association rule learning, anomaly detection, correspondence analysis, and other subjects. Both the theoretical bases and the step by step analyses are described for the benefit of non-mathematical readers. Each chapter can be studied without the need to consult other chapters. Traditional statistical tests are, sometimes, priors to machine learning methods, and they are also, sometimes, used as contrast tests. To those wishing to obtain more knowledge of them, we recommend to additionally study (1) Statistics Applied to Clinical Studies 5th Edition 2012, (2) SPSS for Starters Part One and Two 2012, and (3) Statistical Analysis of Clinical Data on a Pocket Calculator Part One and Two 2012, written by the same authors, and edited by Springer, New York. © 2013 Springer Science+Business Media Dordrecht. All rights are reserved.},
document_type={Book},
source={Scopus},
}

@CONFERENCE{Zhang2013,
author={Zhang, B. and Becker, M.},
title={Mining complex feature correlations from software product line configurations},
journal={ACM International Conference Proceeding Series},
year={2013},
doi={10.1145/2430502.2430529},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874014856&doi=10.1145%2f2430502.2430529&partnerID=40&md5=a6b2c4b682536a8b8f5573faf721d538},
abstract={As a Software Product Line (SPL) evolves with increasing number of features and feature values, the feature correlations become extremely intricate, and the specifications of these correlations tend to be either incomplete or inconsistent with their realizations, causing misconfigurations in practice. In order to guide product configuration processes, we present a solution framework to recover complex feature correlations from existing product configurations. These correlations are further pruned automatically and validated by domain experts. During implementation, we use association mining techniques to automatically extract strong association rules as potential feature correlations. This approach is evaluated using a large-scale industrial SPL in the embedded system domain, and finally we identify a large number of complex feature correlations. © 2013 ACM.},
author_keywords={association mining;  feature correlation;  product line configuration},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Liu2013112,
author={Liu, S. and Peng, L.},
title={Analysis of coal mine hidden danger correlation based on improved apriori algorithm},
journal={Proceedings - 2013 4th International Conference on Intelligent Systems Design and Engineering Applications, ISDEA 2013},
year={2013},
pages={112-116},
doi={10.1109/ISDEA.2013.431},
art_number={6843408},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904467848&doi=10.1109%2fISDEA.2013.431&partnerID=40&md5=3024c1d117ceac4904224c64def85cc8},
abstract={This paper outlines an improved Apriori algorithm that suits coal mine hidden danger data. Then preprocess the data according to the characteristics of safety hidden danger data of coal mine workplaces, including data import and extraction. Put this algorithm embedded in a coal mine hidden danger investigation system. After this is coal mine hidden danger data association rules mining based on the improved Apriori algorithm to achieve getting valuable association rules inside the coal mine hidden dangers. Provide recommendations for improvement for enterprises in the hidden danger management and prevention and ultimately there is an important practical significance in preventing accidents and reducing the loss of the accidents. © 2013 IEEE.},
author_keywords={Apriori algorithm;  Coal;  Correlation analysis;  Hidden danger},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Niu20121085,
author={Niu, X. and Rong, S. and Wang, H. and Yu, Y.},
title={An effective rule miner for instance matching in a web of data},
journal={ACM International Conference Proceeding Series},
year={2012},
pages={1085-1094},
doi={10.1145/2396761.2398406},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871086700&doi=10.1145%2f2396761.2398406&partnerID=40&md5=3a625823ee54fb044cc37e67fe157b45},
abstract={Publishing structured data and linking them to Linking Open Data (LOD) is an ongoing effort to create a Web of data. Each newly involved data source may contain duplicated instances (entities) whose descriptions or schemata differ from those of the existing sources in LOD. To tackle this heterogeneity issue, several matching methods have been developed to link equivalent entities together. Many general-purpose matching methods which focus on similarity metrics suffer from very diverse matching results for different data source pairs. On the other hand, the dataset-specific ones leverage heuristic rules or even manual efforts to ensure the quality, which makes it impossible to apply them to other sources or domains. In this paper, we offer a third choice, a general method of automatically discovering dataset-specific matching rules. In particular, we propose a semi-supervised learning algorithm to iteratively refine matching rules and find new matches of high confidence based on these rules. This dramatically relieves the burden on users of defining rules but still gives high-quality matching results. We carry out experiments on real-world large scale data sources in LOD; the results show the effectiveness of our approach in terms of the precision of discovered matches and the number of missing matches found. Furthermore, we discuss several extensions (like similarity embedded rules, class restriction and SPARQL rewriting) to fit various applications with different requirements. © 2012 ACM.},
author_keywords={association rule mining;  em algorithm;  instance matching;  semi-supervised learning},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ali2012962,
author={Ali, S.H.},
title={Miner for OACCR: Case of medical data analysis in knowledge discovery},
journal={2012 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications, SETIT 2012},
year={2012},
pages={962-975},
doi={10.1109/SETIT.2012.6482043},
art_number={6482043},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875699631&doi=10.1109%2fSETIT.2012.6482043&partnerID=40&md5=ab7735d9d942565e50263fd1236de8b6},
abstract={Modern scientific data consist of huge datasets which gathered by a very large number of techniques and stored in much diversified and often incompatible data repositories as data of bioinformatics, geoinformatics, astroinformatics and Scientific World Wide Web. At the other hand, lack of reference data is very often responsible for poor performance of learning where one of the key problems in supervised learning is due to the insufficient size of the training dataset. Therefore, we try to suggest a new development a theoretically and practically valid tool for analyzing small of sample data remains a critical and challenging issue for researches. This paper presents a methodology for Obtaining Accurate and Comprehensible Classification Rules (OACCR) of both small and huge datasets with the use of hybrid techniques represented by knowledge discovering. In this article the searching capability of a Genetic Programming Data Construction Method (GPDCM) has been exploited for automatically creating more visual samples from the original small dataset. Add to that, this paper attempts to developing Random Forest data mining algorithm to handle missing value problem. Then database which describes depending on their components were built by Principle Component Analysis (PCA), after that, association rule algorithm to the FP-Growth algorithm (FP-Tree) was used. At the last, TreeNet classifier determines the class under which each association rules belongs to was used. The proposed methodology provides fast, Accurate and comprehensible classification rules. Also, this methodology can be use to compression dataset in two dimensions (number of features, number of records). © 2012 IEEE.},
author_keywords={Adboosting;  FP-Growth;  GPDCM;  PCA;  Random Forest},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Raheja2012813,
author={Raheja, V. and Rajan, K.S.},
title={Comparative study of association rule mining and MiSTIC in extracting spatio-temporal disease occurrences patterns},
journal={Proceedings - 12th IEEE International Conference on Data Mining Workshops, ICDMW 2012},
year={2012},
pages={813-820},
doi={10.1109/ICDMW.2012.131},
art_number={6406523},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873125592&doi=10.1109%2fICDMW.2012.131&partnerID=40&md5=663c8cf9b84d58ec2308825af0eed7c0},
abstract={Extracting interesting and useful patterns from spatio-temporal datasets is more difficult than extracting the corresponding patterns from traditional numeric and categorical data due to the complexity of spatial data types and the embedded topologies, spatial and temporal relationships, and spatial autocorrelation. The objective of epidemiology is to identify disease causes and correlating them to spatially explicit disease patterns and variations in health risks. The main issue in traditional mining of association rules in disease surveillance data is that a large number of rules are discovered, but most of them are of limited use in addressing the stated objectives or original questions asked. Moreover, not all of the generated rules are interesting (due to their inability to conclusively mine spatio-temporal prevalence and causative factors of diseases), and some rules may be ignored. These drawbacks result as these methods ignore the inherent spatiotemporal dependency in such data. This paper makes a case for the use of MiSTIC algorithm to address these issues, compare the use of traditional association rule mining in context of Salmonellosis disease management, and share new insights. An illustrative case study presented here suggests that in comparison to traditional association rule mining, even simple spatio-temporal data mining approaches taking into consideration the spatio-temporal interdependencies in disease data, can provide new and valuable scientific insights towards efficient disease surveillance and management. © 2012 IEEE.},
author_keywords={Association Rule mining;  Epidemiology;  MiSTIC;  Pattern extraction;  Spatiotemporal mining},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Fachkha2012,
author={Fachkha, C. and Bou-Harb, E. and Boukhtouta, A. and Dinh, S. and Iqbal, F. and Debbabi, M.},
title={Investigating the dark cyberspace: Profiling, threat-based analysis and correlation},
journal={7th International Conference on Risks and Security of Internet and Systems, CRiSIS 2012},
year={2012},
doi={10.1109/CRISIS.2012.6378947},
art_number={6378947},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872083809&doi=10.1109%2fCRISIS.2012.6378947&partnerID=40&md5=0f811579f6b91b36d9064ea883da9afe},
abstract={An effective approach to gather cyber threat intelligence is to collect and analyze traffic destined to unused Internet addresses known as darknets. In this paper, we elaborate on such capability by profiling darknet data. Such information could generate indicators of cyber threat activity as well as providing in-depth understanding of the nature of its traffic. Particularly, we analyze darknet packets distribution, its used transport, network and application layer protocols and pinpoint its resolved domain names. Furthermore, we identify its IP classes and destination ports as well as geo-locate its source countries. We further investigate darknet-triggered threats. The aim is to explore darknet embedded threats and categorize their severities. Finally, we contribute by exploring the inter-correlation of such threats, by applying association rule mining techniques, to build threat association rules. Specifically, we generate clusters of threats that co-occur targeting a specific victim. Such work proves that specific darknet threats are correlated. Moreover, it provides insights about threat patterns and allows the interpretation of threat scenarios. © 2012 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2012,
title={Asia Simulation Conference 2012, AsiaSim 2012},
journal={Communications in Computer and Information Science},
year={2012},
volume={324},
number={PART 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880577091&partnerID=40&md5=b7cb6d3f6b8c393d0b128fb861172333},
abstract={The proceedings contain 50 papers. The special focus in this conference is on modeling theory and technology, M and S technology on synthesized environments and virtual reality environments, pervasive computing and simulation technology, embedded computing and simulation technology, and verification/ validation/accreditation technology. The topics include: network synchronization mechanism design based on MMORPG; research of networked control system based on predictive functional control; a wireless sensor network location algorithm based on firefly algorithm; simulation research on DSDV and AODV protocol in tactical unit network; the transmission power control method for wireless sensor networks based on LQI and RSSI; research on zigbee wireless meter reading system in opnet simulator; network-in-the-loop simulation platform for control system; command and control evolutive network models for command substitution; stochastic stability analysis of MIMO networked control systems with multi-quantizers; remote iterative learning control system with duplex kalman filtering; prognostics for aircraft control surface damage based on fuzzy least squares support vector regression (FLS-SVR); the SOS simulation of network-centric information system based on agent; modeling on 3D atmospheric transmission of infrared radiation; link prediction based on weighted networks; research on product comprehensive information modeling; research on structure of communication network in smart grid; analysis of information encryption on electric communication network; using distance-based outlier detection method to handle the abnormal gateway in WSN; security in underwater acoustic sensor network; towards a biological more plausible artificial neural networks; modeling and simulation methodology of multifield coupling for hypersonic vehicle; research on target electro-optical tracking based fuzzy disturbance observer controller; comparison on H8 filter and kalman filter for initial alignment of SINS on static base; self-generating interpretable fuzzy rules model from examples; modeling and simulation on pulse compression of hybrid-modulation signal based on simulink; the reentry trajectory optimization for lifting vehicle by using gauss pseudospectral method; intelligent remote wireless streetlight monitoring system based on GPRS; research of time-delay chaotic systems via linear feedback; research on matching pattern of land used transfer alignment; the design of simulation system of GPS/INS ultra-tight integration under high dynamic environment; location based on passive RFID by using least squares SVM; fluid motion estimation based on energy constraint; numerical simulation of discrete gust response for a free flexible aircraft; a study of wireless mobile node localization algorithm based on MCL and HS; the research on association rules mining with co-evolution algorithm in high dimensional data; simulated annealing algorithm in the application of thermal reliability; parallel simulation based on GPU-acceleration; quantization based real-time simulation of continuous system in distributed environment; research on a integrated real-time simulation platform for aircraft control system; HLA collaborative simulation oriented virtual machine task scheduling strategy; scenario driven lifecycle automation of net-centric simulation; research on co-simulation task scheduling based on virtualization technology under cloud simulation; a service encapsulation method in cloud simulation platform; CAE services on cloud computing platform in South Korea.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Paul2012,
author={Paul, R. and Groza, T. and Hunter, J. and Zankl, A.},
title={Decision Support Methods for Finding Phenotype - Disorder Associations in the Bone Dysplasia Domain},
journal={PLoS ONE},
year={2012},
volume={7},
number={11},
doi={10.1371/journal.pone.0050614},
art_number={e50614},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870615111&doi=10.1371%2fjournal.pone.0050614&partnerID=40&md5=60a8b3bace103ee38be29caad496a719},
abstract={A lack of mature domain knowledge and well established guidelines makes the medical diagnosis of skeletal dysplasias (a group of rare genetic disorders) a very complex process. Machine learning techniques can facilitate objective interpretation of medical observations for the purposes of decision support. However, building decision support models using such techniques is highly problematic in the context of rare genetic disorders, because it depends on access to mature domain knowledge. This paper describes an approach for developing a decision support model in medical domains that are underpinned by relatively sparse knowledge bases. We propose a solution that combines association rule mining with the Dempster-Shafer theory (DST) to compute probabilistic associations between sets of clinical features and disorders, which can then serve as support for medical decision making (e.g., diagnosis). We show, via experimental results, that our approach is able to provide meaningful outcomes even on small datasets with sparse distributions, in addition to outperforming other Machine Learning techniques and behaving slightly better than an initial diagnosis by a clinician. © 2012 Paul et al.},
document_type={Article},
source={Scopus},
}

@ARTICLE{McArthur2012442,
author={McArthur, D.P. and Encheva, S. and Thorsen, I.},
title={Exploring the Determinants of Regional Unemployment Disparities in Small Data Sets},
journal={International Regional Science Review},
year={2012},
volume={35},
number={4},
pages={442-463},
doi={10.1177/0160017612439415},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865581364&doi=10.1177%2f0160017612439415&partnerID=40&md5=688712ec38e163b503d660bf2e165096},
abstract={While standard economic theory suggests that unemployment should be evenly distributed across space, casual observation of unemployment rates shows that this is not the case. This has led to the development of a substantial literature on the topic. Due to the complexity of the problem, it is not always clear what the root cause is. This is particularly true when considering a small geographic area with limited data. This article will explore what insights can be gained through the use of formal concept analysis and association rules. It is hoped that these techniques will be of use to both theoreticians and policy makers. © 2012 SAGE Publications.},
author_keywords={association rules;  formal concept analysis;  small datasets;  unemployment disparities},
document_type={Review},
source={Scopus},
}

@ARTICLE{Wever-Pinzon2012857,
author={Wever-Pinzon, O. and Suma, V. and Ahuja, A. and Romero, J. and Sareen, N. and Henry, S.A. and De Benedetti Zunino, M. and Chaudhry, F.F. and Suryadevara, R.S. and Sherrid, M.V. and Chaudhry, F.A.},
title={Safety of echocardiographic contrast in hospitalized patients with pulmonary hypertension: A multi-center study},
journal={European Heart Journal Cardiovascular Imaging},
year={2012},
volume={13},
number={10},
pages={857-862},
doi={10.1093/ehjci/jes057},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867525487&doi=10.1093%2fehjci%2fjes057&partnerID=40&md5=661cf9ed1972735f400c8f6c155c4ace},
abstract={Alms: Echocardiographic contrast (EC) improves the diagnostic accuracy of suboptimal echocardiograms. In October 2007, the Food and Drug Administration (FDA) placed a black box warning on the label of the perflutren-based agents Definity and Optison, contraindicating their use in patients with pulmonary hypertension (PHT) and unstable cardiopulmonary status, after serious cardiopulmonary reactions occurred in temporal relation to EC administration. In 2008 and 2011, the FDA revised the black box warning allowing their use in this same population. However, limited data exist regarding the safety profile of these agents in patients with PHT. Methods and results: Consecutive hospitalized patients with PHT who were referred for echocardiographic evaluation, but required the use of EC, were included. All our patients received the EC agent Definity. We evaluated these patients for serious adverse events (respiratory decompensation, hypotension, syncope, convulsions, arrhythmias, anaphylactic reactions, or death) occurring within 24 h of EC administration. The study group included 1513 patients (age 69±14 years, 55% males, BMI 33±9 kg/m2), of which 911 (60%) had mild PHT, 515 (34%) had moderate PHT, and 87 (6%) had severe PHT. The mean pulmonary artery systolic pressures (PASP) in the groups with mild, moderate, and severe PHT were 41±4 (range 35-49) mmHg, 55±5 (range 50-69) mmHg, and 78±9 (range 70-122) mmHg, respectively. The incidence of adverse events in all subgroups was rare (0.002%) and they were not attributed to EC because of temporal and clinical considerations: Conclusion: The use of the EC agent Definity is safe in hospitalized patients with PHT. © The Author 2012.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wu2012,
author={Wu, J.-L. and Yu, L.-C. and Chang, P.-C.},
title={Detecting causality from online psychiatric texts using inter-sentential language patterns},
journal={BMC Medical Informatics and Decision Making},
year={2012},
volume={12},
number={1},
doi={10.1186/1472-6947-12-72},
art_number={72},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866237772&doi=10.1186%2f1472-6947-12-72&partnerID=40&md5=84d0bf56251dbdce713cf2e818a5582a},
abstract={Background: Online psychiatric texts are natural language texts expressing depressive problems, published by Internet users via community-based web services such as web forums, message boards and blogs. Understanding the cause-effect relations embedded in these psychiatric texts can provide insight into the authors problems, thus increasing the effectiveness of online psychiatric services. Methods: Previous studies have proposed the use of word pairs extracted from a set of sentence pairs to identify cause-effect relations between sentences. A word pair is made up of two words, with one coming from the cause text span and the other from the effect text span. Analysis of the relationship between these words can be used to capture individual word associations between cause and effect sentences. For instance, (broke up, life) and (boyfriend, meaningless) are two word pairs extracted from the sentence pair: I broke up with my boyfriend. Life is now meaningless to me. The major limitation of word pairs is that individual words in sentences usually cannot reflect the exact meaning of the cause and effect events, and thus may produce semantically incomplete word pairs, as the previous examples show. Therefore, this study proposes the use of inter-sentential language patterns such as ≫broke up, boyfriend<, >life, meaningless≪ to detect causality between sentences. The inter-sentential language patterns can capture associations among multiple words within and between sentences, thus can provide more precise information than word pairs. To acquire inter-sentential language patterns, we develop a text mining framework by extending the classical association rule mining algorithm such that it can discover frequently co-occurring patterns across the sentence boundary. Results: Performance was evaluated on a corpus of texts collected from PsychPark (http://www.psychpark. org), a virtual psychiatric clinic maintained by a group of volunteer professionals from the Taiwan Association of Mental Health Informatics. Experimental results show that the use of inter-sentential language patterns outperformed the use of word pairs proposed in previous studies. Conclusions: This study demonstrates the acquisition of inter-sentential language patterns for causality detection from online psychiatric texts. Such semantically more complete and precise features can improve causality detection performance. © 2012 Wu et al.; licensee BioMed Central Ltd.},
author_keywords={Biomedical text mining;  Causality detection;  Inter-sentential language patterns;  Natural language processing},
document_type={Article},
source={Scopus},
}

@ARTICLE{Miori20126802,
author={Miori, V. and Russo, D. and Concordia, C.},
title={Meeting people's needs in a fully interoperable domotic environment},
journal={Sensors (Switzerland)},
year={2012},
volume={12},
number={6},
pages={6802-6824},
doi={10.3390/s120606802},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863209235&doi=10.3390%2fs120606802&partnerID=40&md5=d58294cc4615f92217ca50043a7e9d49},
abstract={The key idea underlying many Ambient Intelligence (AmI) projects and applications is context awareness, which is based mainly on their capacity to identify users and their locations. The actual computing capacity should remain in the background, in the periphery of our awareness, and should only move to the center if and when necessary. Computing thus becomes 'invisible', as it is embedded in the environment and everyday objects. The research project described herein aims to realize an Ambient Intelligence-based environment able to improve users' quality of life by learning their habits and anticipating their needs. This environment is part of an adaptive, context-aware framework designed to make today's incompatible heterogeneous domotic systems fully interoperable, not only for connecting sensors and actuators, but for providing comprehensive connections of devices to users. The solution is a middleware architecture based on open and widely recognized standards capable of abstracting the peculiarities of underlying heterogeneous technologies and enabling them to co-exist and interwork, without however eliminating their differences. At the highest level of this infrastructure, the Ambient Intelligence framework, integrated with the domotic sensors, can enable the system to recognize any unusual or dangerous situations and anticipate health problems or special user needs in a technological living environment, such as a house or a public space. © 2012 by the authors; licensee MDPI, Basel, Switzerland.},
author_keywords={Ambient Intelligent;  Association rules;  Data mining;  DomoNet;  Domotics;  Home environment;  Interoperability;  Machine learning;  Web services;  XML},
document_type={Article},
source={Scopus},
}

@ARTICLE{Jiménez20121,
author={Jiménez, A. and Berzal, F. and Cubero, J.-C.},
title={Using trees to mine multirelational databases},
journal={Data Mining and Knowledge Discovery},
year={2012},
volume={24},
number={1},
pages={1-39},
doi={10.1007/s10618-011-0218-x},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856607691&doi=10.1007%2fs10618-011-0218-x&partnerID=40&md5=888cac0ca7150c2d9244b9c1763686a3},
abstract={This paper proposes a new approach to mine multirelational databases. Our approach is based on the representation of multirelational databases as sets of trees, for which we propose two alternative representation schemes. Tree mining techniques can thus be applied as the basis for multirelational data mining techniques, such as multirelational classification or multirelational clustering. We analyze the differences between identifying induced and embedded tree patterns in the proposed tree-based representation schemes and we study the relationships among the sets of tree patterns that can be discovered in each case. This paper also describes how these frequent tree patterns can be used, for instance, to mine association rules in multirelational databases. © 2011 The Author(s).},
author_keywords={Association rules;  Frequent itemset mining;  Multirelational databases;  Tree pattern mining},
document_type={Article},
source={Scopus},
}

@ARTICLE{Yang2012141,
author={Yang, G.},
title={Mining association rules based on cultural clonal selection algorithm},
journal={International Journal of Advancements in Computing Technology},
year={2012},
volume={4},
number={10},
pages={141-147},
doi={10.4156/ijact.vol4.issue10.17},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862877575&doi=10.4156%2fijact.vol4.issue10.17&partnerID=40&md5=0b7f9393d9e8fbfb8e09046ce7fc9920},
abstract={For extracting association rules, a new algorithm based on cultural clonal selection algorithm is proposed. The clonal selection algorithm is embedded in the cultural algorithm framework. It uses the intelligent searching ability of the clonal selection algorithm and the commonly accepted knowledge in the cultural algorithm to guide the rules mining. The situational knowledge and history knowledge of the cultural algorithm are redefined, and a new mutation operator is put forward. This operator has the self-adaptive adjustment of mutation to improve the global search ability of clonal selection algorithm. The experiments show that the new algorithm is superior to clonal selection algorithm in convergence speed and the rules' accuracy.},
author_keywords={Association rules;  Clonal selection algorithm;  Cultural algorithm;  Mutation operator;  Self-adaptive},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Hasegawa2012214,
author={Hasegawa, S. and Kashihara, A.},
title={An extraction technique for presentation schema embedded in presentation documents},
journal={Proceedings of the 20th International Conference on Computers in Education, ICCE 2012},
year={2012},
pages={214-221},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896344813&partnerID=40&md5=dd0f7c93838b80fa075fd06a382724b5},
abstract={The main topic addressed in this paper is to help a novice graduate/undergraduate student compose his/her presentation document by means of presentation schema that represents heuristics for presenting research contents to be shared by laboratory members. The key idea is to propose a model of presentation structure, which represents roles of and sequences among presentation slides included in the documents with metadata. Following this model, the presentation schema is defined as a typical presentation structure for the laboratory members. This paper accordingly introduces a technique based on association rule mining for automatically extracting the presentation schema from the repository of the documents accumulated in the laboratory. In addition, we report case studies for investigating how to configure the thresholds of the mining and how the schema extracted is valid in comparing the ones between different laboratories.},
author_keywords={Association rule mining;  Presentation schema;  Presentation semantics},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wang2011,
author={Wang, Y. and Wang, H.},
title={Research and application of small and medium-sized manufacturing enterprises sales promotion model based on data mining},
journal={8th International Conference on Service Systems and Service Management - Proceedings of ICSSSM'11},
year={2011},
doi={10.1109/ICSSSM.2011.5959433},
art_number={5959433},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863146883&doi=10.1109%2fICSSSM.2011.5959433&partnerID=40&md5=74cf5fb769c2a50504a431662fbd0256},
abstract={How to make an appropriate sales promotion strategy is critical for enterprises, especially those small and medium-sized manufacturing enterprises. In this paper, we propose a customer-oriented model for sales promotion using data mining techniques. The proposed model can efficiently discovery the association rules between goods. To make the mining algorithm more scalable, a sparse data structure is designed and embedded into an improved association rule mining algorithm. We apply the proposed model on a cleaning product manufacturer. Experimental results show its effectiveness. © 2011 IEEE.},
author_keywords={Apriori algorithm;  association rules;  data mining;  knowledge discovery in database},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Mao20111550,
author={Mao, C.},
title={Variable precision rough set-based fault diagnosis for web services},
journal={Proc. 10th IEEE Int. Conf. on Trust, Security and Privacy in Computing and Communications, TrustCom 2011, 8th IEEE Int. Conf. on Embedded Software and Systems, ICESS 2011, 6th Int. Conf. on FCST 2011},
year={2011},
pages={1550-1555},
doi={10.1109/TrustCom.2011.215},
art_number={6121011},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856149595&doi=10.1109%2fTrustCom.2011.215&partnerID=40&md5=fb4792448e25c219e831c9c601e2005a},
abstract={Web service is the emergent technology for constructing more complex and flexible software system for business applications. However, some new features of Web service-based software such as heterogeneity and loose-coupling bring great trouble to the latter fault debugging and diagnosis. In the paper, variable precision rough set-based diagnosis framework is presented. In such debugging model, SOAP message monitoring and service invocation instrument are used to record service interface information. Meanwhile, factors of execution context are also viewed as conditional attributes of knowledge representation system. The final execution result is treated as the decision attribute, and failure ontology is utilized to classify system's failure behaviors. Based on this extended information system, variable precision rough set reasoning is performed to generate the probability association rules, which are the clues for locating the possible faulty services. In addition, the experiment on a real-world Web services system is performed to demonstrate the feasibility and effectiveness of our proposed method. © 2011 IEEE.},
author_keywords={association rule;  failure;  fault diagnosis;  rough set;  service interface;  Web services},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Leun2011316,
author={Leun, C.K.S.},
title={Mining uncertain data},
journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
year={2011},
volume={1},
number={4},
pages={316-329},
doi={10.1002/widm.31},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052323535&doi=10.1002%2fwidm.31&partnerID=40&md5=8b9dc83693159896e74e5d2162e4b5ca},
abstract={As an important data mining and knowledge discovery task, association rule mining searches for implicit, previously unknown, and potentially useful pieces of information-in the form of rules revealing associative relationships-that are embedded in the data. In general, the association rule mining process comprises two key steps. The first key step, which mines frequent patterns (i.e., frequently occurring sets of items) from data, is more computationally intensive than the second key step of using the mined frequent patterns to form association rules. In the early days, many developed algorithms mined frequent patterns from traditional transaction databases of precise data such as shopping market basket data, in which the contents of databases are known. However, we are living in an uncertainworld, in which uncertain data can be found almost everywhere. Hence, in recent years, researchers have paid more attention to frequent pattern mining from probabilistic databases of uncertain data. In this paper, we review recent algorithmic development on mining uncertain data in these probabilistic databases for frequent patterns. © 2011 John Wiley & Sons, Inc.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Yu20111408,
author={Yu, K.-M. and Wu, S.-H.},
title={An efficient load balancing multi-core frequent patterns mining algorithm},
journal={Proc. 10th IEEE Int. Conf. on Trust, Security and Privacy in Computing and Communications, TrustCom 2011, 8th IEEE Int. Conf. on Embedded Software and Systems, ICESS 2011, 6th Int. Conf. on FCST 2011},
year={2011},
pages={1408-1412},
doi={10.1109/TrustCom.2011.192},
art_number={6120988},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862918711&doi=10.1109%2fTrustCom.2011.192&partnerID=40&md5=1e16e41311185a5724240eb54a287f9c},
abstract={Mining frequent pattern from transactional database is an important problem in data mining. Many methods have been proposed to solve this problem. However, the computation time still increase significantly while the data size grows. Therefore, parallel computing is a good strategy to solve this problem. Researchers have proposed various parallel and distributed algorithms on cluster system, grid system. However, the construction and maintenance cost is pretty high. In this paper, a multi-core load balancing frequent pattern mining algorithm is presented. The main goal of the proposed algorithm is to reduce the massive duplicated candidates generated in previous method. In order to verify the performance, we also implemented the proposed algorithm as well as previous methods for comparison. The experimental results showed that our method could reduce the computation time dramatically with more threads. Moreover, we could observe that the workload was equally dispatched to each computing unit. © 2011 IEEE.},
author_keywords={association rules;  frequent pattern mining;  load balancing;  multi-core},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wang201189,
author={Wang, F. and Yao, L.-W. and Wu, J.-H.},
title={Intelligent test oracle construction for reactive systems without explicit specifications},
journal={Proceedings - IEEE 9th International Conference on Dependable, Autonomic and Secure Computing, DASC 2011},
year={2011},
pages={89-96},
doi={10.1109/DASC.2011.39},
art_number={6118358},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862963108&doi=10.1109%2fDASC.2011.39&partnerID=40&md5=c6cf09d0240372bb914c57ba9c8f1254},
abstract={A test oracle is a mechanism that decides whether an SUT (software under test) fails or passes a test case. We investigate how to use machine learning techniques to automatically construct test oracles for reactive programs without reliance on explicit specifications. Firstly, we present a library, called In TOL (Intelligent Test Oracle Library), for the convenient and flexible collection of test traces. We can flexibly use either user guidance or program assertions to collect verdicts to test traces. Such verdicts are used as supervisory signals to the supervised learning algorithm (SLA) for a test oracle. Secondly, we present several sets of feature variables for the temporal relation among events in test traces of unbounded lengths. Then we present procedures that convert test traces into feature vectors, train an SLA with the feature vectors and their verdicts, and use the trained SLA as a test oracle. We report the implementation of In TOL on top of SVM (support vector machine). We experiment with two open-source benchmark SUTs from the internet to check the performance of our techniques. Our experiment data shows that high-accuracy test verdicts can be achieved with our test oracles for the benchmark SUTs. © 2011 IEEE.},
author_keywords={AI;  machine learning;  software testing;  SVM;  test oracle},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ghali201143,
author={Ghali, N.I. and El Bakrawy, L.M. and Hassanien, A.E.},
title={Associative watermarking scheme for medical image authentication},
journal={Advances in Intelligent and Soft Computing},
year={2011},
volume={91},
pages={43-50},
doi={10.1007/978-3-642-19934-9_6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053022541&doi=10.1007%2f978-3-642-19934-9_6&partnerID=40&md5=f9f73740ddd44f3526fd300cd3ab390d},
abstract={With the widespread and increasing use of internet and digital forms of image; and the convencience of medical professionals that the future of health care will be shaped by teleradiology and technologies such as telemedicine in general. In addition to the various radiological modalities which produce a variety of digital medical files most often datasets and images. These files should be protected from unwanted modification of their contents, especially as they contain vital medical information. Thus their protection and authentication seems to be of great importance and this need will rise along with the future standardization of exchange of data between hospitals or between patients and doctors. In this paper, an associative watermarking scheme is conducted to perform associative watermarking rules to the images which reducts the amount of embedded data, vector quantization indexing scheme is used to embed watermark for the purpose of image authentication. The vector quantization decoding technique is applied to reconstruct the watermarked image from the watermarked index table. The experimental results show that the proposed scheme is robust. The watermarked images are resistant to severe image processing attcks such as Gaussian noise, brightness, blurring, sharpening, cropping, and JPEG lossy compression. © 2011 Springer-Verlag Berlin Heidelberg.},
author_keywords={Association rules;  Edge block detection method;  Vector quantization},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Chian2011218,
author={Chian, Y.-S. and Teng, W.-G.},
title={Discovering visual-concepts of online images from associational image patches},
journal={Proceedings of the International Symposium on Consumer Electronics, ISCE},
year={2011},
pages={218-221},
doi={10.1109/ISCE.2011.5973818},
art_number={5973818},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052398970&doi=10.1109%2fISCE.2011.5973818&partnerID=40&md5=15cc0bdec1b5b5869f9c8a9bb63f12d9},
abstract={With the advance of networking technologies, the widespread use of handheld devices not only enables instant access of required information but also shortens the distance among acquaintances. Nowadays one can easily share their photos on the Internet right after the photos are taken. With an increasing amount of images, a challenging problem for computer algorithms is to discover the visual-concept embedded within an image. Instead of modeling this problem as a classification process which attempts to categorize images into different pre-defined classes, we propose in this work to start with identifying similar image patches. Specifically, we adopt the technique of mining association rules to construct evident relationships among image patches so as to discover identical visual-concepts from online images. © 2011 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Chen2011687,
author={Chen, C.-L. and Tseng, F.S.C. and Liang, T.},
title={An integration of fuzzy association rules and WordNet for document clustering},
journal={Knowledge and Information Systems},
year={2011},
volume={28},
number={3},
pages={687-708},
doi={10.1007/s10115-010-0364-2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052025105&doi=10.1007%2fs10115-010-0364-2&partnerID=40&md5=3b7953014a94100933b7a06bc771ee89},
abstract={With the rapid growth of text documents, document clustering technique is emerging for efficient document retrieval and better document browsing. Recently, some methods had been proposed to resolve the problems of high dimensionality, scalability, accuracy, and meaningful cluster labels by using frequent itemsets derived from association rule mining for clustering documents. In order to improve the quality of document clustering results, we propose an effective Fuzzy Frequent Itemset-based Document Clustering (F2IDC) approach that combines fuzzy association rule mining with the background knowledge embedded in WordNet. A term hierarchy generated from WordNet is applied to discover generalized frequent itemsets as candidate cluster labels for grouping documents. We have conducted experiments to evaluate our approach on Classic4, Re0, R8, and WebKB datasets. Our experimental results show that our proposed approach indeed provide more accurate clustering results than prior influential clustering methods presented in recent literature. © 2010 Springer-Verlag London Limited.},
author_keywords={Document clustering;  Frequent itemsets;  Fuzzy association rule mining;  Text mining;  WordNet},
document_type={Article},
source={Scopus},
}

@ARTICLE{Venkatesan2011536,
author={Venkatesan, M. and Thangavelu, A. and Prabhavathy, P.},
title={A new data mining approach to find co-location pattern from spatial data},
journal={Communications in Computer and Information Science},
year={2011},
volume={198 CCIS},
pages={536-545},
doi={10.1007/978-3-642-22555-0_55},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960313980&doi=10.1007%2f978-3-642-22555-0_55&partnerID=40&md5=3312ce465e71c2cb8bba3d11d703703e},
abstract={Spatial co-location patterns represent the subsets of Boolean spatial features whose instances are often located in close geographic proximity. These patterns derive the meaningful relation between spatial data. Co-location rules can be identified by spatial statistics or data mining approaches. In data mining method, Association rule-based approaches can be used which are further divided into transaction-based approaches and distance-based approaches. Transaction-based approaches focus on defining transactions over space so that an Apriori algorithm can be used. The natural notion of transactions is absent in spatial data sets which are embedded in continuous geographic space. A new distance -based approach is developed to mine co-location patterns from spatial data by using the concept of proximity neighborhood. A new interest measure, a participation index, is used for spatial co-location patterns as it possesses an anti-monotone property. An algorithm to discover co-location patterns are designed which generates candidate locations and their table instances. Finally the co-location rules are generated to identify the patterns. © 2011 Springer-Verlag.},
author_keywords={association rule;  Co-location pattern;  participation index;  spatial data},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Peng20113135,
author={Peng, Y.-F.},
title={Development of robust intelligent tracking control system for uncertain nonlinear systems using H ∞ control technique},
journal={Applied Soft Computing Journal},
year={2011},
volume={11},
number={3},
pages={3135-3146},
doi={10.1016/j.asoc.2010.12.016},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951856769&doi=10.1016%2fj.asoc.2010.12.016&partnerID=40&md5=5f09161568ca213d4ed6120be7327460},
abstract={In this paper, a robust intelligent tracking control (RITC) system employs an adaptive output recurrent cerebellar model articulation controller (ORCMAC) is developed for uncertain nonlinear system to achieve H ∞ tracking performance. The proposed dynamic structure of ORCMAC has superior capability in efficient learning mechanism and dynamic response. Temporal relations are embedded in conventional cerebellar model articulation controller (CMAC) by adding feedback connections between the output space and input space, so that the ORCMAC captures the system dynamic. In the RITC design, the Taylor linearization technique is employed to increase the learning ability of ORCMAC and the on-line adaptive laws are derived based on the Lyapunov stability analysis, the sliding mode control methodology and the H ∞ control technique so that the stability of the closed-loop system and H ∞ tracking performance can be guaranteed. Finally, the proposed control system is applied to control an inverted pendulum system, a Van der Pol oscillator and a Genesio chaotic system. Simulation results demonstrate that the proposed control scheme can achieve favorable tracking performances for the uncertain nonlinear systems with unknown dynamic functions and under the occurrence of external disturbance. © 2010 Elsevier B.V. All rights reserved.},
author_keywords={Adaptive control;  H ∞ control technique;  Intelligent control;  Output recurrent cerebellar model articulation controller (ORCMAC);  Robust control;  Sliding mode control},
document_type={Article},
source={Scopus},
}

@ARTICLE{Hu201138,
author={Hu, H.-J. and Harrison, R.W. and Tai, P.C. and Pan, Y.},
title={Understandable learning machine system design for transmembrane or embedded membrane segments prediction},
journal={International Journal of Data Mining and Bioinformatics},
year={2011},
volume={5},
number={1},
pages={38-51},
doi={10.1504/IJDMB.2011.038576},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951639962&doi=10.1504%2fIJDMB.2011.038576&partnerID=40&md5=212c8bfe80e9d05539a85c0cec34feae},
abstract={We modified an existing association rule-based classifier CPAR to improve traditional black box model based learning machine approaches on Transmembrane (TM) segment prediction. The modified classifier was improved further by combining with SVM. The experimental results indicate that this hybrid scheme offers biologically meaningful rules on TM/EM segment prediction while maintaining the performance almost as well as the SVM method. The evaluation of the sturdiness and the Receiver Operating Characteristic (ROC) curve analysis proved that this new scheme is robust and competent with SVM on TM/EM segment prediction. The prediction server is available at http://bmcc2.cs.gsu.edu/ ~haeh2/. © 2011 Inderscience Enterprises Ltd.},
author_keywords={Association rule based classifier;  Embedded membrane segment.;  Support vector machine;  SVM;  Transmembrane segment},
document_type={Article},
source={Scopus},
}

@ARTICLE{Saravanabhavan2011466,
author={Saravanabhavan, C. and Parvathi, R.M.S.},
title={Utility FP-tree: An efficient approach to mine weighted utility itemsets},
journal={European Journal of Scientific Research},
year={2011},
volume={50},
number={4},
pages={466-480},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953854784&partnerID=40&md5=f0fbf73c654cc69593a788584ca4d80c},
abstract={Conventional association rules mining cannot satisfy the demands emerging from certain real applications. By regarding the diverse values of distinct items as utilities, utility mining concentrates on discovering the itemsets with high utilities. In recent times, high utility pattern mining is one of the most significant research issues in data mining because of its ability to account for the non-binary frequency values of items in transactions and diverse profit values of each item. In this paper, we have presented an efficient tree structure for mining high utility itemsets. At first, we have developed a novel utility frequent-pattern tree structure, an extended tree structure for storing crucial information about utility itemsets. Then, we have utilized the pattern growth methodology for mining the complete set of utility patterns. Improved high utility itemsets mining efficiency is achieved using two major concepts: 1) Compressing a large database into a smaller data structure as well as the utility FP-tree avoids repeated database scans, 2) The pattern growth method utilized in our proposed FP-tree-based utility mining avoids the costly generation of a large number of candidate sets and thereby reduces the search space dramatically. Experimental analysis is carried out on our tree structure mining concept using different real life datasets. The performance evaluation results demonstrate the efficiency of our proposed approach in mining high utility itemsets. © EuroJournals Publishing, Inc. 2011.},
author_keywords={Data mining;  FP-growth;  FP-tree;  Frequent pattern mining;  Utility FP-tree;  Utility itemset mining},
document_type={Article},
source={Scopus},
}

@ARTICLE{Hadzic2010413,
author={Hadzic, F. and Tan, H. and Dillon, T.S.},
title={Model guided algorithm for mining unordered embedded subtrees},
journal={Web Intelligence and Agent Systems},
year={2010},
volume={8},
number={4},
pages={413-430},
doi={10.3233/WIA-2010-0200},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650364789&doi=10.3233%2fWIA-2010-0200&partnerID=40&md5=3b734accd221e8c2c292a48b430feb35},
abstract={Large amount of online information is or can be represented using semi-structured documents, such as XML. The information contained in an XML document can be effectively represented using a rooted ordered labeled tree. This has made the frequent pattern mining problem recast as the frequent subtree mining problem, which is a pre-requisite for association rule mining form tree-structured documents. Driven by different application needs a number of algorithms have been developed for mining of different subtree types under different support definitions. In this paper we present an algorithm for mining unordered embedded subtrees. It is an extension of our general tree model guided (TMG) candidate generation framework and the proposed U3 algorithm considers all support definitions, namely, transaction-based, occurrence-match and hybrid support. A number of experiments are presented on synthetic and real world data sets. The results demonstrate the flexibility of our general TMG framework as well as its efficiency when compared to the existing state-of-the-art approach. © 2010 - IOS Press and the authors. All rights reserved.},
author_keywords={algorithm;  canonical form;  data mining;  Tree mining;  unordered embedded subtrees},
document_type={Article},
source={Scopus},
}

@ARTICLE{Qian2010286,
author={Qian, M. and Pu, L.-J. and Fu, R. and Zhu, M.},
title={Mining spatial association rules with multi-relational approach},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2010},
volume={6440 LNAI},
number={PART 1},
pages={286-293},
doi={10.1007/978-3-642-17316-5_28},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650211215&doi=10.1007%2f978-3-642-17316-5_28&partnerID=40&md5=32e5b9307427dcb2e0d3486f9a6da44b},
abstract={Working on spatial data models for geographic phenomena have always been viewed from a spatial context and emphasizing spatial change. But the problem is that spatial relationships are embedded in space, unknown a priori. To achieve such issue, spatial association rules mining techniques are needed. In this paper, we propose a multi-relational mining method to deal with it. We use a non-parametric way by using Vironoi-diagram based neighborhood, classification method is implemented to pre-process the rules condition, association rules are pre-defined, and a close Apriori-base algorithm is proposed to cope with it. Then the framework is evaluated by the real-world dataset, and some thoughtful association rules are given. © 2010 Springer-Verlag.},
author_keywords={Apriori-base algorithm;  multi-relational approach;  neighborhood;  spatial association rules mining;  Vironoi-diagram},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Yue2010154,
author={Yue, H. and Jones, E. and Revesz, P.},
title={Local polynomial regression models for average traffic speed estimation and forecasting in linear constraint databases},
journal={Proceedings - 17th International Symposium on Temporal Representation and Reasoning, TIME 2010},
year={2010},
pages={154-161},
doi={10.1109/TIME.2010.24},
art_number={5601873},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649404354&doi=10.1109%2fTIME.2010.24&partnerID=40&md5=5835777cfe40eba9b61e4f190f1180b5},
abstract={Constraint databases have the specific advantage of being able to represent infinite temporal relations by linear equations, linear inequalities, polynomial equations, and so on. This advantage can store a continuous time-line that naturally connects with other traffic attributes, such as traffic speed. In most cases, vehicle speed varies over time, that is, the speed is often nonlinear. However, the infinite representations allowed in current constraint database systems are only linear. Our article presents a new approach to estimate and forecast continuous average speed using linear constraint database systems. Our new approach to represent and query the nonlinear average traffic speed is based on a combination of local polynomial regression and piecewise-linear approximation algorithm. Experiments using the MLPQ constraint database system and queries show that our method has a high accuracy in predicting the average traffic speed. The actual accuracy is controllable by a parameter. We compared the local linear regression model with the local cubic model by using a field experiment. It was found that the local cubic model follows more closely the raw data than the linear model follows. © 2010 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kwuida2010235,
author={Kwuida, L. and Missaoui, R. and Ben Amor, B. and Boumedjout, L. and Vaillancourt, J.},
title={Restrictions on concept lattices for pattern management},
journal={CEUR Workshop Proceedings},
year={2010},
volume={672},
pages={235-246},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955771512&partnerID=40&md5=19c0d09461f020531819f8a88aedf48e},
abstract={This paper addresses the problem of pattern management in the framework of formal concept analysis using restrictions on objects or attributes of a given data set. Patterns are pieces of information/knowledge with a concise description that can be obtained from data using data mining techniques. These can be clusters or bi-clusters, implications or association rules, and so on. Even for relatively small data collections, the set of discovered patterns could be very large and therefore difficult to handle. In this paper we propose efficient methods to conduct the projection of a concept lattice on a set of attributes. The selection of a concept lattice on a set of objects is done dually.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2010,
title={13th International Conference on Information Processing and Management of Uncertainty, IPMU 2010},
journal={Communications in Computer and Information Science},
year={2010},
volume={80 PART 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880466850&partnerID=40&md5=d50c82da535139c4bc14dba0c564e633},
abstract={The proceedings contain 79 papers. The special focus in this conference is on theoretical foundations and methods for information processing and management of uncertainty in knowledge-based systems. The topics include: An algorithm to find a perfect map for graphoid structures; an empirical study of the use of the noisy-or model in a real-life Bayesian network; possibilistic graphical models and compositional models; an application to convoy detection; approximation of data by decomposable belief models; a gambler's gain prospects with coherent imprecise previsions; infinite exchangeability for sets of desirable gambles; ergodicity conditions for upper transition operators; on the complexity of non-reversible betting games on many-valued events; similarity-based equality with lazy evaluation; progressive reasoning for complex dialogues among agents; measuring instability in normal residuated logic programs; implementing prioritized merging with ASP; characterization of complete fuzzy preorders defined by Archimedean t-norms; rectification of preferences in a fuzzy environment; identification of speakers by name using belief functions; constructing multiple frames of discernment for multiple subproblems; conflict interpretation in a belief interval based framework; evidential data association filter; TS-models from evidential clustering; multiplication of multinomial subjective opinions; a model in the theory of evidence; gradual evaluation of granules of a fuzzy relation; on scalability of rough set methods; interestingness measures for association rules within groups; data mining in RL-bags; feature subset selection for fuzzy classification methods; restricting the IDM for classification; estimation of possibility-probability distributions; Bayesian assaying of GUHA nuggets; rank correlation coefficient correction by removing worst cases; probabilistic relational learning for medical diagnosis based on ion mobility spectrometry; uncertainty interval expression of measurement; lazy induction of descriptions using two fuzzy versions of the rand index; fuzzy clustering-based filter; fuzzy classification of nonconvex data-inherent structures; fuzzy-pattern-classifier training with small data sets; temporal linguistic summaries of time series using fuzzy logic; a comparison of five fuzzy rand indices; identifying the risk of attribute disclosure by mining fuzzy rules; explicit descriptions of associative sugeno integrals; continuity of choquet integrals of supermodular capacities; fuzzy measure spaces generated by fuzzy sets; absolute continuity of monotone measure and convergence in measure; on a new class of implications in fuzzy logic; fuzzy relation equations in semilinear spaces; adaptive rule based-reasoning by qualitative analysis; a new approach to the distances between intuitionistic fuzzy sets; trust propagation based on group opinion; application of IF-sets to modeling of lip shapes similarities; hesitation degrees as the size of ignorance combined with fuzziness; cardinality and entropy for bifuzzy sets; arity-monotonic extended aggregation operators; mixture utility in general insurance; measurement of ground-neutral currents in three phase transformers using a genetically evolved shaping filter and learning of fuzzy rule-based meta-schedulers for grid computing with differential evolution.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Su2010582,
author={Su, M.-Y. and Yeh, S.-C. and Lin, C.-Y. and Tsai, C.-H.},
title={Using genetic algorithm to improve an online response system for anomaly traffic by incremental mining},
journal={Proceedings - International Symposium on Parallel and Distributed Processing with Applications, ISPA 2010},
year={2010},
pages={582-587},
doi={10.1109/ISPA.2010.75},
art_number={5634386},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952097955&doi=10.1109%2fISPA.2010.75&partnerID=40&md5=f36323ac9d6db429846e98a3a1451123},
abstract={This paper presents an online real-time network response system, which can determine whether a LAN is suffering from a flooding attack within a very short time unit. The detection engine of the system is based on the incremental mining of fuzzy association rules from network packets, in which membership functions of fuzzy variables are optimized by a genetic algorithm. The proposed online system belongs to anomaly detection, not misuse detection. Moreover, a mechanism for dynamic firewall updating is embedded in the proposed system for the function of eliminating suspicious connections when necessary. © 2010 IEEE.},
author_keywords={Anomaly detection;  Fuzzy association rules;  Genetic algorithm;  Membership functions;  Online incremental mining},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{ElBakrawy2010823,
author={El Bakrawy, L.M. and Ghali, N.I. and Hassanien, A.E. and Abraham, A.},
title={An associative watermarking based image authentication scheme},
journal={Proceedings of the 2010 10th International Conference on Intelligent Systems Design and Applications, ISDA'10},
year={2010},
pages={823-828},
doi={10.1109/ISDA.2010.5687160},
art_number={5687160},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79851506020&doi=10.1109%2fISDA.2010.5687160&partnerID=40&md5=bce00472d9ffba6a6d4f81bafb265114},
abstract={In this paper, we propose an associative watermarking scheme which is conducted by the concept of Association Mining Rules (AMRs) and the ideas of Vector Quantization (VQ) and Soble operator. Performing associative watermarking rules to the images will reduct the amount of the embedded data, and using VQ indexing scheme can easily recall the embedded watermark for the purpose of image authentication, and establishing the relation between the association rules on both the original image and the watermark image. The Vector Quantization decoding technique is applied to reconstruct the watermarked image from the watermarked index table. The experimental result shows that the proposed scheme is robust. When the watermarked images suffered from various kinds of image-processing procedures, such as Gaussian noise, brightness, blurring, sharpening, cropping, and JPEG lossy compression can be detected without the original images assistance. © 2010 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Peng2010,
author={Peng, Y.-F. and Lai, H.-W. and Chiu, C.-H. and Wai, R.-J.},
title={Robust recurrent wavelet-based CMAC control for uncertain nonlinear systems with H ∞ tracking performance},
journal={Proceedings of the International Joint Conference on Neural Networks},
year={2010},
doi={10.1109/IJCNN.2010.5596910},
art_number={5596910},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959486018&doi=10.1109%2fIJCNN.2010.5596910&partnerID=40&md5=406c7a2983b767e4c811f3f8d6e0772d},
abstract={In this paper, a robust intelligent tracking control (RITC) system employs a recurrent wavelet-based cerebellar model articulation controller (RWCMAC) is developed for uncertain nonlinear system to achieve H ∞ tracking performance. The dynamic structure of RWCMAC has superior capability to the conventional static cerebellar model articulation controller (CMAC) in efficient learning mechanism and dynamic response. Temporal relations are embedded in RWCMAC by adding feedback connections in the mother wavelet association memory space so that the RWCMAC captures the system dynamic, where the feedback units act as memory elements. In the RITC design, the Taylor linearization technique is employed to increase the learning ability of RWCMAC and the on-line adaptive laws are derived based on the Lyapunov stability analysis, the sliding mode control methodology and the H ∞ control technique so that the stability of the closed-loop system and H ∞ tracking performance can be guaranteed. Finally, the proposed control system is applied to control an inverted pendulum system and a Genesio chaotic system. Simulation results demonstrate that the proposed control scheme can achieve favorable tracking performances for the uncertain nonlinear systems with unknown dynamic functions and under the occurrence of external disturbance. © 2010 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Choi20101654,
author={Choi, D.W. and Hyun, Y.J.},
title={Transitive association rule discovery by considering strategic importance},
journal={Proceedings - 10th IEEE International Conference on Computer and Information Technology, CIT-2010, 7th IEEE International Conference on Embedded Software and Systems, ICESS-2010, ScalCom-2010},
year={2010},
pages={1654-1659},
doi={10.1109/CIT.2010.292},
art_number={5577953},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-78249232606&doi=10.1109%2fCIT.2010.292&partnerID=40&md5=3fa03765457ebdaf5279fe1ef54862f8},
abstract={The TSAA(transitive support association Apriori) algorithm of this paper discovers transitively associated relationships as well as the frequent itemsets. It utilizes the join item set to find the transitive association rules. Since the join item of a transitive association which have low support value tends to be removed from the next candidate itemset generation, we used two kinds of support values,'minimum support' and'minimum relative support,' in finding the transitive relations. This way the items carrying a strategic importance are given a second chance so that they might be used in discovering the transitive association rules. Our experiments with a real world database showed that the TSAA algorithm was useful in producing transitive itemsets which could not have been obtained otherwise. Observation from other transaction database indicated that there is a'minimum relative support level' at which the number of transitive association itemset decreases suddenly. © 2010 IEEE.},
author_keywords={Apriori;  Market basket analysis;  RSAA;  Transitive association},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Danubianu2010684,
author={Danubianu, M. and Pentiuc, S.G. and Tobolcea, I. and Schipor, O.A.},
title={Advanced information technology - support of improved personalized therapy of speech disorders},
journal={International Journal of Computers, Communications and Control},
year={2010},
volume={5},
number={5},
pages={684-692},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-78049278806&partnerID=40&md5=9c7323387dfbd35de816546d447ace17},
abstract={One of the key challenges of the Sustainable Development Strategy adopted by the European Council in 2006 is related to public health whose general objective envisages a good level of public health. One of the specific targets includes better treatments of diseases. It is true that there are affections which by their nature do not endanger the life of a person, however they may have a negative impact on her/his life standard. Various language or speech disorders are part of this category, but if they are discovered and treated in due time, they can be often corrected. The difficulty for researchers and therapists is to identify those children who have disorders that show a wide range of issues that cannot be solved spontaneously or which may lead to further significant deficiencies. Information technology in the latest years was used by specialists in order to assist and supervise speech disorder therapy. Consequently they have collected a considerable volume of data about the personal or familial anamnesis, regarding various disorders or regarding the process of personalized therapies. These data can be used in data mining processes that aim to discover interesting patterns which can help the design and adaptation of different therapies in order to obtain the best results in conditions of maximum efficiency. The aim of this paper is to present the Logo-DM system. This is a data mining system that can be associated with TERAPERS system in order to use the data from its database as a source for analysis and to provide new information based on an improved system of therapy. Through the use of appropriate techniques of data mining Logo-DM realizes predictions on the evolution and the final status of patients undergoing therapy and enriches the knowledge data of expert system embedded in TERAPERS. © 2006-2010 by CCC Publications.},
author_keywords={Associations rules;  Classification;  Clustering;  Data mining;  Personalized therapy},
document_type={Article},
source={Scopus},
}

@CONFERENCE{NoAuthor2010,
title={2010 International Conference on Intelligent Computation Technology and Automation, ICICTA 2010},
journal={2010 International Conference on Intelligent Computation Technology and Automation, ICICTA 2010},
year={2010},
volume={1},
page_count={3554},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955780851&partnerID=40&md5=b7c62597280ddbc62cc288d3feb62b13},
abstract={The proceedings contain 868 papers. The topics discussed include: design of a workpiece of 390 diesel engine punching dies based on CAE; design of belt pulley absorber in the automobile engine based on the dynamic analysis; design of data detection system based on arm embedded system; design of early warning indicator system for enterprise logistics risks based on balanced scorecard; design of intelligence low-frequency pulsed magnetic-field therapeutic instrument; research on load balancing based on multi-agent in ubiquitous networks; research on membership function of ecological water level based on fuzzy membership degrees; research on mission success evaluation model of the combat units; a chaotic theory based on customized inertia particle swarm optimization and applications to PID coefficient design for the automatic voltage regulator; a new method for control allocation based on second-order cone program; and a new method for eliminating redundant association rules.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Shen2010811,
author={Shen, Y. and Liu, J. and Shen, J.},
title={The further development of Weka base on positive and negative association rules},
journal={2010 International Conference on Intelligent Computation Technology and Automation, ICICTA 2010},
year={2010},
volume={3},
pages={811-814},
doi={10.1109/ICICTA.2010.676},
art_number={5523114},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955722498&doi=10.1109%2fICICTA.2010.676&partnerID=40&md5=b3f6fd3ba8ad3db59c3bd002aef7fa70},
abstract={This paper introduced the features, functions, and mining process of the open-source data mining platform of Weka. In order to overcome the weakness of the aspects of association rules in Weka system research, we used positive and negative association rules algorithm to embed into the Weka platform, and expanded the association rules algorithm under the open-source environment for the futher development. We contrasted and analyzed the embedded algorithm with the original algorithm of association rules, taking full advantage of the functions of class and visualization in the open-source platform of Weka. This algorithm was made improvements in both extracting the explicit rules and fully mining the implicit rules. We carried out the experiment of public intelligence and information systems to obtain better results of association rules, and verified the good adaptability and scalability of the data mining platform of Weka based on the positive and negative association rules. © 2010 IEEE.},
author_keywords={Association rules;  Data mining;  Police intelligence and information;  Positive and negative association rules;  Weka},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2010,
title={2010 International Conference on Intelligent Computation Technology and Automation, ICICTA 2010},
journal={2010 International Conference on Intelligent Computation Technology and Automation, ICICTA 2010},
year={2010},
volume={3},
page_count={3554},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955731996&partnerID=40&md5=9ca817e9096307aab8d1bb9a8c1b807f},
abstract={The proceedings contain 868 papers. The topics discussed include: design of a workpiece of 390 diesel engine punching dies based on CAE; design of belt pulley absorber in the automobile engine based on the dynamic analysis; design of data detection system based on arm embedded system; design of early warning indicator system for enterprise logistics risks based on balanced scorecard; design of intelligence low-frequency pulsed magnetic-field therapeutic instrument; research on load balancing based on multi-agent in ubiquitous networks; research on membership function of ecological water level based on fuzzy membership degrees; research on mission success evaluation model of the combat units; a chaotic theory based on customized inertia particle swarm optimization and applications to PID coefficient design for the automatic voltage regulator; a new method for control allocation based on second-order cone program; and a new method for eliminating redundant association rules.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2010,
title={2010 International Conference on Intelligent Computation Technology and Automation, ICICTA 2010},
journal={2010 International Conference on Intelligent Computation Technology and Automation, ICICTA 2010},
year={2010},
volume={2},
page_count={3554},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955699086&partnerID=40&md5=01172e8003659348c7694e4cd07f36e6},
abstract={The proceedings contain 868 papers. The topics discussed include: design of a workpiece of 390 diesel engine punching dies based on CAE; design of belt pulley absorber in the automobile engine based on the dynamic analysis; design of data detection system based on arm embedded system; design of early warning indicator system for enterprise logistics risks based on balanced scorecard; design of intelligence low-frequency pulsed magnetic-field therapeutic instrument; research on load balancing based on multi-agent in ubiquitous networks; research on membership function of ecological water level based on fuzzy membership degrees; research on mission success evaluation model of the combat units; a chaotic theory based on customized inertia particle swarm optimization and applications to PID coefficient design for the automatic voltage regulator; a new method for control allocation based on second-order cone program; and a new method for eliminating redundant association rules.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Shen20101408,
author={Shen, J.-J. and Ren, J.-M.},
title={A robust associative watermarking technique based on vector quantization},
journal={Digital Signal Processing: A Review Journal},
year={2010},
volume={20},
number={5},
pages={1408-1423},
doi={10.1016/j.dsp.2009.10.015},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-78149452890&doi=10.1016%2fj.dsp.2009.10.015&partnerID=40&md5=556f1f3f82f9617947690a955d91b3d0},
abstract={In this paper, the concepts of vector quantization (VQ) and association rules in data mining are employed to propose a robust watermarking technique. Unlike ordinary or traditional watermarking techniques, our approach hides association rules of the watermark, instead of the whole watermark; in other words, the embedded information is the association rules of the watermark. First, VQ encoding is performed on the original image and watermark to generate the index tables, and from which association rules are further mined. Subsequently, by embedding the association rules of the watermark into the association rules of the original image, the purpose for watermarking is accomplished. Finally, VQ decoding technique is applied to reconstruct the watermarked image from the watermarked index table. Experimental results show that our proposed method achieves effective resistance against several image processings such as blurring, sharpening, adding in Gaussian noise, cropping, and JPEG lossy compression. Moreover, the embedding capacity is also significantly increased, so any a complex watermark image is still acceptable in this method. © 2009 Elsevier Inc. All rights reserved.},
author_keywords={Association rules;  Digital image;  Digital watermarking;  Vector quantization (VQ)},
document_type={Article},
source={Scopus},
}

@ARTICLE{Su2010375,
author={Su, M.-Y. and Yeh, S.-C.},
title={An online response system for anomaly traffic by incremental mining with genetic optimization},
journal={Journal of Communications and Networks},
year={2010},
volume={12},
number={4},
pages={375-381},
doi={10.1109/JCN.2010.6388474},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956577119&doi=10.1109%2fJCN.2010.6388474&partnerID=40&md5=666a8f0ad00d4ec4a6799eea7245a63b},
abstract={A flooding attack, such as DoS or Worm, can be easily created or even downloaded from the Internet, thus, it is one of the main threats to servers on the Internet. This paper presents an online real-time network response system, which can determine whether a LAN is suffering from a flooding attack within a very short time unit. The detection engine of the system is based on the incremental mining of fuzzy association rules from network packets, in which membership functions of fuzzy variables are optimized by a genetic algorithm. The incremental mining approach makes the system suitable for detecting, and thus, responding to an attack in real-time. This system is evaluated by 47 flooding attacks, only one of which is missed, with no false positives occurring. The proposed online system belongs to anomaly detection, not misuse detection. Moreover, a mechanism for dynamic firewall updating is embedded in the proposed system for the function of eliminating suspicious connections when necessary. ©2010 KICS.},
author_keywords={Anomaly detection;  Firewall;  Flooding attack;  Fuzzy association rules;  Genetic algorithm;  Membership functions;  Online incremental mining},
document_type={Article},
source={Scopus},
}

@ARTICLE{Chu201016,
author={Chu, Y.-H. and Huang, J.-W. and Chuang, K.-T. and Yang, D.-N. and Chen, M.-S.},
title={Density conscious subspace clustering for high-dimensional data},
journal={IEEE Transactions on Knowledge and Data Engineering},
year={2010},
volume={22},
number={1},
pages={16-30},
doi={10.1109/TKDE.2008.224},
art_number={4663070},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-72949091449&doi=10.1109%2fTKDE.2008.224&partnerID=40&md5=386bf82767d0a4e90f3c987e3bbca8df},
abstract={Instead of finding clusters in the full feature space, subspace clustering is an emergent task which aims at detecting clusters embedded in subspaces. Most of previous works in the literature are density-based approaches, where a cluster is regarded as a high-density region in a subspace. However, the identification of dense regions in previous works lacks of considering a critical problem, called the density divergence problem in this paper, which refers to the phenomenon that the region densities vary in different subspace cardinalities. Without considering this problem, previous works utilize a density threshold to discover the dense regions in all subspaces, which incurs the serious loss of clustering accuracy (either recall or precision of the resulting clusters) in different subspace cardinalities. To tackle the density divergence problem, in this paper, we devise a novel subspace clustering model to discover the clusters based on the relative region densities in the subspaces, where the clusters are regarded as regions whose densities are relatively high as compared to the region densities in a subspace. Based on this idea, different density thresholds are adaptively determined to discover the clusters in different subspace cardinalities. Due to the infeasibility of applying previous techniques in this novel clustering model, we also devise an innovative algorithm, referred to as DENCOS (DENsity COnscious Subspace clustering), to adopt a divide-and-conquer scheme to efficiently discover clusters satisfying different density thresholds in different subspace cardinalities. As validated by our extensive experiments on various data sets, DENCOS can discover the clusters in all subspaces with high quality, and the efficiency of DENCOS outperformes previous works. © 2006 IEEE.},
author_keywords={And association rules;  Classification;  Clustering;  Data clustering;  Data mining;  Subspace clustering.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gonzales2009561,
author={Gonzales, E. and Taboada, K. and Mabu, S. and Shimada, K. and Hirasawa, K.},
title={Combination of two evolutionary methods for mining association rules in large and dense databases},
journal={Journal of Advanced Computational Intelligence and Intelligent Informatics},
year={2009},
volume={13},
number={5},
pages={561-572},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77749330166&partnerID=40&md5=173f32a2152b858240a2d5e93b36d146},
abstract={Among several methods of extracting association rules that have been reported, a new evolutionary method named Genetic Network Programming (GNP) has also shown its effectiveness for small databases in the sense that they have a relatively small number of attributes. However, this conventional GNP method is not be able to deal with large databases with a huge number of attributes, because its search space becomes very large, causing bad performance at running time. The aim of this paper is to propose a new method to extract association rules from large and dense databases with a huge amount of attributes through the combination of conventional GNP based mining method and a specially designed genetic algorithm (GA). Each of these evolutionary methods works in its own processing level and they are highly synchronized to act as one system. Our strategy consists in the division of a large and dense database into many small databases. These small databases are considered as individuals and form a population. Then the conventional GNP based mining method is applied to extract association rules for each of these individuals. Finally, the population is evolved through several generations using GA with special genetic operators considering the acquired information. Two complementary processing levels are defined: Global Level and Local Level, each with its own independent tasks and processes. In the Global Level mainly GA process is carried out, whereas in the Local Level, conventional GNP based mining method is carried out in parallel and they generate their own local pools of association rules. Several special genetic operations for GA in the Global Level are proposed and the performance of each of them and their combination is shown and compared. In our simulations, the conventional GNP based mining method and our proposed method are compared using a real world large and dense database with a huge amount of attributes. The results show that extending the conventional GNP based mining method using GA allows to extract association rules from large and dense databases directly and more efficiently than the conventional GNP method.},
author_keywords={Association rules;  Data mining;  Evolutionary computation;  Genetic algorithms (GA);  Genetic network programming (GNP)},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Nikolov20091258,
author={Nikolov, A. and Li, S. and Pottenger, W.M.},
title={Privacy-enhancing distributed higher-order ARM},
journal={Society for Industrial and Applied Mathematics - 9th SIAM International Conference on Data Mining 2009, Proceedings in Applied Mathematics},
year={2009},
volume={3},
pages={1258-1267},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-73449096119&partnerID=40&md5=5d4dffd2454bd96257dad5bd67176a73},
abstract={Traditional association rule mining algorithms assume that data instances are independent and identically distributed (IID) [29]. In statistical relational learning (SRL), however, relationships between instances can be leveraged to improve the performance of learning algorithms [2]. Higher-order association rule mining is an example of a SRL approach that does not make the IID assumption, but instead discovers itemsets that cross record boundaries [21]. Empirical analysis shows that higher-order methods perform especially well on small datasets as they are able to capture the variability of the underlying data distribution more readily than traditional methods [11]. In a distributed environment, however the discovery of higher-order itemsets reveals significant information about the nature of disparate data sources [21]. Preserving privacy in a setting in which data instances are treated as nodes in a graph rather than independent entities is an open problem in privacy research that has only recently received attention in the data mining community [24]. In this paper we propose a novel privacy-enhancing distributed higher-order ARM algorithm, PE-DiHO ARM. PE-DiHO ARM discovers itemsets from distributed data with a hybrid (non-horizontal, non-vertical) distribution while significantly limiting the amount of private data that is revealed. To demonstrate the validity of the approach we compare it to a non-privacy enhancing higher-order ARM algorithm [21] in an evaluation framework based on supervised learning [23]. Experimental results confirm that privacy can be significantly enhanced during the computation of higher-order itemsets in a distributed environment without significantly impacting performance. In future work we plan to apply these techniques to data provided by our law enforcement partners.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zhai2009457,
author={Zhai, K. and Ng, W.K. and Herianto, A.R. and Han, S.},
title={Speeding up secure computations via embedded caching},
journal={Society for Industrial and Applied Mathematics - 9th SIAM International Conference on Data Mining 2009, Proceedings in Applied Mathematics},
year={2009},
volume={1},
pages={457-468},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-72849108262&partnerID=40&md5=c5a1b592a496ff8584c6eb489148edc4},
abstract={Most existing work on Privacy-Preserving Data Mining (PPDM) focus on enabling conventional data mining algorithms with the ability to run in a secure manner in a multi-party setting. Although various algorithms in data mining have been enhanced to incorporate secure mechanisms for data privacy preservation, their computation performance is far too high to allow them to be practically useful. This is especially true for those algorithms that make use of common cryptosystems. In this paper, we address the efficiency issue of PPDM algorithms by proposing to cache result data that are used more than once by secure computations. For this to be possible, we carefully examine the micro steps of secure computations to identify the repetitive or iterative portions and reduce the overall computational cost by caching intermediate results/data. We have applied this to decision tree induction, association rule mining and k-means clustering that make use of secure building blocks such as secure multi-party sum, secure matrix multiplication, and secure inverse of matrix sum. We show empirically that the computational costs of secure computations can be reduced without affecting the quality of the data mining result in general. Our experiments show that the caching technique is generalizable to common data mining algorithms and the efficiency of PPDM algorithms can be greatly improved without compromising data privacy.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Popova2009283,
author={Popova, V. and Sharpanskykh, A.},
title={Constraint-based modelling and analysis of organisations},
journal={Proceedings of the ACM Symposium on Applied Computing},
year={2009},
pages={283-284},
doi={10.1145/1529282.1529343},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-72949107116&doi=10.1145%2f1529282.1529343&partnerID=40&md5=c7df1bdc672bd613cf81e379c74a7a88},
abstract={Modern organisations are characterised by a great variety of forms and often involve many actors with diverse goals, performing a wide range of tasks in changing environmental conditions. Due to high complexity, mistakes and inconsistencies are not rare in organisations. To provide better insights into the organisational operation and to identify different types of organisational problems explicit specification of relations and rules, on which the structure and behaviour of an organisation are based, is required. Before it is used, the specification of an organisation should be checked for internal consistency and validity w.r.t. the domain. To this end, the paper introduces a framework for formal specification of constraints that ensure the consistency and validity of organisational specifications. To verify the satisfaction of constraints, efficient and scalable algorithms have been developed and implemented. The framework presented here is based on the organisation modelling framework from [2] which defines four interrelated organisational views (or perspective) with their dedicated predicate logic-based languages: performance-oriented, process-oriented, organisation-oriented and agent-oriented. To express temporal relations, the dedicated languages of the views are embedded into the Temporal Trace Language (TTL) [2], which is a variant of the order-sorted predicate logic. Some of the examples given in the paper are from a case study in the air traffic domain. Copyright 2009 ACM.},
author_keywords={Consistency of a specification;  Constraints;  Organisation design;  Organisation modeling;  Validity of a specification},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Deng20093902,
author={Deng, L. and Ma, Z.M. and Tong, Q.},
title={A conceptual model of fuzzy temporal databases: Algebra},
journal={2009 Chinese Control and Decision Conference, CCDC 2009},
year={2009},
pages={3902-3907},
doi={10.1109/CCDC.2009.5191510},
art_number={5191510},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449381858&doi=10.1109%2fCCDC.2009.5191510&partnerID=40&md5=d9badce31337de574af56b4704cffbf4},
abstract={Most of the database research on modeling time has concentrated on the definition of a particular temporal model and its incorporation into a (relation or object) database management system. This has resulted in quite a large number of different temporal models. Representation and querying of temporal information can benefit from the integration of techniques from constraint databases, database models for fuzzy information and reasoning about temporal constraints. With this perspective in mind, we first present a hierarchy of temporal data models. Then we study the semantics of these models and develop algebraic for them. © 2009 IEEE.},
author_keywords={Algebra;  Fuzzy information;  Fuzzy temporal data model;  Fuzzy temporal database;  Fuzzy temporal relation},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Jinzhu2009293,
author={Jinzhu, P. and Yaonan, W. and Hui, Z.},
title={Recurrent fuzzy cerebellar model articulation controller and its application on robotic tracking control},
journal={Proceedings of the 2009 WRI Global Congress on Intelligent Systems, GCIS 2009},
year={2009},
volume={2},
pages={293-297},
doi={10.1109/GCIS.2009.184},
art_number={5209428},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449413498&doi=10.1109%2fGCIS.2009.184&partnerID=40&md5=99c68f372409b6e449e5377612459fde},
abstract={A kind of recurrent fuzzy cerebellar model articulation controller (RFCMAC) model is presented. The recurrent network is embedded in the RFCMAC by adding feedback connections on the first layer to embed temporal relations in the network. A nonconstant differentiable Gaussian basis function is used to model the hypercube structure and the fuzzy weight. A gradient descent learning algorithm is used to adjust the free parameters. Simulation experiments are made by applying proposed RFCMAC on robotic manipulator tracking control problem to confirm its effectiveness. © 2009 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Chun-Ling2009147,
author={Chun-Ling, C. and Frank, T. and Tyne, L.},
title={An integration of fuzzy association rules and wordNet for document clustering},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2009},
volume={5476 LNAI},
pages={147-159},
doi={10.1007/978-3-642-01307-2_16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650705072&doi=10.1007%2f978-3-642-01307-2_16&partnerID=40&md5=a7fd5f2ae52cbd24c282137f8225654a},
abstract={With the rapid growth of text documents, document clustering has become one of the main techniques for organizing large amount of documents into a small number of meaningful clusters. However, there still exist several challenges for document clustering, such as high dimensionality, scalability, accuracy, meaningful cluster labels, and extracting semantics from texts. In order to improve the quality of document clustering results, we propose an effective Fuzzy Frequent Itemset-based Document Clustering (F2IDC) approach that combines fuzzy association rule mining with the background knowledge embedded in WordNet. A term hierarchy generated from WordNet is applied to discovery fuzzy frequent itemsets as candidate cluster labels for grouping documents. We have conducted experiments to evaluate our approach on Reuters-21578 dataset. The experimental result shows that our proposed method outperforms the accuracy quality of FIHC, HFTC, and UPGMA. © Springer-Verlag Berlin Heidelberg 2009.},
author_keywords={Document clustering;  Frequent itemsets;  Fuzzy association rule mining;  Text mining;  WordNet},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Smith2009262,
author={Smith, M.R. and Wang, X. and Rangayyan, R.M.},
title={Evaluation of the sensitivity of a medical data-mining application to the number of elements in small databases},
journal={Biomedical Signal Processing and Control},
year={2009},
volume={4},
number={3},
pages={262-268},
doi={10.1016/j.bspc.2009.04.001},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650214852&doi=10.1016%2fj.bspc.2009.04.001&partnerID=40&md5=9e4cfb9342610187093a212e4f72375b},
abstract={Data-mining methods can be used to generate rules, or identify patterns, from medical data to assist clinical diagnosis and decision-making. However, in the initial stages of a clinical study on a new diagnostic approach, there could be a limited medical dataset available; or the medical characteristics could mean that the number of patients involved in the study will never be large. Diagnoses made using the rules discovered from such small medical databases should be considered suspect unless a confidence range for a particular diagnosis can be established. A method to evaluate the sensitivity and reliability of data-mining with small databases is presented in this paper. Efron's bootstrap method for statistical testing was used to assess the accuracy of the rules produced during the training step of the data-mining algorithm. The case study for validating this new approach was based on a limited-sized mammographic database previously used to discover associations between the diagnostic features of breast masses in mammograms and the biopsy-based classification of the masses. Using the new approach, it was possible to distinguish between the association rules that were sensitive to the size of the training datasets from those that were not. The methods proposed should lead to an efficient way for validating the patterns discovered in medical data-mining applications using small datasets. © 2009 Elsevier Ltd. All rights reserved.},
author_keywords={Breast cancer;  Efron's bootstrap method;  Mammographic masses;  Medical data-mining application;  Sensitivity evaluation},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Cadot200990,
author={Cadot, M. and Lelu, A.},
title={massive pruning for building an operational set of association rules: Metarules for eliminating conflicting and redundant rules.},
journal={Proceedings - International Conference on Information, Process, and Knowledge Management, eKNOW 2009},
year={2009},
pages={90-98},
doi={10.1109/eKNOW.2009.12},
art_number={4782571},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-63849153942&doi=10.1109%2feKNOW.2009.12&partnerID=40&md5=684260f485fb2f39d126f58df32fe69f},
abstract={Extracting a set of Association Rules (AR) is a common method for representing knowledge embedded in a database. As long as many authors have aimed at improving the individual quality of these rules, not so many have considered their global quality and cohesiveness: Our objective is to provide the user with a set of rules he/she may combine to reason with, a consistent set as regards to 'common sense logic'. As local quality measures offer no warranty in this respect, we have defined patterns of major incoherencies and have associated metarules to them, resulting in a post-treatment cleaning phase for tracking down incoherencies and proposing corrections. We show that on the artificial Lucas0 database of the Causality Challenge [11], starting from 100 000 rules, we have reduced this rule set by three orders of magnitude, to 69 high-quality condensed rules embedding most of the structure designed by the challenge organizers. © 2009 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Adnan200984,
author={Adnan, M. and Alhajj, R.},
title={DRFP-tree: Disk-resident frequent pattern tree},
journal={Applied Intelligence},
year={2009},
volume={30},
number={2},
pages={84-97},
doi={10.1007/s10489-007-0099-2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-62949123215&doi=10.1007%2fs10489-007-0099-2&partnerID=40&md5=57575b94e080ad6dad32e6fad0a21156},
abstract={Frequent itemset mining methods basically address time scalability and greatly rely on available physical memory. However, the size of real-world databases to be mined is exponentially increasing, and hence main memory size is a serious bottleneck of the existing methods. So, it is necessary to develop new methods that do not fully rely on physical memory; new methods that utilize the secondary storage in the mining process should be the target. This motivates the work described in this paper; we mainly propose (Disk Resident Frequent Pattern) DRFP-Growth as a disk based approach similar to FP-Growth. DRFP-growth uses DRFP-tree, which is treated exactly as FP-tree when constructed in main memory and gets into a modified structure when it turns into disk resident to overcome the main memory bottleneck. This way, we are able to mine for frequent itemsets from databases of arbitrary sizes without being restricted by the available physical memory. In other words, we initially try to mine the database using the original FP-growth; we expand into the secondary memory only if we run out of physical memory. So, DRFP-growth is very comparable to FP-growth for small databases and high support threshold values. On the other hand, using DRFP-growth, we are still able to mine huge databases for low support threshold values (the only limitation is the available secondary storage rather than physical memory). The reported test results demonstrate how the proposed approach succeeds for cases where main memory based approaches fail. © 2007 Springer Science+Business Media, LLC.},
author_keywords={Association rules;  Data mining;  DRFP-growth;  DRFP-tree;  FP-growth;  FP-tree;  Frequent pattern},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Xu2008,
author={Xu, Y. and Ma, Z. and Chen, X. and Li, L. and Dillon, T.S.},
title={Improving frequent patterns mining by LFP},
journal={2008 International Conference on Wireless Communications, Networking and Mobile Computing, WiCOM 2008},
year={2008},
doi={10.1109/WiCom.2008.2719},
art_number={4680908},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-58049094119&doi=10.1109%2fWiCom.2008.2719&partnerID=40&md5=54a3f7e093d45d59bfe6cf35b049ef39},
abstract={Frequent patterns mining is the focused research topic in association rule analysis. Most of the previous studies adopt Apriori-like algorithms or lattice-theoretic approaches which generate-and-test candidates. However, there are extremely invalidated candidate generations in the exponential search space. In this paper, we systematically explore the search space of frequent patterns mining and present a local frequent pruning (LFP) strategy based on local frequent property. LFP can be used in all Apriori-like algorithms. With a little more memory overhead, proposed pruning strategy can prune invalidated search space and effectively decrease the total number of infrequent candidate generation. For effectiveness testing reason, we optimize MAFIA and SPAM and present the improved algorithms, MAFIA+ and SPAM+. A comprehensive performance experiments study shows that LFP can improve performance by a factor of 10 on small datasets and better than 30% to 50% on reasonably large datasets. © 2008 IEEE.},
author_keywords={Association rule analysis;  Data mining;  Frequent patterns mining;  Pruning strategy},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Hadzic2008285,
author={Hadzic, F. and Tan, H. and Dillon, T.S.},
title={U3 - Mining unordered embedded subtrees using TMG candidate generation},
journal={Proceedings - 2008 IEEE/WIC/ACM International Conference on Web Intelligence, WI 2008},
year={2008},
pages={285-292},
doi={10.1109/WIIAT.2008.403},
art_number={4740462},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-62949243455&doi=10.1109%2fWIIAT.2008.403&partnerID=40&md5=b9a3f7e8cf19d1fdf02bd920037a63b3},
abstract={In this paper we present an algorithm for mining of unordered embedded subtrees. This is an important problem for association rule mining from semistructured documents, and it has important applications in many biomedical, web and scientific domains. The proposed U3 algorithm is an extension of our general tree model guided (TMG) candidate generation framework and it considers both transaction based and occurrence match support. Synthetic and real world data sets are used to experimentally demonstrate the efficiency of our approach to the problem, and the flexibility of our general TMG framework. © 2008 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hadzic2008272,
author={Hadzic, F. and Tan, H. and Dillon, T.},
title={Mining unordered distance-constrained embedded subtrees},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2008},
volume={5255 LNAI},
pages={272-283},
doi={10.1007/978-3-540-88411-8-26},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-56749151022&doi=10.1007%2f978-3-540-88411-8-26&partnerID=40&md5=041ec57f70aae125672edc5914543985},
abstract={Frequent subtree mining is an important problem in the area of association rule mining from semi-structured or tree structured documents, often found in many commercial, web and scientific domains. This paper presents the u3Razor algorithm, for mining unordered embedded subtrees where the distance of nodes relative to the root of the subtree needs to be considered. Mining distance-constrained unordered embedded subtrees will have important applications in web information systems, conceptual model analysis and more sophisticated knowledge matching. An encoding strategy is presented to efficiently enumerate candidate unordered embedded subtrees taking the distance of nodes relative to the root of the subtree into account. Both synthetic and real-world datasets were used for experimental evaluation and discussion. © 2008 Springer Berlin Heidelberg.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Shen2008301,
author={Shen, J.-J. and Hsu, P.-W.},
title={A fragile associative watermarking on 2D barcode for data authentication},
journal={International Journal of Network Security},
year={2008},
volume={7},
number={3},
pages={301-309},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863885032&partnerID=40&md5=c0984a918f016c5577ef54a4991e72de},
abstract={Two-dimensional (2D) barcode has improved the infor-mation encoded capacity, and it also has enriched the applications of barcode technique. Recently, there are researches dealing with watermark technique on 2D bar-code to prevent it from counterfeited or prepensely tam-pered. The existent methods still have to limit the size of embedded watermark in a relatively small portion. Fur-thermore, it also needs to utilize original watermark or other auxiliary verification mechanism to achieve the barcode verification. In this paper, we propose a method called associative watermarking which is conducted by the concept of Association Rules (ARs) and the idea of Vector Quantization (VQ). Our method is a kind of blind watermarking, and it also can free the size limitation of an embedded watermark. Performing associative water-marking to 2D barcode can reduce the embedded infor-mation amount, and using VQ indexing scheme can easily recall the embedded watermark for the purpose of barcode data authentication. The experiment demonstrates that our method can significantly save the information hiding capacity of 2D barcode and detects a counterfeited or prepensely tampered 2D barcode data correctly.},
author_keywords={2D barcode;  Association rules;  Associative watermark;  Authentication;  Digital watermark;  Vector quantization},
document_type={Article},
source={Scopus},
}

@CONFERENCE{NoAuthor2008,
title={2008 Cairo International Biomedical Engineering Conference, CIBEC 2008},
journal={2008 Cairo International Biomedical Engineering Conference, CIBEC 2008},
year={2008},
page_count={398},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-63649150423&partnerID=40&md5=a4861603e5ccd1482b44aaf08d5962f2},
abstract={The proceedings contain 85 papers. The topics discussed include: epileptic seizure detection using AR mode on EEG signals; reduced search space based association rule mining algorithm; computer-aided detection of benign tumors of the female breast; design and implementation of a swing phase control system for a prosthetic knee; classification of the imagination of the left and right hand movements using EEG; foundations of adaptive data stream mining for mobile and embedded applications; mining adverse drug reactions with e-science workflows; medical equipment quality assurance for healthcare facilities; ultra wide band radar based tamper-resistant clinical asset tracking system (ATS); appropriate medical technologies for developing countries: application to cardiovascular disorders; and medical equipment quality assurance by making continuous improvement to the system.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Ezeife200897,
author={Ezeife, C.I. and Dong, J. and Aggarwal, A.K.},
title={SensorWebIDS: A Web mining intrusion detection system},
journal={International Journal of Web Information Systems},
year={2008},
volume={4},
number={1},
pages={97-120},
doi={10.1108/17440080810865648},
art_number={1718625},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77958066110&doi=10.1108%2f17440080810865648&partnerID=40&md5=0ee0106c49af5921e91103b276dd662b},
abstract={Purpose: The purpose of this paper is to propose a web intrusion detection system (IDS), SensorWebIDS, which applies data mining, anomaly and misuse intrusion detection on web environment. Design/methodology/approach: SensorWebIDS has three main components: the network sensor for extracting parameters from real-time network traffic, the log digger for extracting parameters from web log files and the audit engine for analyzing all web request parameters for intrusion detection. To combat web intrusions like buffer-over-flow attack, SensorWebIDS utilizes an algorithm based on standard deviation (d) theory's empirical rule of 99.7 percent of data lying within 3dof the mean, to calculate the possible maximum value length of input parameters. Association rule mining technique is employed for mining frequent parameter list and their sequential order to identify intrusions. Findings: Experiments show that proposed system has higher detection rate for web intrusions than SNORT and mod security for such classes of web intrusions like cross-site scripting, SQL-Injection, session hijacking, cookie poison, denial of service, buffer overflow, and probes attacks. Research limitations/implications: Future work may extend the system to detect intrusions implanted with hacking tools and not through straight HTTP requests or intrusions embedded in non-basic resources like multimedia files and others, track illegal web users with their prior web-access sequences, implement minimum and maximum values for integer data, and automate the process of pre-processing training data so that it is clean and free of intrusion for accurate detection results. Practical implications: Web service security, as a branch of network security, is becoming more important as more business and social activities are moved online to the web. Originality/value: Existing network IDSs are not directly applicable to web intrusion detection, because these IDSs are mostly sitting on the lower (network/transport) level of network model while web services are running on the higher (application) level. Proposed SensorWebIDS detects XSS and SQL-Injection attacks through signatures, while other types of attacks are detected using association rule mining and statistics to compute frequent parameter list order and their maximum value lengths. © Emerald Group Publishing Limited.},
author_keywords={Data management;  Data security;  Internet;  Operating systems},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Zhang2008738,
author={Zhang, Z. and Huang, K. and Tan, T.},
title={Multi-thread parsing for recognizing complex events in videos},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2008},
volume={5304 LNCS},
number={PART 3},
pages={738-751},
doi={10.1007/978-3-540-88690-7-55},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-56749168875&doi=10.1007%2f978-3-540-88690-7-55&partnerID=40&md5=76a2c11a9d97ed7335a33e13db112de5},
abstract={This paper presents a probabilistic grammar approach to the recognition of complex events in videos. Firstly, based on the original motion features, a rule induction algorithm is adopted to learn the event rules. Then, a multi-thread parsing (MTP) algorithm is adopted to recognize the complex events involving parallel temporal relation in sub-events, whereas the commonly used parser can only handle the sequential relation. Additionally, a Viterbi-like error recovery strategy is embedded in the parsing process to correct the large time scale errors, such as insertion and deletion errors. Extensive experiments including indoor gymnastic exercises and outdoor traffic events are performed. As supported by experimental results, the MTP algorithm can effectively recognize the complex events due to the strong discriminative representation and the error recovery strategy. © 2008 Springer Berlin Heidelberg.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Habib200878,
author={Habib, S. and Safar, M.},
title={Hierarchical model for web multimedia documents retrieval and periodical updates},
journal={International Journal of Web Information Systems},
year={2008},
volume={4},
number={1},
pages={78-96},
doi={10.1108/17440080810865639},
art_number={1718624},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886387545&doi=10.1108%2f17440080810865639&partnerID=40&md5=2ce25ddbbe75e355b26bfd14126314ed},
abstract={Purpose: The purpose of this paper is to propose a four-level hierarchy model for multimedia documents representation to be used during the dynamic scheduling and altering of multimedia contents. Design/methodology/approach: The four-level hierarchy model (object, operation, timing, and precedence), offers a fine-grain representation of multimedia contents and is embedded within a research tool, which is called WEBCAP. WEBCAP utilizes the four-level hierarchy to synchronize the retrieval of objects in the multimedia document employing Allen's temporal relations, and then applies the Bellman-Ford's algorithm on the precedence graph to schedule all operations (fetch, transmit, process, and render), while satisfying the in-time updating and all web workload's resources constraints. Findings: The experimental results demonstrate the effectiveness of the model in scheduling the periodical updating multimedia documents while considering a variety of workloads on web/TCP. Research limitations/ implications: WEBCAP should be enhanced to automatically measure and/or approximate the available bandwidth of the system using sophisticated measurement of end-to-end connectivity. In addition, WEBCAP should be expanded and enhanced to examine system infrastructure for more real-time applications, such as tele-medicine and e-learning. Practical implications: WEBCAP can be used as an XML markup language for describing multimedia presentations. It can be used to create online presentations similar to PowerPoint on desktop environment, or used as an interactive e-learning tool. An HTML browser may use a WEBCAP plug-in to display a WEBCAP document embedded in an HTML/XML page. Originality/value: This paper proposed a dynamic scheduling of multimedia documents with frequent updates taking into consideration the network's workload to reduce the packet lost ratio in the TCP flow, especially in the early stages. WEBCAP can be used to guide distributed systems designers/managers to schedule or tune their resources for optimal or near optimal performance, subject to minimizing the cost of document retrieval while satisfying the in time constraints. © Emerald Group Publishing Limited.},
author_keywords={Information management;  Information retrieval;  Internet;  Modelling;  Multimedia},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Calargun2008631,
author={Calargun, S.U. and Yazici, A.},
title={Fuzzy association rule mining from spatio-temporal data},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2008},
volume={5072 LNCS},
number={PART 1},
pages={631-646},
doi={10.1007/978-3-540-69839-5_47},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-54249149374&doi=10.1007%2f978-3-540-69839-5_47&partnerID=40&md5=6bdaeb8e70bfa2a7e26475808167ca81},
abstract={The use of fuzzy sets in mining association rules from spatio-temporal databases is useful since fuzzy sets are able to model the uncertainty embedded in the meaning of data. There are several fuzzy association rule mining techniques that can work on spatio-temporal data. Their ability to mine fuzzy association rules has to be compared on a realistic scenario. Besides the performance criteria, other criteria that can express the quality of an association rule discovered shall be specified. In this paper, fuzzy association rule mining is performed with spatio-temporal data cubes and Apriori algorithm. A real life application is developed to compare data cubes and Apriori algorithm according to the following criteria: interpretability, precision, utility, novelty, direct-to-the-point, performance and visualization, which are defined within the scope of this paper. © 2008 Springer-Verlag Berlin Heidelberg.},
author_keywords={Association rule mining;  Association rule mining comparison criteria;  Data mining;  Fuzzy association rules;  Fuzzy spatio-temporal data cube},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Chong2008314,
author={Chong, S.K. and Gaber, M.M. and Loke, S.W. and Krishnaswamy, S.},
title={ARTS: Adaptive rule triggers on sensors for energy conservation in applications using coarse-granularity data},
journal={Proceedings of The International Conference on Embedded Software and Systems, ICESS 2008},
year={2008},
pages={314-321},
doi={10.1109/ICESS.2008.57},
art_number={4595576},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-51849166422&doi=10.1109%2fICESS.2008.57&partnerID=40&md5=1a6bb271a87a64fd6fb6556d235009ad},
abstract={Communicating extensive in-network data generated by resource-constrained wireless sensor nodes is an energy consuming process. To minimise the amount of data exchanged in sensor networks, several researchers have proposed novel and efficient protocols to perform data aggregations, clustering or regression on sensor nodes. Most of these approaches focus on optimising conventional mining techniques to work on resource-constrained sensor nodes. However, the application of association rules for sensor networks is an area of study that has not been investigated. This is due to the high computational cost of obtaining meaningful rules. Thus, in this paper, we propose Adaptive Rule Triggers on Sensors ARTS, to extract highly correlated rules from sensor data and apply them. The learnt rules are used to extend sensor lifetime by controlling sensor operations using triggers. Our approach is optimised to run on non-critical sensing applications/data-aggregation applications that can tolerate a coarse-granularity for sensed data. For this category of applications, our approach can derive meaningful rules efficiently to further conserve energy of wireless sensors. In this paper, these energy savings are evidenced in our experiments that adapt ARTS to a state-of-the-art clustering protocol. © 2008 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Cano-Izquierdo20081006,
author={Cano-Izquierdo, J.M. and Ibarrola, J. and Pinzolas, M. and Almonacid, M.},
title={dNSP: A biologically inspired dynamic Neural network approach to Signal Processing},
journal={Neural Networks},
year={2008},
volume={21},
number={7},
pages={1006-1019},
doi={10.1016/j.neunet.2008.03.015},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-51049090378&doi=10.1016%2fj.neunet.2008.03.015&partnerID=40&md5=250c14ffad03c9dbbf1dcdc1e615d119},
abstract={The arriving order of data is one of the intrinsic properties of a signal. Therefore, techniques dealing with this temporal relation are required for identification and signal processing tasks. To perform a classification of the signal according with its temporal characteristics, it would be useful to find a feature vector in which the temporal attributes were embedded. The correlation and power density spectrum functions are suitable tools to manage this issue. These functions are usually defined with statistical formulation. On the other hand, in biology there can be found numerous processes in which signals are processed to give a feature vector; for example, the processing of sound by the auditory system. In this work, the dNSP (dynamic Neural Signal Processing) architecture is proposed. This architecture allows representing a time-varying signal by a spatial (thus statical) vector. Inspired by the aforementioned biological processes, the dNSP performs frequency decomposition using an analogical parallel algorithm carried out by simple processing units. The architecture has been developed under the paradigm of a multilayer neural network, where the different layers are composed by units whose activation functions have been extracted from the theory of Neural Dynamic [Grossberg, S. (1988). Nonlinear neural networks principles, mechanisms and architectures. Neural Networks, 1, 17-61]. A theoretical study of the behavior of the dynamic equations of the units and their relationship with some statistical functions allows establishing a parallelism between the unit activations and correlation and power density spectrum functions. To test the capabilities of the proposed approach, several testbeds have been employed, i.e. the frequencial study of mathematical functions. As a possible application of the architecture, a highly interesting problem in the field of automatic control is addressed: the recognition of a controlled DC motor operating state. © 2008 Elsevier Ltd. All rights reserved.},
author_keywords={Correlation function;  Neural dynamic theory;  Power spectrum;  Sigma-Pi units;  Signal Processing},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Bashir2008172,
author={Bashir, S. and Halim, Z. and Baig, A.R.},
title={Mining fault tolerant frequent patterns using pattern growth approach},
journal={AICCSA 08 - 6th IEEE/ACS International Conference on Computer Systems and Applications},
year={2008},
pages={172-179},
doi={10.1109/AICCSA.2008.4493532},
art_number={4493532},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-50049101806&doi=10.1109%2fAICCSA.2008.4493532&partnerID=40&md5=ef94294880eba7645c8448efd625ee0c},
abstract={Mining fault tolerant (FT) frequent patterns from transactional datasets are very complex than mining all frequent patterns (itemsets), in terms of both search space exploration and support counting of candidate FT-patterns. Previous studies on mining FT frequent patterns adopt Apriori-like candidate set generationand-test approach, in which a number of dataset scans are needed to declare a candidate FT-pattern frequent. First for checking its FT-pattern support, and then for checking its individual items support present in its FT-pattern which depends on the cardinality of pattern. Inspired from the pattern growth technique for mining frequent itemsets, in this paper we present a novel algorithm for mining FT frequent patterns using pattern growth approach. Our algorithm stores the original transactional dataset in a highly condensed, much smaller data structure called FT-FP-tree, and the FT-pattern support and item support of all the FT-patterns are counting directly from the FT-FP-tree, without scanning the original dataset multiple times. While costly candidate set generations are avoided by generating conditional patterns from FT-FP-tree. Our extensive experiments on benchmark datasets suggest that, mining FT frequent patterns using our algorithm is highly efficient as compared to Apriori-like approach. © 2008 IEEE.},
author_keywords={Association rules;  Bit-vector representation;  Fault tolerant frequent patterns mining;  Maximal frequent patterns mining},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Huan2008,
author={Huan, T. and Sivachenko, A.Y. and Harrison, S.H. and Chen, J.Y.},
title={ProteoLens: A visual analytic tool for multi-scale database-driven biological network data mining},
journal={BMC Bioinformatics},
year={2008},
volume={9},
number={SUPPL. 9},
doi={10.1186/1471-2105-9-S9-S5},
art_number={S5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-49649091381&doi=10.1186%2f1471-2105-9-S9-S5&partnerID=40&md5=2c1647ac4480978db26d7169c4eb55d4},
abstract={Background: New systems biology studies require researchers to understand how interplay among myriads of biomolecular entities is orchestrated in order to achieve high-level cellular and physiological functions. Many software tools have been developed in the past decade to help researchers visually navigate large networks of biomolecular interactions with built-in template-based query capabilities. To further advance researchers' ability to interrogate global physiological states of cells through multi-scale visual network explorations, new visualization software tools still need to be developed to empower the analysis. A robust visual data analysis platform driven by database management systems to perform bi-directional data processing-to-visualizations with declarative querying capabilities is needed. Results: We developed ProteoLens as a JAVA-based visual analytic software tool for creating, annotating and exploring multi-scale biological networks. It supports direct database connectivity to either Oracle or PostgreSQL database tables/views, on which SQL statements using both Data Definition Languages (DDL) and Data Manipulation languages (DML) may be specified. The robust query languages embedded directly within the visualization software help users to bring their network data into a visualization context for annotation and exploration. ProteoLens supports graph/network represented data in standard Graph Modeling Language (GML) formats, and this enables interoperation with a wide range of other visual layout tools. The architectural design of ProteoLens enables the de-coupling of complex network data visualization tasks into two distinct phases: 1) creating network data association rules, which are mapping rules between network node IDs or edge IDs and data attributes such as functional annotations, expression levels, scores, synonyms, descriptions etc; 2) applying network data association rules to build the network and perform the visual annotation of graph nodes and edges according to associated data values. We demonstrated the advantages of these new capabilities through three biological network visualization case studies: human disease association network, drug-target interaction network and protein-peptide mapping network. Conclusion: The architectural design of ProteoLens makes it suitable for bioinformatics expert data analysts who are experienced with relational database management to perform large-scale integrated network visual explorations. ProteoLens is a promising visual analytic platform that will facilitate knowledge discoveries in future network and systems biology studies. © 2008 Huan et al; licensee BioMed Central Ltd.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tan20089,
author={Tan, H. and Hadzic, F. and Dillon, T.S. and Chang, E. and Feng, L.},
title={Tree model guided candidate generation for mining frequent subtrees from XML documents},
journal={ACM Transactions on Knowledge Discovery from Data},
year={2008},
volume={2},
number={2},
pages={9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-49149120315&partnerID=40&md5=a168fd783177eaff77c7b4a4b2e6267b},
abstract={Due to the inherent flexibilities in both structure and semantics, XML association rules mining faces few challenges, such as: a more complicated hierarchical data structure and ordered data context. Mining frequent patterns from XML documents can be recast as mining frequent tree structures from a database of XML documents. In this study, we model a database of XML documents as a database of rooted labeled ordered subtrees. In particular, we are mainly concerned with mining frequent induced and embedded ordered subtrees. Our main contributions are as follows. We describe our unique embedding list representation of the tree structure, which enables efficient implementation of our Tree Model Guided (TMG) candidate generation. TMG is an optimal, nonredundant enumeration strategy that enumerates all the valid candidates that conform to the structural aspects of the data. We show through a mathematical model and experiments that TMG has better complexity compared to the commonly used join approach. In this article, we propose two algorithms, MB3-Miner and iMB3-Miner. MB3-Miner mines embedded subtrees. iMB3-Miner mines induced and/or embedded subtrees by using the maximum level of embedding constraint. Our experiments with both synthetic and real datasets against two well-known algorithms for mining induced and embedded subtrees, demonstrate the effectiveness and the efficiency of the proposed techniques. © 2008 ACM.},
author_keywords={FREQT;  TMG;  Tree mining;  Tree model guided;  TreeMiner},
document_type={Article},
source={Scopus},
}

@ARTICLE{Tan20081,
author={Tan, H. and Hadzic, F. and Dillon, T.S. and Chang, E. and Feng, L.},
title={Tree Model Guided Candidate Generation for Mining Frequent Subtrees from XML Documents},
journal={ACM Transactions on Knowledge Discovery from Data},
year={2008},
volume={2},
number={2},
pages={1-43},
doi={10.1145/1376815.1376818},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962804101&doi=10.1145%2f1376815.1376818&partnerID=40&md5=fb0eae081157058243ee18fa0dd34ae8},
abstract={Due to the inherent flexibilities in both structure and semantics, XML association rules mining faces few challenges, such as: a more complicated hierarchical data structure and ordered data context. Mining frequent patterns from XML documents can be recast as mining frequent tree structures from a database of XML documents. In this study, we model a database of XML documents as a database of rooted labeled ordered subtrees. In particular, we are mainly concerned with mining frequent induced and embedded ordered subtrees. Our main contributions are as follows. We describe our unique embedding list representation of the tree structure, which enables efficient implementation of our Tree Model Guided (TMG) candidate generation. TMG is an optimal, nonredundant enumeration strategy that enumerates all the valid candidates that conform to the structural aspects of the data. We show through a mathematical model and experiments that TMG has better complexity compared to the commonly used join approach. In this article, we propose two algorithms, MB3-Miner and iMB3-Miner. MB3-Miner mines embedded subtrees. iMB3-Miner mines induced and/or embedded subtrees by using the maximum level of embedding constraint. Our experiments with both synthetic and real datasets against two well-known algorithms for mining induced and embedded subtrees, demonstrate the effectiveness and the efficiency of the proposed techniques. © 2008, ACM. All rights reserved.},
author_keywords={Algorithms;  Experimentation;  FREQT;  Performance;  TMG;  Tree mining;  tree model guided;  TreeMiner},
document_type={Article},
source={Scopus},
}

@ARTICLE{Brossette2008119,
author={Brossette, S.E. and Hymel Jr., P.A.},
title={Data Mining and Infection Control},
journal={Clinics in Laboratory Medicine},
year={2008},
volume={28},
number={1},
pages={119-126},
doi={10.1016/j.cll.2007.10.007},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-37849044613&doi=10.1016%2fj.cll.2007.10.007&partnerID=40&md5=21f0b090e4c0c173ab29fb9e85c2eda6},
abstract={Patterns embedded in large volumes of clinical data may provide important insights into the characteristics of patients or care delivery processes, but may be difficult to identify by traditional means. Data mining offers methods that can recognize patterns in these large data sets and make them actionable. We present an example of this capability in which we successfully applied data mining to hospital infection control. The Data Mining Surveillance System (DMSS) uses data from the clinical laboratory and hospital information systems to create association rules linking patients, sample types, locations, organisms, and antibiotic susceptibilities. Changes in association strength over time signal epidemiologic patterns potentially appropriate for follow-up, and additional heuristic methods identify the most informative of these patterns for alerting. © 2008 Elsevier Inc. All rights reserved.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Gorla200835,
author={Gorla, N. and Betty, P.W.Y.},
title={Vertical fragmentation in databases using data-mining technique},
journal={International Journal of Data Warehousing and Mining},
year={2008},
volume={4},
number={3},
pages={35-53},
doi={10.4018/jdwm.2008070103},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-47349098800&doi=10.4018%2fjdwm.2008070103&partnerID=40&md5=327acf5652f0266820f93b0308dfd1f8},
abstract={A new approach to vertical fragmentation in relational databases is proposed using association rules, a data-mining technique. Vertical fragmentation can enhance the performance of database systems by reducing the number of disk accesses needed by transactions. By adapting Apriori algorithm, a design methodology for vertical partitioning is proposed. The heuristic methodology is tested using two real-life databases for various minimum support levels and minimum confidence levels. In the smaller database, the partitioning solution obtained matched the optimal solution using exhaustive enumeration. Ae application of our method on the larger database resulted in the partitioning solution that has an improvement of 41.05% over unpartitioned solution and took less than a second to produce the solution. We provide future research directions an extending the procedure to distributed and object-oriented database designs. Copyright © 2008, IGI Global.},
author_keywords={Association rules;  Data mining;  Database performance;  Design methodologies;  Information systems;  Physical database design;  Vertical partitioning},
document_type={Article},
source={Scopus},
}

@ARTICLE{Hébert2007533,
author={Hébert, C. and Crémilleux, B.},
title={A unified view of objective interestingness measures},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2007},
volume={4571 LNAI},
pages={533-547},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-37249066652&partnerID=40&md5=65c5b3b9bf056b88c0defca6ad13654a},
abstract={Association rule mining often results in an overwhelming number of rules. In practice, it is difficult for the final user to select the most relevant rules. In order to tackle this problem, various interestingness measures were proposed. Nevertheless, the choice of an appropriate measure remains a hard task and the use of several measures may lead to conflicting information. In this paper, we give a unified view of objective interestingness measures. We define a new framework embedding a large set of measures called SBMs and we prove that the SBMs have a similar behavior. Furthermore, we identify the whole collection of the rules simultaneously optimizing all the SBMs. We provide an algorithm to efficiently mine a reduced set of rules among the rules optimizing all the SBMs. Experiments on real datasets highlight the characteristics of such rules. © Springer-Verlag Berlin Heidelberg 2007.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Gonzales20072686,
author={Gonzales, E. and Shimada, K. and Mabu, S. and Hirasawa, K. and Hu, J.},
title={Hierarchical association rule mining in large and dense databases using genetic network programming},
journal={Proceedings of the SICE Annual Conference},
year={2007},
pages={2686-2693},
doi={10.1109/SICE.2007.4421446},
art_number={4421446},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-50249187805&doi=10.1109%2fSICE.2007.4421446&partnerID=40&md5=022640274abc5acdb81e2953b1d635dd},
abstract={In this paper we propose a new hierarchical method to extract association rules from large and dense datasets using Genetic Network Programming (GNP) considering a real world database with a huge number of attributes. It uses three ideas. First, the large database is divided into many small datasets. Second, these small datasets are independently processed by the conventional GNP-based mining method (CGNP) in parallel. This level of processing is called Local Level. Finally, new genetic operations are carried out for small datasets considered as individuals in order to improve the number of rules extracted and their quality as well. This level of processing is called Global Level. The amount of small datasets is also important especially for avoiding the overload and improving the general performance; we find the minimum amount of files needed to extract important association rules. The proposed method shows its effectiveness in simulations using a real world large and dense database. © 2007 SICE.},
author_keywords={Association rules;  Data mining;  Genetic network programming;  Parallel processing},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Gonzales20074615,
author={Gonzales, E. and Taboada, K. and Shimada, K. and Mabu, S. and Hirasawa, K. and Hu, J.},
title={Class association rule mining for large and dense databases with parallel processing of genetic network programming},
journal={2007 IEEE Congress on Evolutionary Computation, CEC 2007},
year={2007},
pages={4615-4622},
doi={10.1109/CEC.2007.4425077},
art_number={4425077},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955312177&doi=10.1109%2fCEC.2007.4425077&partnerID=40&md5=bdb0f6c35d3436436ab4b2ad8b9cc908},
abstract={Among several methods of extracting association rules that have been reported, a new evolutionary computation method named Genetic Network Programming (GNP) has also shown its effectiveness for small datasets that have a relatively small number of attributes. The aim of this paper is to propose a new method to extract association rules from large and dense datasets with a huge amount of attributes using GNP. It consists of two-level of processing. Server Level where conventional GNP based mining method runs in parallel and Client Level where files are considered as individuals and genetic operations are carried out over them. The algorithm starts dividing the large dataset into small datasets with appropiate size, and then each of them are dealt with GNP in parallel processing. The new association rules obtained in each generation are stored in a general global pool. We compared several genetic operators applied to the individuals in the Global Level. The proposed method showed remarkable improvements on simulations. © 2007 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Couturier2007258,
author={Couturier, O. and Rouillard, J. and Chevrin, V.},
title={An interactive approach to display large sets of association rules},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2007},
volume={4557 LNCS},
number={PART 1},
pages={258-267},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-38149007784&partnerID=40&md5=e0c9bac2567ebcf6c45265852be41303},
abstract={Knowledge Discovery in Databases (KDD) is an active research domain. Due to the number of large databases, various data mining methods were developed. Those tools can generate a large amount of knowledge that needs more advanced tools to be explored. We focus on association rules mining such as "If Antecedent then Conclusion" and more particularly on rules visualization during the post processing stage in order to help expert's analysis. An association rule is mainly calculated depending on two user-specified metrics: support and confidence. All current representations present a common limitation which is effective on small data quantities. We introduced a new interactive approach which combines both a global representation (2D matrix) and a detailed representation (Fisheyes view) in order to display large sets of association rules. © Springer-Verlag Berlin Heidelberg 2007.},
author_keywords={Human Computer Interaction (HCI);  Knowledge Discovery in Databases (KDD);  Visualization},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Gruenwald2007207,
author={Gruenwald, L. and Chok, H. and Aboukhamis, M.},
title={Using data mining to estimate missing sensor data},
journal={Proceedings - IEEE International Conference on Data Mining, ICDM},
year={2007},
pages={207-212},
doi={10.1109/ICDMW.2007.103},
art_number={4476669},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-49549091727&doi=10.1109%2fICDMW.2007.103&partnerID=40&md5=b5fea1dd1140f0911df676f80e804f58},
abstract={Estimating missing sensor values is an inherent problem in sensor network applications; however, existing data estimation approaches do not apply well to the context of datastreams, a major characteristic of sensornet applications. Additionally, they fail to account for relationships among sensors and simultaneously, incorporate the time factor making the estimation process computationally aware of the relative relevance of each data round in the datastream. To address this gap, we propose a data estimation technique, FARM, which uses association rule mining to discover intrinsic relationships among sensors and incorporate them into the data estimation while taking data freshness into consideration. FARM was tested with data from two real sensornet applications, namely climate sensing and traffic monitoring. Simulation shows that in terms of estimation accuracy, FARM outperformed existing techniques costing only marginally more space and time overheads while scaling well with the network size, thus assuring quality of service for real-time applications. © 2007 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Xu2007,
author={Xu, F. and Sheng, J. and Chen, J.},
title={Rough sets based fuzzy logic control for greenhouse temperature},
journal={Proceedings of the 2nd IEEE/ASME International Conference on Mechatronic and Embedded Systems and Applications, MESA 2006},
year={2007},
doi={10.1109/MESA.2006.296991},
art_number={4077818},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-44949265548&doi=10.1109%2fMESA.2006.296991&partnerID=40&md5=4f8a0bf1950e2476b8750d778c54744c},
abstract={In this paper, a rough sets based fuzzy logic control method was proposed for greenhouse temperature control. The process of system attribute reduct and a normalized processing for the sample data were carried out. Then the discernibility function was applied In the mining of certain and association rules from an Incomplete decision table. Two overall thumb rules were generated for the definition of the fuzzy logic rule set. The corresponding fuzzy logic control system for greenhouse temperature was established by using the Simullnk tools of MATLAB, Including the choosing of variables, grade partition of the universes, choosing of membership functions. The simulation achieved good performance, which verified the validity of employing rough sets based fuzzy logic control for greenhouse temperature control.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{González2007213,
author={González, M.P. and Granollers, T. and Lorés, J.},
title={A hybrid approach for modelling early prototype evaluation under user-centred design through association rules},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2007},
volume={4323 LNCS},
pages={213-219},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-35349031890&partnerID=40&md5=398410e0a2db6971f49586f239e7f955},
abstract={One of the main activities in User Centred Design (UCD) is prototype evaluation, which is traditionally performed by means of an Evaluation Stage that looks for the redefinition of the prototype requirements, involving quantitative and qualitative usability testing techniques. This paper describes a new approach in which the traditional methodology for performing the Evaluation Stage under UCD is embedded in a framework with capabilities for mining association rules. This allows to minimise the impact of the interpretation bias of the evaluation team when analysing ambiguous user statements in natural language. © Springer-Verlag Berlin Heidelberg 2007.},
author_keywords={Association rules;  Data mining;  Evaluation stage;  UCD},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Gonzales20071512,
author={Gonzales, E. and Shimada, K. and Mabu, S. and Hirasawa, K. and Hu, J.},
title={Genetic network programming with parallel processing for association rule mining in large and dense databases},
journal={Proceedings of GECCO 2007: Genetic and Evolutionary Computation Conference},
year={2007},
pages={1512},
doi={10.1145/1276958.1277241},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548063771&doi=10.1145%2f1276958.1277241&partnerID=40&md5=1050f66534de5bd23ef54eb4c710e908},
abstract={Several methods of extracting association rules have been reported. A new evolutionary computation method named Genetic Network Programming (GNP) has also been developed recently and its efectiveness is shown for small datasets. However, it has not been tested for large datasets, particularly in datasets with a large number of attributes. The aim of this paper is to extract association rules from large and dense datasets using GNP considering a real world database with a huge number of attributes. We propose a new method where a large database is divided into many small datasets, then each GNP deals with one dataset having attributes with appropiate size, which was selected randomly from a large dataset and generated genetically. These GNPs are processed in parallel. We then propose some new genetic operations to improve the number of rules extracted and their quality as well. The proposed method improves remarkably on simulations. Fig. 1 shows the architecture of the proposed method. We use the CLIENT/SERVER model. CLIENT side carries out preprocessing of large database, assignment of files to each server, rule checking, and genetic operations on files. SERVER side carries out processing of each file using conventional GNP based mining method independently. The features and advantages of the proposed method are the following: Rule extraction is done in parallel. Each file generates its local pool of the rules. Files or datasets are treated as individuals in order to do new genetic operations over them and improve the rule extraction. Extracted rules are stored in a global pool. The rules are verified to avoid redundancy among them and it is assured that only new rules are stored.},
author_keywords={Association rules;  Genetic network programming;  Parallel processing},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Peng2007651,
author={Peng, Y.-F. and Lin, C.-M.},
title={RCMAC-based adaptive control for uncertain nonlinear systems},
journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics},
year={2007},
volume={37},
number={3},
pages={651-666},
doi={10.1109/TSMCB.2006.888761},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-34249071319&doi=10.1109%2fTSMCB.2006.888761&partnerID=40&md5=e6e694b7db05acd79daa327004bb616d},
abstract={An adaptive control system, using a recurrent cerebellar model articulation controller (RCMAC) and based on a sliding mode technique, is developed for uncertain nonlinear systems. The proposed dynamic structure of RCMAC has superior capability to the conventional static cerebellar model articulation controller in an efficient learning mechanism and dynamic response. Temporal relations are embedded in RCMAC by adding feedback connections in the association memory space so that the RCMAC provides a dynamical structure. The proposed control system consists of an adaptive RCMAC and a compensated controller. The adaptive RCMAC is used to mimic an ideal sliding mode controller, and the compensated controller is designed to compensate for the approximation error between the ideal sliding mode controller and the adaptive RCMAC. The online adaptive laws of the control system are derived based on the Lyapunov stability theorem, so that the stability of the system can be guaranteed. In addition, in order to relax the requirement of the approximation error bound, an estimation law is derived to estimate the error bound. Finally, the simulation and experimental studies demonstrate the effectiveness of the proposed control scheme for the nonlinear systems with unknown dynamic functions. © 2007 IEEE.},
author_keywords={Adaptive control;  Nonlinear systems;  Recurrent cerebellar model articulation controller (RCMAC);  Sliding mode control (SMC)},
document_type={Article},
source={Scopus},
}

@ARTICLE{Shen20071355,
author={Shen, J.-J. and Hsu, P.-W.},
title={A robust associative watermarking technique based on similarity diagrams},
journal={Pattern Recognition},
year={2007},
volume={40},
number={4},
pages={1355-1367},
doi={10.1016/j.patcog.2006.09.015},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845397101&doi=10.1016%2fj.patcog.2006.09.015&partnerID=40&md5=315f23220bae819ee2df213ae320ea3c},
abstract={In this paper, a new digital watermarking technique is proposed for watermarking in a random sequence form. By the term associative watermarking we refer to this new technique that combines the traditional idea of digital watermarking with the concept of association rules widely applied in the field of data mining. As our experimental results, after the similarity diagram test, the new digital watermarking technique proves to be capable of guaranteeing the existence and uniqueness of the extracted watermark even when the embedded image has gone through various kinds of image processing procedures. © 2006 Pattern Recognition Society.},
author_keywords={Association rule;  Digital watermarking;  Image;  Random sequence;  Similarity diagram},
document_type={Article},
source={Scopus},
}

@CONFERENCE{NoAuthor2006,
title={Proceedings: First International Multi- Symposiums on Computer and Computational Sciences (IMSCCSo6)},
journal={First International Multi- Symposiums on Computer and Computational Sciences, IMSCCS'06},
year={2006},
volume={2},
page_count={834},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845529202&partnerID=40&md5=e2cdaf8367d37689a70c415d83a6d70f},
abstract={The proceedings contain 141 papers. The topics discussed include: a novel stochastic generalized cellular automata for self-organizing data clustering; a novel mining approach for schemas in XML documents; an improved cascade SVM training algorithm with crossed feedbacks; temporal association rules in mining method; weighted ordinal support vector clustering; a privacy-preserving mining algorithm of association rules in distributed databases; design of smart phone-oriented embedded real-time operating system; an advanced timing characterization method considering global false path; knowledge and process based decision support in business intelligence system; a cellular automaton technique for the modeling of solidification microstructure in multi-component alloys; an improvement of an identity-based key issuing protocol; designated verifier proxy signature scheme from bilinear pairings; and a proxy-protected signature scheme based on finite automaton.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Meo2006135,
author={Meo, R. and Lanzi, P.L. and Matera, M. and Esposito, R.},
title={Integrating Web conceptual modeling and Web usage mining},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2006},
volume={3932 LNAI},
pages={135-148},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845216719&partnerID=40&md5=f863759f04c7f7d719b0d72ad1a139c8},
abstract={We present a case study about the application of the inductive database approach to the analysis of Web logs. We consider rich XML Web logs - called conceptual logs - that are generated by Web applications designed with the WebML conceptual model and developed with the WebRatio CASE tool. Conceptual logs integrate the usual information about user requests with meta-data concerning the structure of the content and the hypertext of a Web application. We apply a data mining language (MINE RULE) to conceptual logs in order to identify different types of patterns, such as: recurrent navigation paths, most frequently visited page contents, and anomalies (e.g., intrusion attempts or harmful usages of resources). We show that the exploitation of the nuggets of information embedded in the logs and of the specialized mining constructs provided by the query languages enables the rapid customization of the mining procedures following to the Web developers' need. Given our on-field experience, we also suggest that the use of queries in advanced languages, as opposed to ad-hoc heuristics, eases the specification and the discovery of large spectrum of patterns. © Springer-Verlag Berlin Heidelberg 2006.},
author_keywords={Association rules;  Inductive databases;  MINE RULE;  Web log;  Web structure mining;  Web usage mining},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Pham2006521,
author={Pham, S.B. and Hoffmann, A.},
title={Efficient knowledge acquisition for extracting temporal relations},
journal={Frontiers in Artificial Intelligence and Applications},
year={2006},
volume={141},
pages={521-525},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886039467&partnerID=40&md5=5486b4341c3df66f659bba200aed8085},
abstract={Machine learning approaches in natural language processing often require a large annotated corpus. We present a complementary approach that utilizes expert knowledge to overcome the scarceness of annotated data. In our framework KAFTIE, the expert could easily create a large number of rules in a systematic manner without the need of a knowledge engineer. Using KAFTIE, a knowledge base was built based on a small data set that outperforms machine learning algorithms trained on a much bigger data set for the task of recognizing temporal relations. Furthermore, our knowledge acquisition approach could be used in synergy with machine learning algorithms to both increase the performance of the machine learning algorithms and to reduce the expert's knowledge acquisition effort. © 2006 The authors.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Hsieh2006272,
author={Hsieh, A. and Kuo, R. and Hsu, C.-K. and Chang, M. and Heh, J.-S.},
title={Making static online teaching materials be flexible to learners by reconstructing its hypermedia structures automatically},
journal={7th International Conference on Information Technology Based Higher Education and Training, ITHET},
year={2006},
pages={272-279},
doi={10.1109/ITHET.2006.339775},
art_number={4141638},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-46949095261&doi=10.1109%2fITHET.2006.339775&partnerID=40&md5=97a545837c57449cf615c922fd7dcbb2},
abstract={Many teachers and researchers put their teaching materials on the Internet for students to read in recent years. This sort of teaching materials could be seen as static because students can only follow the learning sequence made by teachers in advance. The goal of this paper is trying to develop a tool, K-Navi toolbar, to parse and rebuild teaching materials' hypermedia structures according to the concept relations and extracted rules automatically. K-Navi toolbar first uses the Formal Concept Analysis (FCA) to parse the whole set of teaching materials and gets the embedded concept relations between each of two instructional documents; then uses the Association Rule Methodology (ARM) to extract the rules from the concept lattices; and, finally rebuilds the hypermedia structure of the instructional document read by the student automatically. K-Navi toolbar adds related concept hyperlinks (or says links to other knowledge pieces) into the specific position on the instructional hypermedia document automatically when a student asks the document resource. A student then will be able to dig related knowledge pieces via these relevant hyperlinks. © 2006 IEEE.},
author_keywords={Adaptive web;  Association rule;  e-Learning;  Formal concept analysis;  Hypermedia environment;  Keyword;  Knowledge navigation},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Hadzic2006213,
author={Hadzic, F. and Dillon, T.S. and Sidhu, A.S. and Chang, E. and Tan, H.},
title={Mining substructures in protein data},
journal={Proceedings - IEEE International Conference on Data Mining, ICDM},
year={2006},
pages={213-217},
art_number={4063627},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-78449286038&partnerID=40&md5=94bca20646d70c93469ab9fe04a1eb60},
abstract={In this paper we consider the 'Prions' database that describes protein instances stored for Human Prion Proteins. The Prions database can be viewed as a database of rooted ordered labeled subtrees. Mining frequent substructures from tree databases is an important task and it has gained a considerable amount of interest in areas such as XML mining, Bioinformatics, Web mining etc. This has given rise to the development of many tree mining algorithms which can aid in structural comparisons, association rule discovery and in general mining of tree structured knowledge representations. Previously we have developed the MB3 tree mining algorithm, which given a minimum support threshold, efficiently discovers all frequent embedded subtrees from a database of rooted ordered labeled subtrees. In this work we apply the algorithm to the Prions database in order to extract the frequently occurring patterns, which in this case are of induced subtree type. Obtaining the set of frequent induced subtrees from the Prions database can potentially reveal some useful knowledge. This aspect will be demonstrated by providing an analysis of the extracted frequent subtrees with respect to discovering interesting protein information. Furthermore, the minimum support threshold can be used as the controlling factor for answering specific queries posed on the Prions dataset. This approach is shown to be a viable technique for mining protein data. © 2006 IEEE.},
author_keywords={Association mining;  Frequent subtree mining;  Protein discovery;  Structure matching},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lee200690,
author={Lee, H. and Kang, S. and Ko, H.},
title={Decision theoretic fusion framework for actionability using data mining on an embedded system},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2006},
volume={3755 LNAI},
pages={90-104},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-37149016313&partnerID=40&md5=085d5574031af765948eb95036eb214c},
abstract={This paper proposes a decision theoretic fusion framework for actionability using data mining techniques in an embedded car navigation system. An embedded system having limited resources is not easy to manage the abundant information in the database. Thus, the proposed system stores and manages only multiple level-of-abstraction in the database to resolve the problem of resource limitations, and then represents the information received from the Web via the wireless network after connecting a communication channel with the data mining server. To do this, we propose a decision theoretic fusion framework that includes the multiple level-of-abstraction approach combining multiple-level association rules and the summary table, as well as an active interaction rule generation algorithm for actionability in an embedded car navigation system. In addition, it includes the sensory and data fusion level rule extraction algorithm to cope with simultaneous events occurring from multimodal interface. The proposed framework can make interactive data mining flexible, effective, and instantaneous in extracting the proper action item. © Springer-Verlag Berlin Heidelberg 2006.},
author_keywords={Data mining;  Embedded data mining;  Speech interactive approach},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zeng20066636,
author={Zeng, K. and Zeng, B. and Sun, D. and Li, Y. and Wang, Y.},
title={Achievement to abnormity association of processor and embedded operating system},
journal={Proceedings of the World Congress on Intelligent Control and Automation (WCICA)},
year={2006},
volume={2},
pages={6636-6640},
doi={10.1109/WCICA.2006.1714366},
art_number={1714366},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-34047199588&doi=10.1109%2fWCICA.2006.1714366&partnerID=40&md5=a6249683e50895d17b8cea8b21569bf7},
abstract={The operating system owns the standard abnormity interface, and the High-Performance processor has independent system Architectures. This paper explored the possibility to achieve the abnormity association of the operating system and the processor. The researcher designed the experimental method-Counterfeit Vectors (CV) on the basis of the two different systems. The Vectors Route Jump (VRJ) method was found in the experiment debugging. It directly pointed to the interface of operating system through abnormity vectors, thus improved the efficiency of the abnormity response. The two methods resolve the problem that the Non-Remap processor is not able to achieve abnormity association with the operating system. The abnormal response-time and the system efficiency achieve that of the Remap processor. © 2006 IEEE.},
author_keywords={Counterfeit vectors method;  REMAP;  The abnormity association;  The vectors route jump method},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Qiu2006572,
author={Qiu, M. and Jia, Z. and Xuc, C. and Shao, Z. and Liu, Y. and Sha, E.H.-M.},
title={Loop scheduling to minimize cost with data mining and prefetching for heterogeneous DSP},
journal={Proceedings of the IASTED International Conference on Parallel and Distributed Computing and Systems},
year={2006},
pages={572-577},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-38049165538&partnerID=40&md5=7da721a99fb4f1f38c5ab15f5e360d1e},
abstract={In real-time embedded systems, such as multimedia and video applications, cost and time are the most important issues and loop is the most critical part. Due to the uncertainties in execution time of some tasks, this paper models each varied execution time as a probabilistic random variable. We proposes a novel algorithm to minimize the total cost while satisfying the timing constraint with a guaranteed confidence probability. First, we use data mining to predict the distribution of execution time and find the association rules between execution time and different inputs from history table. Then we use rotation scheduling to obtain the best assignment for total cost minimization, which is called the HAP problem in this paper. Finally, we use prefetching to prepare data in advance at run time. Experiments demonstrate the effectiveness of our algorithm. Our approach can handle loops efficiently. In addition, it is suitable to both soft and hard real-time systems.},
author_keywords={Data mining;  Heterogeneous;  Prefetch;  Probability;  Scheduling},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Mooney2006229,
author={Mooney, C.H. and De Vries, D. and Roddick, J.F.},
title={A multi-level framework for the analysis of sequential data},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2006},
volume={3755 LNAI},
pages={229-243},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-37149049243&partnerID=40&md5=b236c280d498cdafd56553f4493c901c},
abstract={Traditionally text mining has had a strong link with information retrieval and classification and has largely aimed to classify documents according to embedded knowledge. Association rule mining and sequence mining, on the other hand, have had a different goal; one of eliciting relationships within or about the data being mined. Recently there has been research conducted using sequence mining techniques on digital document collections by treating the text as sequential data. In this paper we propose a multi-level framework that is applicable to text analysis and that improves the knowledge discovery process by finding additional or hitherto unknown relationships within the data being mined. We believe that this can lead to the detection or fine tuning of the context of documents under consideration and may lead to a more informed classification of those documents. Moreover, since we use a semantic map at varying stages in the framework, we are able to impose a greater degree of focus and therefore a greater transitivity of semantic relatedness that facilitates the improvement in the knowledge discovery process. © Springer-Verlag Berlin Heidelberg 2006.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Coenders2006237,
author={Coenders, J.},
title={Approximating complex shapes with intelligent structures: Embedded design intelligence in systems for the early phases of design},
journal={Journal of the International Association for Shell and Spatial Structures},
year={2006},
volume={47},
number={152},
pages={237-243},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847032572&partnerID=40&md5=7156ce0b1cec2219eef7017792700ee7},
abstract={In contemporary architecture and structural engineering a trend towards the increased use of advanced geometry and computation can be observed. This poses new challenges for the structural engineer, the designed structures and structural types, and the technology used to design, describe, model, calculate, engineer, communicate, produce and assemble these structures. System concepts, like parametric associative design, can be used to capture the design intelligence in parameters, associations, rules, objects (features) and programmatic components [1]. Although these technologies have many features for the modelling the geometrical representation of a structure, buildings consist of more than only geometry and generation. For free-form structures, surfaces should be meshed, tessellated or populated to impose a grid-based structure consisting of these parametric elements. However, not all restrictions of the structural design can be expressed in a single surface model of the intended design, since often the structure imposes restrictions in the form of angles, lengths, stresses, etc. Therefore, surface population is often not the appropriate technique for defining a structure. This paper presents a computational method to model a geometrical and structural representation with embedded design intelligence in the form of simple rules, constraints and the generation process. With the presented method a designed shape can be automatically approximated in order to allow the architect and the engineer to quickly apply and test a typical structure (for instance a space frame or a beam-column-structure) on the designed shape in the early phases of the design, while taking into account restrictions from various aspects, such as the load bearing behaviour, production aspects, etc. Proper structural design and fine-tuning of the design still has to take place by the designers, but this tool allows quick tests and indicative exploration during the first conversations of the design. A prototype implementation has been created in a new parametric associative system, GenerativeComponents [1], by programming components in the C# programming language.},
author_keywords={Computation;  Computational design;  Embedded design intelligence;  Geometry;  Modelling;  Parametric associative design},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Eapen2006122,
author={Eapen, A.G. and Ponnambalam, K. and Arocha, J.F. and Shioda, R. and Smith, T.F. and Poss, J. and Hirdes, J.},
title={Data mining in mental health},
journal={Proceedings of the IASTED International Conference on Modelling and Simulation},
year={2006},
volume={2006},
pages={122-127},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33751238137&partnerID=40&md5=0f563a9def9da5e6b1335929b8906d42},
abstract={Data mining is the process of automatic classification of cases based on data patterns obtained from a dataset. A number of algorithms have been developed and implemented to extract information and discover knowledge patterns that may be useful for decision support. Once these patterns are extracted they can be used for automatic classification of case mixes. Although research has been conducted using diverse algorithms on small datasets (of about ten to fifteen attributes), in this paper, for the first time, we make use of a large database, namely, the interRAI Minimum Data Set for Mental Health (MDS-MH) containing over 455 attributes. Several data mining algorithms were used to classify clinical cases using MDS-MH data. The algorithms included Bayes methods, association rules, decision trees, and clustering. We compare these algorithms in various classification tasks and identify advantages and disadvantages of each algorithm with respect to their accuracy and use.},
author_keywords={Case mix;  Classification;  Clustering;  Data mining;  Decision assist;  Mental health},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Yoo20061323,
author={Yoo, J.S. and Shekhar, S.},
title={A joinless approach for mining spatial colocation patterns},
journal={IEEE Transactions on Knowledge and Data Engineering},
year={2006},
volume={18},
number={10},
pages={1323-1337},
doi={10.1109/TKDE.2006.150},
art_number={1683769},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748365438&doi=10.1109%2fTKDE.2006.150&partnerID=40&md5=6f22862fc7ba970a3aaf8270e4301ec8},
abstract={Spatial colocations represent the subsets of features which are frequently located together in geographic space. Colocation pattern discovery presents challenges since spatial objects are embedded in a continuous space, whereas classical data is often discrete. A large fraction of the computation time is devoted to identifying the instances of colocation patterns. We propose a novel joinless approach for efficient colocation pattern mining. The joinless colocation mining algorithm uses an instance-lookup scheme instead of an expensive spatial or instance join operation for identifying colocation instances. We prove the joinless algorithm is correct and complete in finding colocation rules. We also describe a partial join approach for spatial data which are clustered in neighborhood areas. We provide the algebraic cost models to characterize the performance dominance zones of the joinless method and the partial join method with a current join-based colocation mining method, and compare their computational complexities. In the experimental evaluation, using synthetic and real-world data sets, our methods performed more efficiently than the join-based method and show more scalability in dense data. © 2006 IEEE.},
author_keywords={Association rule;  Relocation pattern;  Spatial data mining;  Spatial neighbor relationship},
document_type={Article},
source={Scopus},
}

@ARTICLE{Rahal200657,
author={Rahal, I. and Ren, D. and Wu, W. and Denton, A. and Besemann, C. and Perrizo, W.},
title={Exploiting edge semantics in citation graphs using efficient, vertical ARM},
journal={Knowledge and Information Systems},
year={2006},
volume={10},
number={1},
pages={57-91},
doi={10.1007/s10115-005-0229-2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745941139&doi=10.1007%2fs10115-005-0229-2&partnerID=40&md5=8a59db0fa50e7ef008340e9669f327eb},
abstract={Graphs are increasingly becoming a vital source of information within which a great deal of semantics is embedded. As the size of available graphs increases, our ability to arrive at the embedded semantics grows into a much more complicated task. One form of important hidden semantics is that which is embedded in the edges of directed graphs. Citation graphs serve as a good example in this context. This paper attempts to understand temporal aspects in publication trends through citation graphs, by identifying patterns in the subject matters of scientific publications using an efficient, vertical association rule mining model. Such patterns can (a) indicate subject-matter evolutionary history, (b) highlight subject-matter future extensions, and (c) give insights on the potential effects of current research on future research. We highlight our major differences with previous work in the areas of graph mining, citation mining, and Web-structure mining, propose an efficient vertical data representation model, introduce a new subjective interestingness measure for evaluating patterns with a special focus on those patterns that signify strong associations between properties of cited papers and citing papers, and present an efficient algorithm for the purpose of discovering rules of interest followed by a detailed experimental analysis. © Springer-Verlag London Limited 2006.},
author_keywords={Association rule mining;  Citation analysis;  Citation graphs;  Data mining;  Frequent itemset mining;  Graph databases;  Link analysis;  P-trees},
document_type={Article},
source={Scopus},
}

@ARTICLE{Lin2006193,
author={Lin, C.-J. and Xu, Y.-J.},
title={A novel evolution learning for recurrent wavelet-based neuro-fuzzy networks},
journal={Soft Computing},
year={2006},
volume={10},
number={3},
pages={193-205},
doi={10.1007/s00500-004-0455-7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-29444435032&doi=10.1007%2fs00500-004-0455-7&partnerID=40&md5=a333c6952d3289b0f8629e7ef64f8b04},
abstract={This study presents a recurrent wavelet-based neuro-fuzzy network with dynamic symbiotic evolution (RWNFN-DSE) for dynamic system processing. The proposed RWNFN-DSE model combines the traditional Takagi-Sugeno-Kang (TSK) fuzzy model and the wavelet neural networks (WNN). This study adopts the non-orthogonal and compactly supported functions as wavelet neural network bases. Temporal relations embedded in the network are caused by adding some feedback connections representing the memory units into the second layer. A novel evolution learning called dynamic symbiotic evolution (DSE) is used to tune the parameter of the RWNFN-DSE model. The better chromosomes will be initially generated while the better mutation points will be determined for performing dynamic-mutation. Simulation results have shown that the proposed RWNFN-DSE model obtain better performance than other existing models. © Springer-Verlag Berlin Heidelberg 2005.},
author_keywords={Control;  Genetic algorithms;  Identification;  Neuro-fuzzy;  Symbiotic evolution},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kim2006751,
author={Kim, H.-K.},
title={Intelligent frameworks for encoding XML elements using mining algorithm},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2006},
volume={4252 LNAI - II},
pages={751-759},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750687947&partnerID=40&md5=ad135f257236df924f36d5ef22fdadcc},
abstract={Mining of association rules is to find associations among data items that appear together in some transactions or business activities. As of today, algorithms for association rule mining, as well as for other data mining tasks, are mostly applied to relational databases. As XML being adopted as the universal format for data storage and exchange, mining associations from XML data becomes an area of attention for researchers and developers. The challenge is that the semi-structured data format in XML is not directly suitable for traditional data mining algorithms and tools. In this paper we present an intelligent encoding method to encode XML tree-nodes. This method is used to store the XML data in 2-dimensional tables that can be easily accessed via indexing using knowledge. The hierarchical relationship in the original XML tree structure is embedded in the encoding. We applied this method in some applications, such as mining of association rules. © Springer-Verlag Berlin Heidelberg 2006.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2006,
title={Computational Science and Its Applications - ICCSA 2006: International Conference, Proceedings},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2006},
volume={3982 LNCS},
page_count={5877},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941152060&partnerID=40&md5=ea456c1f7b252a30b5e7e2f775a1e2d5},
abstract={The proceedings contain 621 papers. The topics discussed include: upper bound on dilation of triangulations of cyclic polygons; visibility maps of segments and triangles in 3D; backward error analysis in computational geometry; fast intersections for subdivision surfaces; efficient algorithm for the extraction of association rules in data mining; a robust digital fingerprinting mechanism for digital copyright protection; an application-independent multimedia adaptation framework for the mobile web; effort predu\iction model using similarity for embedded software development; a CGM algorithm solving the longest increasing subsequence problem; computer-assisted source-code parallelization; a template language for agent construction; an ontology-based context model in smart home; service mobility manager for OSGi framework; a security requirement management database based on ISO/IEC 15408; and applying product line to the embedded systems.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2006,
title={Computational Science and Its Applications - ICCSA 2006: International Conference, Proceedings},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2006},
volume={3981 LNCS},
page_count={5877},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941154543&partnerID=40&md5=f67741efc536d37512231baf10355cb3},
abstract={The proceedings contain 621 papers. The topics discussed include: upper bound on dilation of triangulations of cyclic polygons; visibility maps of segments and triangles in 3D; backward error analysis in computational geometry; fast intersections for subdivision surfaces; efficient algorithm for the extraction of association rules in data mining; a robust digital fingerprinting mechanism for digital copyright protection; an application-independent multimedia adaptation framework for the mobile web; effort predu\iction model using similarity for embedded software development; a CGM algorithm solving the longest increasing subsequence problem; computer-assisted source-code parallelization; a template language for agent construction; an ontology-based context model in smart home; service mobility manager for OSGi framework; a security requirement management database based on ISO/IEC 15408; and applying product line to the embedded systems.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2006,
title={Computational Science and Its Application - ICCSA 2006: International Conference, Proceedings},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2006},
volume={3983 LNCS},
page_count={5877},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941159533&partnerID=40&md5=5e75430fd3897ecd55d20a88c0b92da0},
abstract={The proceedings contain 621 papers. The topics discussed include: upper bound on dilation of triangulations of cyclic polygons; visibility maps of segments and triangles in 3D; backward error analysis in computational geometry; fast intersections for subdivision surfaces; efficient algorithm for the extraction of association rules in data mining; a robust digital fingerprinting mechanism for digital copyright protection; an application-independent multimedia adaptation framework for the mobile web; effort predu\iction model using similarity for embedded software development; a CGM algorithm solving the longest increasing subsequence problem; computer-assisted source-code parallelization; a template language for agent construction; an ontology-based context model in smart home; service mobility manager for OSGi framework; a security requirement management database based on ISO/IEC 15408; and applying product line to the embedded systems.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2006,
title={Computational Science and Its Applications - ICCSA 2006: International Conference, Proceedings},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2006},
volume={3980 LNCS},
page_count={5877},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941150035&partnerID=40&md5=4bf706e4a5e8a4b2ca52b95d80aaf197},
abstract={The proceedings contain 621 papers. The topics discussed include: upper bound on dilation of triangulations of cyclic polygons; visibility maps of segments and triangles in 3D; backward error analysis in computational geometry; fast intersections for subdivision surfaces; efficient algorithm for the extraction of association rules in data mining; a robust digital fingerprinting mechanism for digital copyright protection; an application-independent multimedia adaptation framework for the mobile web; effort predu\iction model using similarity for embedded software development; a CGM algorithm solving the longest increasing subsequence problem; computer-assisted source-code parallelization; a template language for agent construction; an ontology-based context model in smart home; service mobility manager for OSGi framework; a security requirement management database based on ISO/IEC 15408; and applying product line to the embedded systems.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2006,
title={Computational Science and Its Applications - ICCSA 2006: International Conference, Proceedings},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2006},
volume={3984 LNCS},
page_count={5877},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941160623&partnerID=40&md5=e8a0563e85047115ad611dd58a5f8fc1},
abstract={The proceedings contain 621 papers. The topics discussed include: upper bound on dilation of triangulations of cyclic polygons; visibility maps of segments and triangles in 3D; backward error analysis in computational geometry; fast intersections for subdivision surfaces; efficient algorithm for the extraction of association rules in data mining; a robust digital fingerprinting mechanism for digital copyright protection; an application-independent multimedia adaptation framework for the mobile web; effort predu\iction model using similarity for embedded software development; a CGM algorithm solving the longest increasing subsequence problem; computer-assisted source-code parallelization; a template language for agent construction; an ontology-based context model in smart home; service mobility manager for OSGi framework; a security requirement management database based on ISO/IEC 15408; and applying product line to the embedded systems.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Hébert2006238,
author={Hébert, C. and Crémilleux, B.},
title={Optimized rule mining through a unified framework for interestingness measures},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2006},
volume={4081 LNCS},
pages={238-247},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33751354748&partnerID=40&md5=cfda329ed69dbe468486743545307576},
abstract={The large amount of association rules resulting from a KDD process makes the exploitation of the patterns embedded in the database difficult even impossible. In order to address this problem, various interestingness measures were proposed for selecting the most relevant rules. Nevertheless, the choice of an appropriate measure remains a hard task and the use of several measures may lead to conflicting information. In this paper, we propose a unified framework for a set of interestingness measures M and prove that most of the usual objective measures behave in a similar way. In the context of classification rules, we show that each measure of M admits a lower bound on condition that a minimal frequency threshold and a maximal number of exceptions are considered. Furthermore, our framework enables to characterize the whole collection of the rules simultaneously optimizing all the measures of M. We finally provide a method to mine a rule cover of this collection. © Springer-Verlag Berlin Heidelberg 2006.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lin2006747,
author={Lin, C. and Lee, C. and Chin, C.},
title={Dynamic recurrent wavelet network controllers for nonlinear system control},
journal={Journal of the Chinese Institute of Engineers, Transactions of the Chinese Institute of Engineers,Series A/Chung-kuo Kung Ch'eng Hsuch K'an},
year={2006},
volume={29},
number={4},
pages={747-751},
doi={10.1080/02533839.2006.9671171},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746877095&doi=10.1080%2f02533839.2006.9671171&partnerID=40&md5=aa6f36640d300c094b27f52ce05b1ede},
abstract={To solve nonlinear system control problems, a Recurrent Wavelet Network Controller (RWNC) is proposed in this paper. The proposed RWNC model has four-layer structure. Temporal relations embedded in the network by adding some feedback connections representing the memory units in the second layer. A self-organizing learning algorithm, which consists of structure learning and parameter learning, is proposed and is able to construct the recurrent wavelet network dynamically. The structure learning is based on the input partitions to determine the number of wavelet bases, and the parameter learning is based on the supervised gradient descent method to adjust the shape of wavelet functions, feedback weights, and the connection weights. Computer simulations were conducted to illustrate the performance and applicability of the proposed model. © 2006, Taylor & Francis Group, LLC.},
author_keywords={Control;  Degree measure;  Recurrent networks;  Self-organizing learning;  Wavelet bases},
document_type={Article},
source={Scopus},
}

@ARTICLE{Park2006423,
author={Park, H. and Kim, J.},
title={Design and implementation of a high-speed RFID data filtering engine},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2006},
volume={4097 LNCS},
pages={423-434},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749381633&partnerID=40&md5=c8c64da4452b77e0c5efb186839bc429},
abstract={In this paper, we present a high-speed RFID data filtering engine designed to carry out filtering under the conditions of massive data and massive filters. We discovered that the high-speed RFID data filtering technique is very similar to the high-speed packet classification technique which is used in high-speed routers and firewall systems. Actually, our filtering engine is designed based on existing packet classification algorithms, Bit-Parallelism and Aggregated Bit Vector (ABV). In addition, we also discovered that there are strong temporal relations and redundancy in the RFID data filtering operations. We incorporated two kinds of caches, tag and filter caches, to make use of this characteristic to improve the efficiency of the filtering engine. The performance of the proposed engine has been examined by implementing a prototype system and testing it. Compared to the basic sequential filter comparison approach, our engine shows much better performance, and it gets better as the number of filters increases. © IFIP International Federation for Information Processing 2006.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Pham2005354,
author={Pham, S.B. and Hoffmann, A.},
title={Incremental knowledge acquisition for extracting temporal relations},
journal={Proceedings of 2005 IEEE International Conference on Natural Language Processing and Knowledge Engineering, IEEE NLP-KE'05},
year={2005},
volume={2005},
pages={354-359},
doi={10.1109/NLPKE.2005.1598761},
art_number={1598761},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847289257&doi=10.1109%2fNLPKE.2005.1598761&partnerID=40&md5=e455165b6b015f10315ba43a1f89a57a},
abstract={We present KAFTIE - an incremental knowledge acquisition framework which utilizes expert knowledge to build high quality knowledge base annotators. Using KAFTIE, a knowledge base was built based on a small data set that outperforms machine learning algorithms trained on a much bigger data set for the task of recognizing temporal relations. In particular, this can be incorporated to bootstrap the process of labeling data for domains where annotated data is not available. © 2005 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Verma2005651,
author={Verma, K. and Vyas, O.P. and Vyas, R.},
title={Temporal approach to association rule mining using T-tree and P-tree},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2005},
volume={3587 LNAI},
pages={651-659},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-26944446908&partnerID=40&md5=50caf23a4a63eca050a24fdc7f4e53f9},
abstract={The real transactional databases often exhibit temporal characteristic and time varying behavior. Temporal association rule has thus become an active area of research. A calendar unit such as months and days, clock units such as hours and seconds and specialized units such us business days and academic years, play a major role in a wide range of information system applications. The calendar-based pattern has already been proposed by researchers to restrict the time-based associationships. This paper proposes a novel algorithm to find association rule on time dependent data using efficient T-tree and P-tree data structures. The algorithm elaborates the significant advantage in terms of time and memory while incorporating time dimension. Our approach of scanning based on time-intervals yields smaller dataset for a given valid interval thus reducing the processing time. This approach is implemented on a synthetic dataset and result shows that temporal TFP tree gives better performance over a TFP tree approach. © Springer-Verlag Berlin Heidelberg 2005.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Shen20051159,
author={Shen, J.-J. and Hsu, P.-W.},
title={Watermarking with association rules alignment},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2005},
volume={3682 LNAI},
pages={1159-1167},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745296564&partnerID=40&md5=5ff1a8985e11a6b6dde8aab273cbffdc},
abstract={A new watermarking technique called associative watermarking is proposed in this paper. The watermark in our new scheme will be embedded by applying the concept of association rules borrowed from the field of data mining. We implant the watermark's rules into the original image by changing a very small portion of the image's pixels during the rules alignment process. As a result, the robustness can be enhanced by emphasizing the specific rules mined from critical areas in the original image. Instead of transforming the watermark into its bit pattern, we just mine the association rules from the watermark and embed them into a colorful image. Our experimental results reveal that the PSNR value of the image after watermark implanting exceeds 40, and more than 90% of the watermarked images can be accurately recognized after similarity checking. © Springer-Verlag Berlin Heidelberg 2005.},
author_keywords={Association rule;  Digital Watermarking;  Image;  Similarity},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Buono2005221,
author={Buono, P. and Costabile, M.F.},
title={Visualizing association rules in a framework for visual data mining},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2005},
volume={3379 LNCS},
pages={221-231},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-36849076724&partnerID=40&md5=0c0afa00b528fdd4f2f51be26218ee66},
abstract={The abundance of data available nowadays fosters the need of developing tools and methodologies to help users in extracting significant information. Visual data mining is going in this direction, exploiting data mining algorithms and methodologies together with information visualization techniques. The demand for visual and interactive analysis tools is particularly pressing in the Association Rules context where often the user has to analyze hundreds of rules in order to grasp valuable knowledge. In this paper, we present a visual strategy that exploits a graph-based technique and parallel coordinates to visualize the results of association rule mining algorithms. This helps data miners to get an overview of the rule set they are interacting with and enables them to deeper investigate inside a specific set of rules. The tools developed are embedded in a framework for Visual Data Mining that is briefly described. © Springer-Verlag Berlin Heidelberg 2005.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Mori20051833,
author={Mori, T. and Takada, A. and Noguchi, H. and Harada, T. and Sato, T.},
title={Behavior prediction based on daily-life record database in distributed sensing space},
journal={2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS},
year={2005},
pages={1833-1839},
doi={10.1109/IROS.2005.1545244},
art_number={1545244},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957983215&doi=10.1109%2fIROS.2005.1545244&partnerID=40&md5=612ab9324f36420685387f3e4b6c476d},
abstract={This paper proposes a behavior prediction system for supporting our daily lives. The behaviors in daily-life are recorded in an environment with embedded sensors, and the prediction system learns the characteristic patterns that would be followed by the behaviors to be predicted. In this research, the authors applied a method of discovering time-series association rules, which discovers frequent combinations of events called episodes. The prediction system observes behaviors with the sensors and outputs the prediction of the future behaviors based on the rules. © 2005 IEEE.},
author_keywords={Daily behavior database;  Human monitoring;  Knowledge discovery;  Ubiquitous sensing},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Napoli2005913,
author={Napoli, A.},
title={A Smooth Introduction to Symbolic Methods for Knowledge Discovery},
journal={Handbook of Categorization in Cognitive Science},
year={2005},
pages={913-933},
doi={10.1016/B978-008044612-7/50096-2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-41549162642&doi=10.1016%2fB978-008044612-7%2f50096-2&partnerID=40&md5=f23ae09767c258ebe0a981497eb5c998},
abstract={The purpose of this chapter is to present a smooth introduction to symbolic methods for Knowledge Discovery in Databases (KDD). The KDD process extracts from large databases information units that can be interpreted as knowledge units to be reused. This process has three major steps: the selection and preparation of data, the data mining operation, and finally the interpretation of the extracted units. The process may take advantage of domain knowledge embedded in domain ontologies, which may be used at every step of the KDD process. The three symbolic methods for KDD are: lattice-based classification, frequent item set search, and association rule extraction. The KDD process is iterative and interactive, and is controlled by an analyst, who is in charge of guiding and validating the extraction process. The chapter focuses primarily on symbolic methods, and especially on lattice-based classification, level-wise search for frequent item sets, and association rule extraction. These methods are operational and can provide good results in real-world problems. The three kinds of applications that are discussed in the chapter are: an experiment on the mining of chemical reaction databases, an experiment on the mining of gene expression databases, and finally, web mining, which is an increasingly important research field. © 2005 Elsevier Ltd.},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Kavka20051385,
author={Kavka, C. and Roggero, P. and Schoenauer, M.},
title={Evolution of voronoi based fuzzy recurrent controllers},
journal={GECCO 2005 - Genetic and Evolutionary Computation Conference},
year={2005},
pages={1385-1392},
doi={10.1145/1068009.1068231},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-32444441359&doi=10.1145%2f1068009.1068231&partnerID=40&md5=5f2aea93ce93602f1824ce7243f6d11f},
abstract={A fuzzy controller is usually designed by formulating the knowledge of a human expert into a set of linguistic variables and fuzzy rules. Among the most successful methods to automate the fuzzy controllers development process are evolutionary algorithms. In this work, we propose the Recurrent Fuzzy Voronoi (RFV) model, a representation for recurrent fuzzy systems. It is an extension of the FV model proposed by Kavka and Schoenauer that extends the application domain to include temporal problems. The FV model is a representation for fuzzy controllers based on Voronoi diagrams that can represent fuzzy systems with synergistic rules, fulfilling the ε-completeness property and providing a simple way to introduce a priory knowledge. In the proposed representation, the temporal relations are embedded by including internal units that provide feedback by connecting outputs to inputs. These internal units act as memory elements. In the RFV model, the semantic of the internal units can be specified together with the a priori rules. The geometric interpretation of the rules allows the use of geometric variational operators during the evolution. The representation and the algorithms are validated in two problems in the area of system identification and evolutionary robotics. Copyright 2005 ACM.},
author_keywords={Evolutionary robotics;  Fuzzy control;  Genetic algorithms;  Recurrent fuzzy systems;  Voronoi diagrams},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Jiang2005773,
author={Jiang, J.-Y. and Lee, W.-J. and Lee, S.-J.},
title={Mining calendar-based asynchronous periodical association rules with fuzzy calendar constraints},
journal={IEEE International Conference on Fuzzy Systems},
year={2005},
pages={773-778},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-23944506350&partnerID=40&md5=daf76fba3f0fb8be9964d3d6843ebd88},
abstract={We propose a new representation of calendars such that users can specify fuzzy calendar constraints to discover asynchronous periodical association rules embedded in temporal databases. We borrow the fuzzy set theory and use the conjunction operation to construct fuzzy calendar patterns and each fuzzy calendar pattern represents an asynchronous periodical behavior. Moreover, different time intervals have different weights corresponding to their matching degrees to the specified fuzzy calendar pattern. An efficient algorithm is also proposed to find association rules with the specified fuzzy calendar pattern. Unlike levelwise Apriori-based approaches, our method scans the underlying database at most twice. In the first scan, frequent 2-itemsets with their weighted counts in the specified fuzzy calendar pattern are obtained and then all candidate itemsets are generated from the discovered frequent 2-itemsets. Finally, all frequent itemsets with their weighted counts in the specified fuzzy calendar pattern are discovered in one shot. Asynchronous periodical association rules in the specified fuzzy calendar pattern are then obtained. © 2005 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Jessop2005225,
author={Jessop, B.},
title={The political economy of scale and European governance},
journal={Tijdschrift voor Economische en Sociale Geografie},
year={2005},
volume={96},
number={2},
pages={225-230},
doi={10.1111/j.1467-9663.2005.00453.x},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-18844434714&doi=10.1111%2fj.1467-9663.2005.00453.x&partnerID=40&md5=aa9daa98042b8e561785cd912502780c},
abstract={This paper introduces some concepts for analysing scalar aspects of governance, governance failure, and meta-governance. There is now a significant corpus of work on multi-level governance in the European Union as well as an enormous literature on various modes of governance. Although the problem of scale is often posed directly for the EU case (notably in terms of the 'multi-level' character of its political regime), scalar issues are also important for all forms of governance. For effective governance must take account of the specific spatio-temporalities of its objects and mechanisms as well as the spatio-temporal location and horizons of action of the subjects involved in its exercise. In particular, among their other relational properties, the objects of governance are more or less embedded in space, place, and scale and linked to distinctive temporal relations and emergent temporalities. This indicates the relevance of a strategic-relational concern with space, place and scale, with spatial, local and scalar imaginaries, and with attempts to secure spatio-temporal fixes to facilitate the reproduction of objects of governance. Given space constraints, I focus here on two sets of issues: (i) theoretically, the role of scale, scalar divisions of labour, the relativisation of scale, and multi-scalar governance; and (ii) substantively, the now paradigmatic case of the European Union as a novel form of multi-scalar meta-governance. © 2005 by the Royal Dutch Geographical Society KNAG.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Tsironis2005237,
author={Tsironis, L. and Bilalis, N. and Moustakis, V.},
title={Using machine learning to support quality management: Framework and experimental investigation},
journal={TQM Magazine},
year={2005},
volume={17},
number={3},
pages={237-248},
doi={10.1108/09544780510594207},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-18244386945&doi=10.1108%2f09544780510594207&partnerID=40&md5=5c9e4011e411ceb05f9064688104c843},
abstract={Purpose - To demonstrate the applicability of machine-learning tools in quality management. Design/methodology/approach - Two popular machine-learning approaches, decision tree induction and association rules mining, were applied on a set of 960 production case records. The accuracy of results was investigated using randomized experimentation and comprehensibility of rules was assessed by experts in the field. Findings - Both machine-learning approaches exhibited very good accuracy of results (average error was about 9 percent); however, association rules mining outperformed decision tree induction in comprehensibility and correctness of learned rules. Research limitations/implications - The proposed methodology is limited with respect to case representation. Production cases are described via attribute-value sets and the relation between attribute values cannot be determined by the selected machine-learning methods. Practical implications - Results demonstrate that machine-learning techniques may be effectively used to enhance quality management procedures and modeling of cause-effect relationships, associated with faulty products. Originality/value - The article proposes a general methodology on how to use machine-learning techniques to support quality management. The application of the technique in ISDN modem manufacturing demonstrates the effectiveness of the proposed general methodology. © Emerald Group Publishing Limited.},
author_keywords={Decision trees;  Manufacturing systems;  Modems;  Quality management},
document_type={Article},
source={Scopus},
}

@ARTICLE{NoAuthor2005,
title={IFIP TCI2 WG12.5 2nd IFIP Conference on Artificial Intelligence Applications and Innovations, AIAI 2005},
journal={IFIP Advances in Information and Communication Technology},
year={2005},
volume={187},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902993827&partnerID=40&md5=1f01f13d5481d141ed3c925def2daa3d},
abstract={The proceedings contain 94 papers. The special focus in this conference is on Artificial Intelligence. The topics include: A fuzzy system for multiobjective problems; aero-engine adaptive fuzzy decoupling control; dynamic-fuzzy concepts; a hybrid connectionist-symbolic approach for real-valued pattern classification; designing fuzzy logic controller for inverted pendulum; learning search pattern for construction procurement using keyword net; stratified sampling for association rules mining; the incompatible knowledge elimination in knowledge-integration; designing cooperative embedded systems using a multiagent approach; a flexible agent-based simulation framework for complex adaptive systems; implementation of an application ontology; translating ontologies to default logic; fuzzy timed object-oriented Petri net; soft modeling of knowledge systems through fuzzy Petri nets; an improved 3D face synthesis based on morphable model; local linear embedding with morphable model for face recognition; a kind of continuous digit speech recognition method; a new hybrid HMM/ANN model for speech recognition; an intelligent retrieval framework in semantic web based on agents; a hybrid method for extracting classification rules; an algorithm for MADM based on subjective preference; an algorithm for mining association rules with weighted minimum supports; decision making with uncertainty; design and implement cost-sensitive email filtering algorithms; improving the particle swarm optimization algorithm using the simplex method at late stage; reconstruction of freeform surface by support vector regression; an operator based adaptive genetic algorithm; solving network testbed mapping problem with genetic algorithm; a study on the ANN-based credit risk prediction model and its application; an novel neural network training based on hybrid DE and BP; forecasting runoff with higher-embedded dimensions using DMEP-based artificial neural networks; rotating machinery fault diagnosis based on wavelet fuzzy neural network; a rough sets based evaluation model for BOT projects bidders; a dynamic constraint solving scheme for semi on-line scheduling problems; a web-based intelligent tutoring system; an expert system for deficit irrigation in the north China region based on PDA; automatic guidance of agricultural vehicles based on global positioning system; development of an expert system for landfilling applications in Sri Lanka; development of an intelligent adapter for field computer; fuzzy relationship mapping inversion and automatic reasoning of crime detective; leaf mage retrieval using a shape based method; research on prediction about fruit tree diseases and insect pests based on neural network; research on wheat diseases and insect pests geographic information system; solution of MDPS using simulation-based value iteration; study on applications of web mining to digital library; study on knowledge reasoning based on extended formulas; study on web-based agricultural mechanization decision support system; ICT supported knowledge transfer for agricultural extension; study and application of softman communication model; the adaptive web server based on ant behavior and the validities of pep and some characteristic formulas in modal logic.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Lin2005226,
author={Lin, C.-J. and Chin, C.-C.},
title={Recurrent wavelet-based neuro fuzzy networks for dynamic system identification},
journal={Mathematical and Computer Modelling},
year={2005},
volume={41},
number={2-3},
pages={226-239},
doi={10.1016/j.mcm.2004.05.004},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-19744374545&doi=10.1016%2fj.mcm.2004.05.004&partnerID=40&md5=1c416350ac05ff5202f03f8f747dfced},
abstract={A recurrent wavelet-based neuro fuzzy network (RWNFN) is proposed in this paper. The proposed RWNFN integrates wavelet transforms with fuzzy rules. Temporal relations are embedded in the network by adding feedback connections from memory units in the third layer of a feedforward wavelet-based neuro fuzzy network (WNFN). The RWNFN augments the basic ability of the WNFN to overcome temporal problems. Moreover, an online learning algorithm is proposed to automatically construct the RWNFN. Computer simulations were conducted to illustrate the performance and applicability of the proposed system. © 2005 Elsevier Ltd. All rights reserved.},
author_keywords={Recurrent network;  TSK-type fuzzy model;  Wavelet neural networks},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Li2004391,
author={Li, Y. and Gopalan, R.P.},
title={Effective sampling for mining association rules},
journal={Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
year={2004},
volume={3339},
pages={391-401},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-22944457185&partnerID=40&md5=bdb471199473589d1107828db9c575ee},
abstract={As discovering association rules in a very large database is time consuming, researchers have developed many algorithms to improve the efficiency. Sampling can significantly reduce the cost of mining, since the mining algorithms need to deal with only a small dataset compared to the original database. Especially, if data comes as a stream flowing at a faster rate than can be processed, sampling seems to be the only choice. How to sample the data and how big the sample size should be for a given error bound and confidence level are key issues for particular data mining tasks. In this paper, we derive the sufficient sample size based on central limit theorem for sampling large datasets with replacement. This approach requires smaller sample size than that based on the Chernoff bounds and is effective for association rules mining. The effectiveness of the method has been evaluated on both dense and sparse datasets. © Springer-Verlag Berlin Heidelberg 2004.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tsai2004685,
author={Tsai, P.S.M. and Chen, C.-M.},
title={Mining interesting association rules from customer databases and transaction databases},
journal={Information Systems},
year={2004},
volume={29},
number={8},
pages={685-696},
doi={10.1016/S0306-4379(03)00061-9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-3343008958&doi=10.1016%2fS0306-4379%2803%2900061-9&partnerID=40&md5=a77ee069cc7df63b5e9c16cf5ad9a49f},
abstract={In this paper, we examine a new data mining issue of mining association rules from customer databases and transaction databases. The problem is decomposed into two subproblems: identifying all the large itemsets from the transaction database and mining association rules from the customer database and the large itemsets identified. For the first subproblem, we propose an efficient algorithm to discover all the large itemsets from the transaction database. Experimental results show that by our approach, the total execution time can be reduced significantly. For the second subproblem, a relationship graph is constructed according to the identified large itemsets from the transaction database and the priorities of condition attributes from the customer database. Based on the relationship graph, we present an efficient graph-based algorithm to discover interesting association rules embedded in the transaction database and the customer database. © 2003 Elsevier Ltd. All rights reserved.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Huang20041472,
author={Huang, Y. and Shekhar, S. and Xiong, H.},
title={Discovering colocation patterns from spatial data sets: A general approach},
journal={IEEE Transactions on Knowledge and Data Engineering},
year={2004},
volume={16},
number={12},
pages={1472-1485},
doi={10.1109/TKDE.2004.90},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-10944243785&doi=10.1109%2fTKDE.2004.90&partnerID=40&md5=d2075d2e83fd2e5051e46f6f1ee93bef},
abstract={Given a collection of Boolean spatial features, the colocation pattern discovery process finds the subsets of features frequently located together. For example, the analysis of an ecology data set may reveal symbiotic species. The spatial colocation rule problem is different from the association rule problem since there is no natural notion of transactions in spatial data sets which are embedded in continuous geographic space. In this paper, we provide a transaction-free approach to mine colocation patterns by using the concept of proximity neighborhood. A new interest measure, a participation index, is also proposed for spatial colocation patterns. The participation index is used as the measure of prevalence of a colocation for two reasons. First, this measure is closely related to the cross-K function, which is often used as a statistical measure of interaction among pairs of spatial features. Second, it also possesses an antimonotone property which can be exploited for computational efficiency. Furthermore, we design an algorithm to discover colocation patterns. This algorithm includes a novel multiresolution pruning technique. Finally, experimental results are provided to show the strength of the algorithm and design decisions related to performance tuning.},
author_keywords={Colocation patterns;  Participation index;  Spatial association rules},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Lee200490,
author={Lee, W.-J. and Lee, S.-J.},
title={An incremental algorithm for discovering fuzzy temporal Web usage patterns},
journal={Proceedings of the International Conference on Internet Computing, IC'04},
year={2004},
volume={1},
pages={90-96},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-12744280595&partnerID=40&md5=dbbb9422d9767f70cafc41eadb320f1b},
abstract={In this paper, we are interested in discovering from web access data temporal web usage patterns in terms of fuzzy temporal association rules. Fuzzy temporal association rules can describe periodical and seasonal web browsing behaviors of the clients and help develop effective seasonal marketing strategies and give an indication to organize web space efficiently in different time periods. We propose a mining system based on an incremental mining algorithm, called Border-Filtering, to deal with the on-line collection of usage data on the web. With the aid of the fuzzy calendric algebra, knowledge embedded in the clickstream data can be efficiently discovered. By keeping knowledge of the original database in a border, the work for counting those candidates which are generated in an incoming database but also exist in the border over the old database can be saved. The minimal border can be easily derived. Moreover, the smallest set of candidate itemsets can be computed in an efficient way, and the unnecessary scans over the database with the candidate itemsets are saved. Simulation results have shown that our system runs faster than other incremental mining techniques, especially when there are a small number of new frequent itemsets in the updated database.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Au2004239,
author={Au, W.-H. and Chan, K.C.C.},
title={Mining fuzzy rules for time series classification},
journal={IEEE International Conference on Fuzzy Systems},
year={2004},
volume={1},
pages={239-244},
doi={10.1109/FUZZY.2004.1375726},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-11144340959&doi=10.1109%2fFUZZY.2004.1375726&partnerID=40&md5=c21bbcb85065090f57140be1bec820cc},
abstract={Time series classification is concerned about discovering classification models in a database of pre-classified time series and using them to classify unseen time series. To better handle the noises and fuzziness in time series data, we propose a new data mining technique to mine fuzzy rules in the data. The fuzzy rules discovered employ fuzzy sets to represent the revealed regularities and exceptions. The resilience of fuzzy sets to noises allows the proposed approach to better handle the noises embedded in the data. Furthermore, it uses the adjusted residual as an objective measure to evaluate the interestingness of association relationships hidden in the data. The adjusted residual analysis allows the differentiation of interesting relationships from uninteresting ones without any user-specified thresholds. To evaluate the performance of the proposed approach, we applied it to several well-known time series datasets. The experimental results showed that our approach is very promising.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Malerba200495,
author={Malerba, D. and Appice, A. and Ceci, M.},
title={A data mining query language for knowledge discovery in a geographical information system},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2004},
volume={2682},
pages={95-116},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-35048829759&partnerID=40&md5=dc7725d0d495f8dec633094f29256079},
abstract={Spatial data mining is a process used to discover interesting but not explicitly available, highly usable patterns embedded in both spatial and non-spatial data, which are possibly stored in a spatial database. An important application of spatial data mining methods is the extraction of knowledge from a Geographic Information System (GIS). INGENS (INductive GEographic iNformation System) is a prototype GIS which integrates data mining tools to assist users in their task of topographic map interpretation. The spatial data mining process is aimed at a user who controls the parameters of the process by means of a query written in a mining query language. In this paper, we present SDMOQL (Spatial Data Mining Object Query Language), a spatial data mining query language used in INGENS, whose design is based on the standard OQL (Object Query Language). Currently, SDMOQL supports two data mining tasks: inducing classification rules and discovering association rules. For both tasks the language permits the specification of the task-relevant data, the kind of knowledge to be mined, the background knowledge and the hierarchies, the interestingness measures and the visualization for discovered patterns. Some constraints on the query language are identified by the particular mining task. The syntax of the query language is described and the application to a real repository of maps is briefly reported. © Springer-Verlag Berlin Heidelberg 2004.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Kumar2004313,
author={Kumar, S. and Choudhary, S.K. and Mathur, V. and Jha, H.},
title={Application of data mining technology at Tata Steel},
journal={AISTech - Iron and Steel Technology Conference Proceedings},
year={2004},
volume={2},
pages={313-328},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-18044363843&partnerID=40&md5=f852bb7b6c174095414dabcd709e1636},
abstract={A Data Warehouse (DWH) Facility was installed at the LD2 & Slab Caster Shop of Tata Steel. This system collects and stores data generated at the various Level 1, Level 2 and Level 3 systems that are operational on different hardware and software platforms, in the steelmelting shop The DWH Facility has simplified access to data generated in the shop, something that was previously, an extremely tedious task. In addition to the data storage function, the DWH facility also has several tools for advanced data analysis. These include IBM's OLAP (On-Line Analytical Processing), IBM's Intelligent Miner (Data Mining), COGNOS's Impromptu and Power Play (Standard Reporting). In simple terms, Data Mining is extraction of previously unknown and potentially useful information from the historical data. This technology is being applied to process large quantities of data, as well as discover meaningful patterns and rules about the business process. The algorithms are based on techniques such as generation of hypothesis, classification, prediction, association rules or affinity grouping and clustering. The powerful algorithms embedded in the data mining tools have the ability to reveal "hidden" patterns or relationships even in complex data-sets that may be associated with high degree of uncertainty. Data Mining techniques were applied to several problem areas in the steelmelting shop. The important ones included understanding blister formation in IF steel, production of low-sulphur steels (co-injection factor for hot metal desulphurization and sulphur-reversal at LD steelmaking stage), transverse crack formation in slabs, high nitrogen problem in IF steel, premature LD vessel life failure, etc. While the Data Mining analysis did verify the known impacts of various parameters, there were several instances of generation of new knowledge / understanding about the process with respect to the pertinent problem being studied. The journey has just begun. Data Mining technology will be at the heart of advanced data analysis and problem solving in the steelmelting shop of Tata Steel.},
author_keywords={Data Mining;  Data preparation;  Steelmelting shop},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Peng2004885,
author={Peng, Y.-F. and Lin, C.-M. and Chin, W.-L.},
title={Adaptive recurrent cerebellar model articulation controller for unknown dynamic systems with optimal learning-rates},
journal={IEEE International Conference on Neural Networks - Conference Proceedings},
year={2004},
volume={2},
pages={885-890},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-10944222771&partnerID=40&md5=cd7ec2730db2303a8c17eed5a379f497},
abstract={In this study, an adaptive recurrent cerebellar model articulation controller (ARCMAC) is designed for feedback control system with unknown dynamics. The proposed ARCMAC has superior capability to the conventional cerebellar model articulation controller (CMAC) in efficient learning mechanism, guaranteed system stability and dynamic response. Temporal relations are embedded in ARCMAC by adding feedback connections in the association memory space so that the ARCMAC captures the dynamic response. The dynamic gradient descent method is adopted to adjust ARCMAC parameters on-line. Moreover, the variable optimal learning-rates are derived to achieve most rapid convergence of tracking error. Finally, the effectiveness of the proposed control system is verified by experimental results of linear piezoelectric ceramic motor (LPCM) position control system. Experimental results show that accurate tracking response and superior dynamic performance can be obtained because of the powerful on-line learning capability of the proposed ARCMAC.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lin20042144,
author={Lin, C.-J. and Chin, C.-C.},
title={Prediction and identification using wavelet-based recurrent fuzzy neural networks},
journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics},
year={2004},
volume={34},
number={5},
pages={2144-2154},
doi={10.1109/TSMCB.2004.833330},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-4844222566&doi=10.1109%2fTSMCB.2004.833330&partnerID=40&md5=5d5ba82e4600e241d76f6cc4b1c80505},
abstract={This paper presents a wavelet-based recurrent fuzzy neural network (WRFNN) for prediction and identification of nonlinear dynamic systems. The proposed WRFNN model combines the traditional Takagi-Sugeno-Kang (TSK) fuzzy model and the wavelet neural networks (WNN). This paper adopts the nonorthogonal and compactly supported functions as wavelet neural network bases. Temporal relations embedded in the network are caused by adding some feedback connections representing the memory units into the second layer of the feedforward wavelet-based fuzzy neural networks (WFNN). An online learning algorithm, which consists of structure learning and parameter learning, is also presented. The structure learning depends on the degree measure to obtain the number of fuzzy rules and wavelet functions. Meanwhile, the parameter learning is based on the gradient descent method for adjusting the shape of the membership function and the connection weights of WNN. Finally, computer simulations have demonstrated that the proposed WRFNN model requires fewer adjustable parameters and obtains a smaller rms error than other methods. © 2004 IEEE.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Huang2004514,
author={Huang, Y.-P. and Kao, L.-J.},
title={Using fuzzy support and confidence setting to mine interesting association rules},
journal={Annual Conference of the North American Fuzzy Information Processing Society - NAFIPS},
year={2004},
volume={2},
pages={514-519},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-4544220115&partnerID=40&md5=988244535571227fc33f222205dbb558},
abstract={This paper proposes a fuzzy model to derive the appropriate minimum support and confidence thresholds for mining the association rules. The traditional data mining technologies of association rules usually base on user-defined minimum support and confidence values. The most important problem is how to select the appropriate minimum support and confidence to find frequent itemsets. Apriori algorithm, the widely adopted approach, exploits the following property to derive the frequent itemset: If an itemset is frequent, so are all its subsets. That is, Apriori algorithm generates itemsets in a level-wise manner where each candidate in the jth iteration is generated from previous frequent (j-l)-itemsets. A generated candidate can be further pruned if any subset of size j-1 is not a frequent itemset. Apriori algorithm relies on the essential assumption that all itemsets have a uniform minimum support value, i.e., we assume that all items in the dataset have the same nature, e.g., all the items have the same sale price or the same salability condition in different time intervals or locations. However, the assumption may not comply with the rules embedded in the large databases. Concept hierarchy is helpful to solve the problem and the support and confidence thresholds should vary especially while we consider items at different conceptual abstractions. For example, turkey and pumpkin pie are seldom sold together. However, if we look at the transactions in the week before Thanksgiving, we may discover that most transactions contain turkey and pumpkin pie. It means that we should apply different support values to different time intervals. In this paper, we present a framework of multilevel association rules mining in the presence of fuzzy concept hierarchies that will derive a reasonable minimum support and confidence setting without losing potential interesting rules.},
author_keywords={Concept hierarchy;  Data mining;  Fuzzy control model;  Multilevel association rules mining},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Guan2004119,
author={Guan, J.W. and Liu, D.Y. and Bell, D.A.},
title={Discovering motifs in DNA sequences},
journal={Fundamenta Informaticae},
year={2004},
volume={59},
number={2-3},
pages={119-134},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-2342666705&partnerID=40&md5=c8b7ac1370850bc4e1a9a7e2da5b1faa},
abstract={Large collections of genomic information have been accumulated in recent years, and embedded latently in them is potentially significant knowledge for exploitation in medicine and in the pharmaceutical industry. The approach taken here to the distillation of such knowledge is to detect strings in DNA sequences which appear frequently, either within a given sequence (e.g., for a particular patient) or across sequences (e.g., from different patients sharing a particular medical diagnosis). Motifs are strings that occur very frequently. We present basic theory and algorithms for finding very frequent and common strings. Strings which are maximally frequent are of particular interest and, having discovered such motifs, we show briefly how to mine association rules by an existing rough sets based technique. Further work and applications are in progress.},
author_keywords={Bioinformatics;  Data Mining;  DNA;  Knowledge Discovery in Databases;  Rough Sets},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Chiu2003230,
author={Chiu, S. and Liao, W.-K. and Choudhary, A.},
title={Design and evaluation of distributed smart disk architecture for I/O-intensive workloads},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2003},
volume={2660},
pages={230-241},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-21144433900&partnerID=40&md5=36e09f1107338f75e075da4a6b938464},
abstract={Smart disks, a type of processor-embedded active I/O devices, with their on-disk memory and network interface controller, can be viewed as processing elements with attached storage. The growing size and access patterns of today's large I/O-intensive applications require architectures whose processing power scales with the storage capacity. We evaluate a distributed smart disk architecture with representative I/O-intensive workloads including TPC-H queries, association rule mining, data clustering, and 2-D fast Fourier transform applications to study the proposed architecture. © Springer-Verlag Berlin Heidelberg 2003.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Han2003105,
author={Han, J. and Hu, X. and Cercone, N.},
title={A visualization model of interactive knowledge discovery systems and its implementations},
journal={Information Visualization},
year={2003},
volume={2},
number={2},
pages={105-125},
doi={10.1057/palgrave.ivs.9500045},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997907687&doi=10.1057%2fpalgrave.ivs.9500045&partnerID=40&md5=ee4791d072ea4652d7255ab1635c8f5a},
abstract={We briefly introduce an interactive visualization model, RuleViz, for knowledge discovery and data mining, which consists of five components: data preparation and visualization, interactive data reduction, data preprocessing, pattern discovery, and pattern visualization. With this model, the implementation issues are considered and three implementation paradigms, including image-based paradigm, algorithm-embedded paradigm, and interaction-driven paradigm, are discussed. We implement an interactive visualization system, AViz, which discovers 3D numerical association rules from large data sets based on the image-based paradigm. The framework of the AViz system is presented and each component is explored. To discretize numerical attributes, three approaches, including equal-sized, bin-packing-based equal-depth, and interaction-based approaches are proposed, and the algorithm for mining and visualizing numerical association rules is developed. Our experimental result on a census data set is illustrated, which shows that the AViz system is useful and helpful for discovering and visualizing numerical association rules. © 2003, SAGE Publications. All rights reserved.},
author_keywords={association rules;  data mining;  Interactive information visualization;  knowledge discovery in databases},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Vaidya2002639,
author={Vaidya, J. and Clifton, C.},
title={Privacy preserving association rule mining in vertically partitioned data},
journal={Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
year={2002},
pages={639-644},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0242709355&partnerID=40&md5=a713342eebbce9dc4460bb1edbbce7ba},
abstract={Privacy considerations often constrain data mining projects. This paper addresses the problem of association rule mining where transactions are distributed across sources. Each site holds some attributes of each transaction, and the sites wish to collaborate to identify globally valid association rules. However, the sites must not reveal individual transaction data. We present a two-party algorithm for efficiently discovering frequent itemsets with minimum support levels, without either site revealing individual transaction values.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Li2002173,
author={Li, W. and Wong, K.-F.},
title={A Word-Based Approach for Modeling and Discovering Temporal Relations Embedded in Chinese Sentences},
journal={ACM Transactions on Asian Language Information Processing},
year={2002},
volume={1},
number={3},
pages={173-206},
doi={10.1145/772755.772756},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988220373&doi=10.1145%2f772755.772756&partnerID=40&md5=ac7067a496d58e80cd6189fd30d0e3bb},
abstract={Conventional information extraction systems cannot effectively mine temporal information. For example, users queries on how one event is related to another in time could not be handled effectively. For this reason, it is important to capture and deduce temporal knowledge associated with the relevant events. It is generally acknowledged that information extraction cannot be isolated from natural language processing. As Chinese has no tenses, conventional means for finding temporal references based on verb forms no longer apply. In this article we present an approach for formulating and discovering temporal relations in Chinese. A set of rules is devised to map the combinational effects of the temporal indicators (also known as temporal markers, gathered from various grammatical categories) in a sentence to its corresponding temporal relation. To evaluate the proposed algorithm, experiments were conducted using a set of news reports and the results look promising. Problem discussions are also provided. Through this work, we hope to open up new doors for future research in Chinese temporal information extraction and processing. © 2002, ACM. All rights reserved.},
author_keywords={Algorithms;  Chinese language processing;  Experimentation;  Languages;  Temporal information processing;  temporal relationship discovery},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wojciechowski200277,
author={Wojciechowski, M. and Zakrzewicz, M.},
title={Dataset filtering techniques in constraint-based frequent pattern mining},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2002},
volume={2447},
pages={77-91},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937713687&partnerID=40&md5=1364c4a3206818bfacbc71db0a07aeea},
abstract={Many data mining techniques consist in discovering patterns frequently occurring in the source dataset. Typically, the goal is to discover all the patterns whose frequency in the dataset exceeds a userspecified threshold. However, very often users want to restrict the set of patterns to be discovered by adding extra constraints on the structure of patterns. Data mining systems should be able to exploit such constraints to speed-up the mining process. In this paper, we focus on improving the efficiency of constraint-based frequent pattern mining by using dataset filtering techniques. Dataset filtering conceptually transforms a given data mining task into an equivalent one operating on a smaller dataset. We present transformation rules for various classes of patterns: itemsets, association rules, and sequential patterns, and discuss implementation issues regarding integration of dataset filtering with well-known pattern discovery algorithms. © 2002 Springer-Verlag Berlin Heidelberg.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Li2002190,
author={Li, Q. and Zhang, Y.-J. and Dai, S.-Y.},
title={Image search engine with selective filtering and feature element based classification},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2002},
volume={4672},
pages={190-197},
doi={10.1117/12.452672},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036031063&doi=10.1117%2f12.452672&partnerID=40&md5=8f59eec1f7c6a51302e64bc5ceb06d10},
abstract={With the growth of Internet and storage capability in recent years, image has become a widespread information format in World Wide Web. However, it has become increasingly harder to search for images of interest, and effective image search engine for the WWW needs to be developed. We propose in this paper a selective filtering process and a novel approach for image classification based on feature element in the image search engine we developed for the WWW. First a selective filtering process is embedded in a general web crawler to filter out the meaningless images with GIF format. Two parameters that can be obtained easily are used in the filtering process. Our classification approach first extract feature elements from images instead of feature vectors. Compared with feature vectors, feature elements can better capture visual meanings of the image according to subjective perception of human beings. Different from traditional image classification method, our classification approach based on feature element doesn't calculate the distance between two vectors in the feature space, while trying to find associations between feature element and class attribute of the image. Experiments are presented to show the efficiency of the proposed approach.},
author_keywords={Association rule mining;  Feature element;  Image classification;  Selective filtering},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Surmann2001649,
author={Surmann, H. and Maniadakis, M.},
title={Learning feed-forward and recurrent fuzzy systems: A genetic approach},
journal={Journal of Systems Architecture},
year={2001},
volume={47},
number={7},
pages={649-662},
doi={10.1016/S1383-7621(01)00021-2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035358455&doi=10.1016%2fS1383-7621%2801%2900021-2&partnerID=40&md5=bdcba5763be7ef13eb86fb67adde23b8},
abstract={In this paper, we present a new learning method for rule-based feed-forward and recurrent fuzzy systems. Recurrent fuzzy systems have hidden fuzzy variables and can approximate the temporal relation embedded in dynamic processes of unknown order. The learning method is universal i.e., it selects optimal width and position of Gaussian like membership functions and it selects a minimal set of fuzzy rules as well as the structure of the rules. A genetic algorithm (GA) is used to estimate the fuzzy systems which capture low complexity and minimal rule base. Optimization of the "entropy" of a fuzzy rule base leads to a minimal number of rules, of membership functions and of subpremises together with an optimal input/output (I/O) behavior. Most of the resulting fuzzy systems are comparable to systems designed by an expert but offers a better performance. The approach is compared to others by a standard benchmark (a system identification process). Different results for feed-forward and first-order rec urrent fuzzy systems with symmetric and non-symmetric membership functions are presented. © 2001 Elsevier Science B.V.},
author_keywords={Dynamic processes;  Entropy of fuzzy rule;  Fuzzy logic controller;  Genetic algorithm;  Machine learning;  Recurrent fuzzy systems},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Liu2000208,
author={Liu, B. and Hu, M. and Hsu, W.},
title={Multi-level organization and summarization of the discovered rules},
journal={Proceeding of the Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
year={2000},
pages={208-217},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034593061&partnerID=40&md5=d47e3a75b7de9a7263226565cd75dfe0},
abstract={Many existing data mining techniques often produce a large number of rules, which make it very difficult for manual inspection of the rules to identify those interesting ones. This problem represents a major gap between the results of data mining and the understanding and use of the mining results. In this paper, we argue that the key problem is not with the large number of rules because if there are indeed many rules that exist in data, they should be discovered. The man problem is with our inability to organize, summarize and present the rules in such a way that they can be easily analyzed by the user. In this paper, we propose a technique to intuitively organize and summarize the discovered rules. With this organization, the discovered rules can be presented to the user in the way as we think and talk about knowledge in our dally lives. This organization also allows the user to view the discovered rules at different levels of details, and to focus his/her attention on those interesting aspects. This paper presents this technique and uses it to organize, summarize and present the knowledge embedded in a decision tree, and a set of association rules. Experiment results and practical applications show that the technique is both intuitive and effective.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lee2000349,
author={Lee, C.-H. and Teng, C.-C.},
title={Identification and control of dynamic systems using recurrent fuzzy neural networks},
journal={IEEE Transactions on Fuzzy Systems},
year={2000},
volume={8},
number={4},
pages={349-366},
doi={10.1109/91.868943},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034244894&doi=10.1109%2f91.868943&partnerID=40&md5=33ba62c4f1d7fc6828aa9768a2f006e4},
abstract={This paper proposes a recurrent fuzzy neural network (RFNN) structure for identifying and controlling nonlinear dynamic systems. The RFNN is inherently a recurrent multilayered connectionist network for realizing fuzzy inference using dynamic fuzzy rules. Temporal relations are embedded in the network by adding feedback connections in the second layer of the fuzzy neural network (FNN). The RFNN expands the basic ability of the FNN to cope with temporal problems. In addition, results for the FNN-fuzzy inference engine, universal approximation, and convergence analysis are extended to the RFNN. For the control problem, we present the direct and indirect adaptive control approaches using the RFNN. Based on the Lyapunov stability approach, rigorous proofs are presented to guarantee the convergence of the RFNN by choosing appropriate learning rates. Finally, the RFNN is applied in several simulations (time series prediction, identification, and control of nonlinear systems). The results confirm the effectiveness of the RFNN.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Oguchi2000411,
author={Oguchi, Masato and Kitsuregawa, Masaru},
title={Using available remote memory dynamically for parallel data mining application on ATM-connected PC cluster},
journal={Proceedings of the International Parallel Processing Symposium, IPPS},
year={2000},
pages={411-420},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033880531&partnerID=40&md5=7a4fa2118de4b38110dbb0dd6fdfe47e},
abstract={Personal computer/Workstation (PC/WS) clusters are promising candidates for future high performance computers, because of their good scalability and cost performance ratio. Data intensive applications, such as data mining and ad hoc query processing in databases, are considered very important for massively parallel processors, as well as conventional scientific calculations. Thus, investigating the feasibility of data intensive applications on a PC cluster is meaningful. Association rule mining, one of the best-known problems in data mining, differs from conventional scientific calculations in its usage of main memory. It allocates many small data areas in main memory, and the number of those areas suddenly grows enormously during execution. As a result, the contents of memory must be swapped out if the requirement for memory space exceeds the real memory size. However, because the size of each data area is rather small and the elements are accessed almost at random, swapping out to a storage device must degrade the performance severely. In this paper, we investigate the feasibility of using available remote nodes' memory as a swap area when application execution nodes need to swap out their real memory contents during the execution of parallel data mining on PC clusters. We report our experiments in which application execution nodes acquire extra memory dynamically from several available remote nodes through an ATM network. A method of remote memory utilization with remote update operations is proposed and evaluated. The experimental results on our PC cluster show that the proposed method is expected to be considerably better than using hard disks as a swapping device. The dynamic decision mechanism for remote memory availability and the migration operations are also evaluated.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Gupta1999759,
author={Gupta, Gunjan K. and Strehl, Alexander and Ghosh, Joydeep},
title={Distance based clustering of association rules},
journal={Intelligent Engineering Systems Through Artificial Neural Networks},
year={1999},
volume={9},
pages={759-764},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033355986&partnerID=40&md5=a8b0d47d7aa4aff9e8150310485ee834},
abstract={Association rule mining is one of the most important procedures in data mining. In industry applications, often more than 10,000 rules are discovered. To allow manual inspection and support knowledge discovery the number of rules has to be reduced significantly by techniques such as pruning or grouping. In this paper, we present a new normalized distance metric to group association rules. Based on these distances, an agglomerative clustering algorithm is used to cluster the rules. Also the rules are embedded in a vector space by multi-dimensional scaling and clustered using a self organizing feature map. The results are combined for visualization. We compare various distance measures and illustrate subjective and objective cluster purity on results obtained from real data-sets.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wong1999,
author={Wong, Allan K.Y. and Wu, S.L. and Feng, L.},
title={Efficient algorithm for mining association rules for large itemsets in large centralized databases},
journal={Proceedings of the IEEE International Conference on Systems, Man and Cybernetics},
year={1999},
volume={3},
pages={III-905 - III-910},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0343838583&partnerID=40&md5=50637b07f976e363bd8153587b5a16a4},
abstract={The proposed algorithm is derived from the conventional Apriori approach with features added to improve data mining performance. These features are embedded in the encoding and decoding mechanisms. It has been confirmed by the preliminary test results that these features can indeed support effective and efficient mining of association rules in large centralized databases. The goal of the encoding mechanism is to reduce the I/O time for finding large itemsets, and to economize memory usage in a predictable manner. The decoding mechanism contributes to speed up the process of identifying different items in a transaction. The performance of three different decoding methods will be compared to demonstrate the potential gain delivered by any ingeniously devised decoding approach.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Juang1999828,
author={Juang, C.-F. and Lin, C.-T.},
title={A recurrent self-organizing neural fuzzy inference network},
journal={IEEE Transactions on Neural Networks},
year={1999},
volume={10},
number={4},
pages={828-845},
doi={10.1109/72.774232},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032681147&doi=10.1109%2f72.774232&partnerID=40&md5=86118d0760f7d490f948439e388a414d},
abstract={A recurrent self-organizing neural fuzzy inference network (RSONFIN) is proposed in this paper. The RSONFIN is inherently a recurrent multilayered connectionist network for realizing the basic elements and functions of dynamic fuzzy inference, and may be considered to be constructed from a series of dynamic fuzzy rules. The temporal relations embedded in the network are built by adding some feedback connections representing the memory elements to a feedforward neural fuzzy network. Each weight as well as node in the RSONFIN has its own meaning and represents a special element in a fuzzy rule. There are no hidden nodes (i.e., no membership functions and fuzzy rules) initially in the RSONFIN. They are created on-line via concurrent structure identification (the construction of dynamic fuzzy if-then rules) and parameter identification (the tuning of the free parameters of membership functions). The structure learning together with the parameter learning forms a fast learning algorithm for building a small, yet powerful, dynamic neural fuzzy network. Two major characteristics of the RSONFIN can thus be seen: 1) the recurrent property of the RSONFIN makes it suitable for dealing with temporal problems and 2) no predetermination, like the number of hidden nodes, must be given, since the RSONFIN can find its optimal structure and parameters automatically and quickly. Moreover, to reduce the number of fuzzy rules generated, a flexible input partition method, the aligned clustering-based algorithm, is proposed. Various simulations on temporal problems are done and performance comparisons with some existing recurrent networks are also made. Efficiency of the RSONFIN is verified from these results. © 1999 IEEE.},
author_keywords={Context node;  Dynamic fuzzy inference;  Feedback term node;  Ordered derivative;  Projection-based correlation measure},
document_type={Article},
source={Scopus},
}

@ARTICLE{NoAuthor19991,
title={2nd International Conference on Discovery Science, DS 1999},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={1999},
volume={1721},
pages={1-373},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957808354&partnerID=40&md5=324db086080c4b5ad4f3ee0bd71092fc},
abstract={The proceedings contain 53 papers. The special focus in this conference is on Discovery Science. The topics include: The melting pot of automated discovery; expressive probability models in science; weighted majority decision among several region rules for scientific discovery; classification by aggregating emerging patterns; an appropriate abstraction for an attribute-oriented induction; collaborative hypothesis testing processes by interactive production systems; computer aided discovery of user’s hidden interest for query restructuring; iterative naive bayes; schema design for causal law mining from imcomplete database; design and evaluation of an environment to automate the construction of inductive applications; designing views in hypothesiscreator; discovering poetic allusion in anthologies of classical japanese poems; characteristic sets of strings common to semi-structured documents; approximation of optimal two-dimensional association rules for categorical attributes using semidefinite programming; data mining of generalized association rules using a method of partial-match retrieval; adaptive sampling methods for scaling up knowledge discovery algorithms; scheduled discovery of exception rules; learning in constraint databases; discover risky active faults by indexing an earthquake sequence; machine discovery based on the co-occurrence of references in a search engine; smoothness prior approach to explore the mean structure in large time series data; automatic detection of geomagnetic sudden commencement using lifting wavelet filters; a noise resistant model inference system; a graphical method for parameter learning of symbolic-statistical models and parallel execution for speeding up inductive logic programming systems.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor19991,
title={7th International Conference Database Theory, ICDT 1999},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={1999},
volume={1540},
pages={1-488},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947214443&partnerID=40&md5=813801c871782c5ff58e954d3255151c},
abstract={The proceedings contain 29 papers. The special focus in this conference is on Query Languages, Concurrency and Distribution. The topics include: Issues raised by three years of developing pjama; novel computational approaches to information retrieval and data mining; description logics and their relationships with databases; an equational chase for path-conjunctive queries, constraints, and views; adding for-loops to first-order logic; definability and descriptive complexity on databases of bounded tree-width; decidability of first-order logic queries over views; urn models and yao’s formula; on the generation of 2-dimensional index workloads; increasing the expressiveness of analytical performance models for replicated databases; transactions in stack, fork, and join composite systems; databases for tracking mobile units in real time; on capturing first-order topological properties of planar spatial databases; on the orthographic dimension of constraint databases; on rectangular partitionings in two dimensions; optimal dynamic range searching in non-replicating index structures; index structures for path expressions; schemas for integration and translation of structured and semi-structured data; in search of the lost schema; tableau techniques for querying information sources through global schemas; optimizing large join queries in mediation systems; a framework for the investigation of aggregate functions in database queries; discovering frequent closed itemsets for association rules; answering queries using materialized views with disjunctions; selection of views to materialize under a maintenance cost constraint; the data warehouse of newsgroups.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Oguchi1999553,
author={Oguchi, M. and Kitsuregawa, M.},
title={Dynamic remote memory acquiring for parallel data mining on PC cluster: Preliminary performance results},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={1999},
volume={1593},
pages={553-562},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956862845&partnerID=40&md5=b10ec70d84f475de9a80988c4bb120da},
abstract={Recently data intensive applications such as data mining and data warehousing have been focused as one of the most important applications for high performance computing. As a platform, PC/WS cluster is a promising candidate for future high performance computers, from the viewpoint of good scalability and cost performance ratio. We have developed a large scale ATM connected PC cluster until now, and implemented several database applications, including parallel data mining, to evaluate their performance and the feasibility of such applications over PC clusters. Different from the conventional scientific calculations, association rule mining, which is one of the most well known problems in data mining, has a peculiar feature for its usage of main memory. It needs a lot of small data on main memory at each node, and the number of those areas suddenly swells to be enormous during the execution. Thus the requirement of memory space changes dynamically and becomes tremendously large. As a result, contents of memory must be swapped out if the requirement exceeds the real memory size. However, because the size of each data is rather small and all the areas are accessed almost at random, swapping out to a storage device is expected to degrade the performance dramatically in this case. Therefore some other methods must be introduced to perform large scale data mining on PC clusters, which may require huge memory dynamically. We are investigating the feasibility of using available idle nodes' memory as a swap area when some nodes need to swap out its real memory contents, during the execution of parallel data mining on PC clusters. Idle nodes are expected to exist in large scale clusters. In this paper, we report our preliminary results in which application executing nodes acquire extra-memory dynamically from several available idle nodes through ATM network. The experimental result on the PC cluster shows this method is expected to be considerably better than using hard disks as a swapping device. © Springer-Verlag Berlin Heidelberg 1999.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Oguchi1999246,
author={Oguchi, Masato and Kitsuregawa, Masaru},
title={Dynamic remote memory acquisition for parallel data mining on ATM-connected PC cluster},
journal={Proceedings of the International Conference on Supercomputing},
year={1999},
pages={246-252},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032645267&partnerID=40&md5=53b1f1c28fb6616127c380dfcd28f0c3},
abstract={Personal computer/Workstation (PC/WS) clusters are promising candidates for future high performance computers, because of their good scalability and cost performance ratio. Data intensive applications, such as data mining and data warehousing, have become yew important applications for high performance computing. We previously developed a large scale PC cluster connected with ATM, and implemented several database applications, including parallel data mining, to evaluate their performance and the feasibility of such applications using PC clusters. Association rule mining, one of the best-known problems in data mining, differs from conventional scientific calculations in its usage of main memory. It allocates many small data areas in main memory, and the number of those areas suddenly grows enormously during execution. Thus, the requirement for memory space changes dynamically and becomes extremely large. As a result, the contents of memory must be swapped out if the requirement exceeds the real memory size. However, because the size of each data area is rather small and the elements are accessed almost at random, swapping out to a storage device must degrade the performance severely in this case. We are investigating the feasibility of using available memory on idle nodes as a swap area when working nodes need to swap out their real memory contents during the execution of parallel data mining on PC clusters. In many cases, idle nodes are expected to exist in large clusters. In this paper, we report our experiments in which nodes executing applications acquire extra memory dynamically from several available idle nodes through a high-speed network - ATM in our pilot system. The experimental results on our PC cluster show that the proposed method is expected to be considerably better than using hard disks as a swapping device. Moreover, a method using a distant node's memory with remote update operations, which is expected to prevent a thrashing problem, is proposed and evaluated.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Liu1998248,
author={Liu, Y. and Chen, H. and Yu, J.X. and Ohbo, N.},
title={Using stem rules to refine document retrieval queries},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={1998},
volume={1495},
pages={248-259},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948953817&partnerID=40&md5=000812b3e193f7e8f013d99c981d4c73},
abstract={In this paper, a data mining approach for query refinement is proposed using Association Rules (ARs) among keywords being extracted from a document database. When a query is under-specified or contains ambiguous keywords, a set of association rules will be displayed to assist the user to choose additional keywords in order to refine his/her original query. To the best of our knowledge, no reported study has discussed on how to screen the number of documents being retrieved using ARs. The issues we are concerned in this paper are as follows. First, an AR, X =, Y, with high confidence will intend to show that the number of documents that contain both sets of keywords X and Y is large. Therefore, the effectiveness of using minimum support and minimum confidence to screen documents can be little. To address this issue, maximum support and maximum confidence are used. Second, a large number of rules will be stored in a rule base, and will be displayed at run time in response to a user query. In order to reduce the number of rules, in this paper, we introduce two co-related concepts: "stem rule" and "coverage". The stem rules are the rules by which other rules can be derived. A set of keywords is said to be a coverage of a set of documents if these documents can be retrieved using the same set of keywords. A minimum coverage can reduce the number of keywords to cover a certain number of documents, and therefore can assist to reduce the number of rules to be managed. In order to demonstrate the applicability of the proposed method, we have built an interactive interface, and a mediumsized document database is maintained. The effectiveness of using ARs to screen will be addressed in this paper as well. © Springer-Verlag Berlin Heidelberg 1998.},
author_keywords={And Keyword Coverage;  Data Mining;  Information Retrieval;  Query Refinement;  Stem Rule},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lent1997220,
author={Lent, Brian and Swami, Arun and Widom, Jennifer},
title={Clustering association rules},
journal={Proceedings - International Conference on Data Engineering},
year={1997},
pages={220-231},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030643619&partnerID=40&md5=e0f6db66bb3983f45484e359ddc08014},
abstract={We consider the problem of clustering two-dimensional association rules in large database. We present a geometric-based algorithm, BitOp, for performing the clustering, embedded within an association rule clustering system, ARCS. Association rule clustering is useful when the user desires to segment the data. We measure the quality of the segmentation generated by ARCS using the Minimum Description Length (MDL) principle of encoding the clusters on several databases including noise and errors. Scale-up experiments show that ARCS, using the BitOp algorithm, scales linearly with the amount of data.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Juang19971369,
author={Juang, Chia-Feng and Lin, Chin-Teng},
title={Recurrent self-organizing neural fuzzy inference network},
journal={IEEE International Conference on Fuzzy Systems},
year={1997},
volume={3},
pages={1369-1374},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030684248&partnerID=40&md5=e1b6dd7642807b3ac48075fcdf384d29},
abstract={A Recurrent Self-Organizing Neural Fuzzy Inference Network (RSONFIN) is proposed in this paper. The RSONFIN is constructed from a series of dynamic fuzzy rules. The temporal relations embedded in the network are built by adding some feedback connections representing the memory elements to a feedforward neural fuzzy network. Each weight as well as node in the RSONFIN has its own meaning and represents a special element in a fuzzy rule. There are no hidden nodes (i.e., no membership functions and fuzzy rules) initially in the RSONFIN. They are created on-line via concurrent structure identification (the construction of dynamic fuzzy if-then rules) and parameter identification (the tuning of the free parameters of membership functions). The structure learning together with the parameter learning forms a fast learning algorithm for building a small, yet powerful, dynamic neural fuzzy network. Simulations on temporal problems are done finally.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Koubarakis1994141,
author={Koubarakis, M.},
title={Database models for infinite and indefinite temporal information},
journal={Information Systems},
year={1994},
volume={19},
number={2},
pages={141-173},
doi={10.1016/0306-4379(94)90008-6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0000179322&doi=10.1016%2f0306-4379%2894%2990008-6&partnerID=40&md5=e88424e33d7ec235f48d95cad0cb5842},
abstract={Representation and querying of temporal information can benefit from the integration of techniques from constraint databases, database models for indefinite information and reasoning about temporal constraints. With this perspective in mind, we present a hierarchy of temporal data models: temporal relations, generalized temporal relations and temporal tables. We study the semantics of these models and develop algebraic and calculus query languages for them. The proposed models can be useful to several novel applications include planning, scheduling, project management, medical information systems, geographical information systems and natural language processing systems. © 1994.},
document_type={Article},
source={Scopus},
}
